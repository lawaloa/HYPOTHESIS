<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Lawal’s Note">
<meta name="dcterms.date" content="2025-01-14">

<title>Hypothesis Testing in Python</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-Chapter1" id="toc-sec-Chapter1" class="nav-link active" data-scroll-target="#sec-Chapter1"><span class="header-section-number">1</span> Chapter 1: Hypothesis Testing Fundamentals</a>
  <ul class="collapse">
  <li><a href="#sec-Chapter1.1" id="toc-sec-Chapter1.1" class="nav-link" data-scroll-target="#sec-Chapter1.1"><span class="header-section-number">1.1</span> Chapter 1.1: Hypothesis tests and z-scores</a></li>
  <li><a href="#exercise-1.1.1" id="toc-exercise-1.1.1" class="nav-link" data-scroll-target="#exercise-1.1.1"><span class="header-section-number">1.2</span> Exercise 1.1.1</a></li>
  <li><a href="#exercise-1.1.2" id="toc-exercise-1.1.2" class="nav-link" data-scroll-target="#exercise-1.1.2"><span class="header-section-number">1.3</span> Exercise 1.1.2</a></li>
  <li><a href="#sec-Chapter1.2" id="toc-sec-Chapter1.2" class="nav-link" data-scroll-target="#sec-Chapter1.2"><span class="header-section-number">1.4</span> Chapter 1.2: p-values</a></li>
  <li><a href="#exercise-1.2.1" id="toc-exercise-1.2.1" class="nav-link" data-scroll-target="#exercise-1.2.1"><span class="header-section-number">1.5</span> Exercise 1.2.1</a></li>
  <li><a href="#chapter-1.3-statistical-significance" id="toc-chapter-1.3-statistical-significance" class="nav-link" data-scroll-target="#chapter-1.3-statistical-significance"><span class="header-section-number">1.6</span> Chapter 1.3: Statistical significance</a></li>
  <li><a href="#exercise-1.3.1" id="toc-exercise-1.3.1" class="nav-link" data-scroll-target="#exercise-1.3.1"><span class="header-section-number">1.7</span> Exercise 1.3.1</a></li>
  </ul></li>
  <li><a href="#sec-Chapter2" id="toc-sec-Chapter2" class="nav-link" data-scroll-target="#sec-Chapter2"><span class="header-section-number">2</span> Chapter 2: Two-Sample and ANOVA Tests</a>
  <ul class="collapse">
  <li><a href="#sec-Chapter2.1" id="toc-sec-Chapter2.1" class="nav-link" data-scroll-target="#sec-Chapter2.1"><span class="header-section-number">2.1</span> Chapter 2.1: Performing t-tests</a></li>
  <li><a href="#exercise-2.1.1" id="toc-exercise-2.1.1" class="nav-link" data-scroll-target="#exercise-2.1.1"><span class="header-section-number">2.2</span> Exercise 2.1.1</a></li>
  <li><a href="#sec-Chapter2.2" id="toc-sec-Chapter2.2" class="nav-link" data-scroll-target="#sec-Chapter2.2"><span class="header-section-number">2.3</span> Chapter 2.2: Calculating p-values from t-statistics</a></li>
  <li><a href="#exercise-2.2.1" id="toc-exercise-2.2.1" class="nav-link" data-scroll-target="#exercise-2.2.1"><span class="header-section-number">2.4</span> Exercise 2.2.1</a></li>
  <li><a href="#sec-Chapter2.3" id="toc-sec-Chapter2.3" class="nav-link" data-scroll-target="#sec-Chapter2.3"><span class="header-section-number">2.5</span> Chapter 2.3: Paired t-tests</a></li>
  <li><a href="#exercise-2.3.1" id="toc-exercise-2.3.1" class="nav-link" data-scroll-target="#exercise-2.3.1"><span class="header-section-number">2.6</span> Exercise 2.3.1</a></li>
  <li><a href="#exercise-2.3.2" id="toc-exercise-2.3.2" class="nav-link" data-scroll-target="#exercise-2.3.2"><span class="header-section-number">2.7</span> Exercise 2.3.2</a></li>
  <li><a href="#sec-Chapter2.4" id="toc-sec-Chapter2.4" class="nav-link" data-scroll-target="#sec-Chapter2.4"><span class="header-section-number">2.8</span> Chapter 2.4: ANOVA tests</a></li>
  <li><a href="#exercise-2.4.1" id="toc-exercise-2.4.1" class="nav-link" data-scroll-target="#exercise-2.4.1"><span class="header-section-number">2.9</span> Exercise 2.4.1</a></li>
  <li><a href="#exercise-2.4.2" id="toc-exercise-2.4.2" class="nav-link" data-scroll-target="#exercise-2.4.2"><span class="header-section-number">2.10</span> Exercise 2.4.2</a></li>
  <li><a href="#exercise-2.4.3" id="toc-exercise-2.4.3" class="nav-link" data-scroll-target="#exercise-2.4.3"><span class="header-section-number">2.11</span> Exercise 2.4.3</a></li>
  </ul></li>
  <li><a href="#sec-Chapter3" id="toc-sec-Chapter3" class="nav-link" data-scroll-target="#sec-Chapter3"><span class="header-section-number">3</span> Chapter 3: Proportion Tests</a>
  <ul class="collapse">
  <li><a href="#sec-Chapter3.1" id="toc-sec-Chapter3.1" class="nav-link" data-scroll-target="#sec-Chapter3.1"><span class="header-section-number">3.1</span> Chapter 3.1: One-sample proportion tests</a></li>
  <li><a href="#exercise-3.1.1" id="toc-exercise-3.1.1" class="nav-link" data-scroll-target="#exercise-3.1.1"><span class="header-section-number">3.2</span> Exercise 3.1.1</a></li>
  <li><a href="#sec-Chapter3.2" id="toc-sec-Chapter3.2" class="nav-link" data-scroll-target="#sec-Chapter3.2"><span class="header-section-number">3.3</span> Chapter 3.2: Two-sample proportion tests</a></li>
  <li><a href="#exercise-3.2.1" id="toc-exercise-3.2.1" class="nav-link" data-scroll-target="#exercise-3.2.1"><span class="header-section-number">3.4</span> Exercise 3.2.1</a></li>
  <li><a href="#exercise-3.2.2" id="toc-exercise-3.2.2" class="nav-link" data-scroll-target="#exercise-3.2.2"><span class="header-section-number">3.5</span> Exercise 3.2.2</a></li>
  <li><a href="#sec-Chapter3.3" id="toc-sec-Chapter3.3" class="nav-link" data-scroll-target="#sec-Chapter3.3"><span class="header-section-number">3.6</span> Chapter 3.3: Chi-square test of independence</a></li>
  <li><a href="#exercise-3.3.3" id="toc-exercise-3.3.3" class="nav-link" data-scroll-target="#exercise-3.3.3"><span class="header-section-number">3.7</span> Exercise 3.3.3</a></li>
  <li><a href="#sec-Chapter3.4" id="toc-sec-Chapter3.4" class="nav-link" data-scroll-target="#sec-Chapter3.4"><span class="header-section-number">3.8</span> Chapter 3.4: Chi-square goodness of fit tests</a></li>
  <li><a href="#exercise-3.4.1" id="toc-exercise-3.4.1" class="nav-link" data-scroll-target="#exercise-3.4.1"><span class="header-section-number">3.9</span> Exercise 3.4.1</a></li>
  <li><a href="#exercise-3.4.2" id="toc-exercise-3.4.2" class="nav-link" data-scroll-target="#exercise-3.4.2"><span class="header-section-number">3.10</span> Exercise 3.4.2</a></li>
  </ul></li>
  <li><a href="#sec-Chapter4" id="toc-sec-Chapter4" class="nav-link" data-scroll-target="#sec-Chapter4"><span class="header-section-number">4</span> CHAPTER 4: Non-Parametric Tests</a>
  <ul class="collapse">
  <li><a href="#sec-Chapter4.1" id="toc-sec-Chapter4.1" class="nav-link" data-scroll-target="#sec-Chapter4.1"><span class="header-section-number">4.1</span> Chapter 4.1: Assumptions in hypothesis testing</a></li>
  <li><a href="#exercise-4.1.1" id="toc-exercise-4.1.1" class="nav-link" data-scroll-target="#exercise-4.1.1"><span class="header-section-number">4.2</span> Exercise 4.1.1</a></li>
  <li><a href="#sec-Chapter4.2" id="toc-sec-Chapter4.2" class="nav-link" data-scroll-target="#sec-Chapter4.2"><span class="header-section-number">4.3</span> Chapter 4.2: Non-parametric tests</a></li>
  <li><a href="#exercise-4.2.1" id="toc-exercise-4.2.1" class="nav-link" data-scroll-target="#exercise-4.2.1"><span class="header-section-number">4.4</span> Exercise 4.2.1</a></li>
  <li><a href="#chapter-4.3-non-parametric-anova-and-unpaired-t-tests" id="toc-chapter-4.3-non-parametric-anova-and-unpaired-t-tests" class="nav-link" data-scroll-target="#chapter-4.3-non-parametric-anova-and-unpaired-t-tests"><span class="header-section-number">4.5</span> Chapter 4.3: Non-parametric ANOVA and unpaired t-tests</a></li>
  <li><a href="#exercise-4.3.1" id="toc-exercise-4.3.1" class="nav-link" data-scroll-target="#exercise-4.3.1"><span class="header-section-number">4.6</span> Exercise 4.3.1</a></li>
  <li><a href="#exercise-4.3.2" id="toc-exercise-4.3.2" class="nav-link" data-scroll-target="#exercise-4.3.2"><span class="header-section-number">4.7</span> Exercise 4.3.2</a></li>
  </ul></li>
  <li><a href="#reference" id="toc-reference" class="nav-link" data-scroll-target="#reference"><span class="header-section-number">5</span> Reference</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="index.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li><li><a href="index.docx"><i class="bi bi-file-word"></i>MS Word</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Hypothesis Testing in Python</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Lawal’s Note </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Associate Data Science Course in Python by DataCamp Inc
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 14, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p><img src="SOA_Hypo.jpg" class="img-fluid"></p>
<section id="sec-Chapter1" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-Chapter1"><span class="header-section-number">1</span> Chapter 1: Hypothesis Testing Fundamentals</h2>
<p>How does hypothesis testing work and what problems can it solve? To find out, you’ll walk through the workflow for a one sample proportion test. In doing so, you’ll encounter important concepts like z-scores, p-values, and false negative and false positive errors.</p>
<section id="sec-Chapter1.1" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="sec-Chapter1.1"><span class="header-section-number">1.1</span> Chapter 1.1: Hypothesis tests and z-scores</h3>
<p>Hi, I’m James. Welcome to this course on hypothesis testing in Python. To start, let’s look at a real-world example where a hypothesis test was crucial in a decision-making process.</p>
<section id="ab-testing" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="ab-testing">A/B testing</h4>
<p>In 2013, Electronic Arts, or EA, launched a video game called SimCity 5. Leading up to its release, they wanted to increase pre-order sales. They used an experimental design technique called A/B testing, which has roots in hypothesis testing, to test different advertising scenarios and see which improved sales the most. Website visitors were split into a control group and a treatment group. Each group saw a different version of the game’s pre-order sales page. 1. 1 Image credit: “Electronic Arts” by majaX1 CC BY-NC-SA 2.0</p>
</section>
<section id="retail-webpage-ab-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="retail-webpage-ab-test">Retail webpage A/B test</h4>
<p>Here’s each version of the SimCity 5 pre-order page. The control group saw the version with a banner advertising money off their next purchase with each pre-order. The treatment group saw the version without the banner. EA compared the percentage of checkouts for the two groups to see which performed best. Our naive guess would be that the advertisement increased pre-order sales.</p>
</section>
<section id="ab-test-results" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="ab-test-results">A/B test results</h4>
<p>The results of the A/B test were surprising. The treatment page without the advertisement resulted in 43 percent higher sales than the control page with the advert. The experiment proved that our intuition that more discount adverts would result in more sales was false. We might ask ourselves, was the 43 percent difference a meaningful difference between the control and treatment groups, or was it just random chance? To get this answer, we’d need the original dataset from EA, which isn’t publicly available. However, the method to answering this question of significance would involve techniques from both the Sampling in Python course and from this course.</p>
</section>
<section id="stack-overflow-developer-survey-2020" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="stack-overflow-developer-survey-2020">Stack Overflow Developer Survey 2020</h4>
<p>Each year, Stack Overflow surveys its users, who are primarily software developers, about themselves, how they use Stack Overflow, their work, and the development tools they use. In this course, we’ll look at a subset of the survey responses from users who identified as Data Scientists.</p>
</section>
<section id="hypothesizing-about-the-mean" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="hypothesizing-about-the-mean">Hypothesizing about the mean</h4>
<p>Let’s hypothesize that the mean annual compensation of the population of data scientists is 110,000 dollars. We can initially examine the mean annual compensation from the sample survey data. Annual compensation, converted to dollars, is stored in the <code>converted_comp</code> column. The sample mean is a type of point estimate, which is another name for a summary statistic. We can calculate it with pandas using the <code>.mean</code> method on the <code>converted_comp</code> Series. The result is different from our hypothesis, but is it meaningfully different?</p>
</section>
<section id="generating-a-bootstrap-distribution" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="generating-a-bootstrap-distribution">Generating a bootstrap distribution</h4>
<p>To answer this, we need to generate a bootstrap distribution of sample means. This is done by resampling the dataset, calculating the sample mean for that resample, then repeating those steps to create a list of sample means.</p>
<ol type="1">
<li>1 [Bootstrap distributions are taught in Chapter 4 of Sampling in Python(https://lawaloa.github.io/Sampling/#chapter-4-bootstrap-distributions){target=“_blank”}</li>
</ol>
</section>
<section id="visualizing-the-bootstrap-distribution" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="visualizing-the-bootstrap-distribution">Visualizing the bootstrap distribution</h4>
<p>The histogram of the bootstrap distribution is a bell shape. Its bell shape means that it’s roughly normally distributed. Notice that 110,000 is on the left of the distribution.</p>
</section>
<section id="standard-error" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="standard-error">Standard error</h4>
<p>Recall that the standard deviation of the sample statistics in the bootstrap distribution estimates the standard error of the statistic.</p>
</section>
<section id="z-scores" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="z-scores">z-scores</h4>
<p>Since variables have arbitrary units and ranges, before we test our hypothesis, we need to standardize the values. A common way of standardizing values is to subtract the mean, and divide by the standard deviation. For hypothesis testing, we use a variation where we take the sample statistic, subtract the hypothesized parameter value, and divide by the standard error. The result is called a z-score. Here are the values we calculated earlier. The sample mean annual compensation for data scientists of around 120,000 dollars, minus the hypothesized compensation of 110,000, divided by the standard error gives a z-score of one-point-seven-zero-seven.</p>
<p><span class="math display">\[
\text{Standard value} = \frac{\text{value} - \text{mean}}{\text{standard deviation}}
\]</span></p>
<p><span class="math display">\[
z = \frac{\text{sample statistic} - \text{hypothesized parameter value}}{\text{standard error}}
\]</span></p>
</section>
<section id="testing-the-hypothesis" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="testing-the-hypothesis">Testing the hypothesis</h4>
<p>Is that a big or small number? Determining that is the goal of this course. In particular, we can now state one of the uses of hypothesis testing: determining whether a sample statistic is close to or far away from an expected value.</p>
</section>
<section id="standard-normal-z-distribution" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="standard-normal-z-distribution">Standard normal (z) distribution</h4>
<p>One final thing. Here’s a plot of the probability density function for the standard normal distribution, which is a normal distribution with mean of zero and standard deviation of one. It’s often called the z-distribution, and z-scores are related to this distribution. We’ll encounter the z-distribution throughout this course.</p>
</section>
</section>
<section id="exercise-1.1.1" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="exercise-1.1.1"><span class="header-section-number">1.2</span> Exercise 1.1.1</h3>
<section id="calculating-the-sample-mean" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-the-sample-mean">Calculating the sample mean</h4>
<p>The <code>late_shipments</code> dataset contains supply chain data on the delivery of medical supplies. Each row represents one delivery of a part. The <code>late</code> columns denotes whether or not the part was delivered late. A value of <code>"Yes"</code> means that the part was delivered late, and a value of <code>"No"</code> means the part was delivered on time.</p>
<p>You’ll begin your analysis by calculating a point estimate (or sample statistic), namely the proportion of late shipments.</p>
<p>In pandas, a value’s proportion in a categorical DataFrame column can be quickly calculated using the syntax:</p>
<pre><code>prop = (df['col'] == val).mean()</code></pre>
</section>
<section id="instructions" class="level4" data-number="1.2.1">
<h4 data-number="1.2.1" class="anchored" data-anchor-id="instructions"><span class="header-section-number">1.2.1</span> Instructions</h4>
<ol type="1">
<li>Print the <code>late_shipments</code> dataset.</li>
<li>Calculate the proportion of late shipments in the sample; that is, the mean cases where the <code>late</code> column is <code>"Yes"</code>.</li>
</ol>
<div id="8686c218" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import pandas</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the late_shipments dataset</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(late_shipments)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the proportion of late shipments</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>late_prop_samp <span class="op">=</span> (late_shipments[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(late_prop_samp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>          id       country managed_by  fulfill_via vendor_inco_term  \
0    36203.0       Nigeria   PMO - US  Direct Drop              EXW   
1    30998.0      Botswana   PMO - US  Direct Drop              EXW   
2    69871.0       Vietnam   PMO - US  Direct Drop              EXW   
3    17648.0  South Africa   PMO - US  Direct Drop              DDP   
4     5647.0        Uganda   PMO - US  Direct Drop              EXW   
..       ...           ...        ...          ...              ...   
995  13608.0        Uganda   PMO - US  Direct Drop              DDP   
996  80394.0    Congo, DRC   PMO - US  Direct Drop              EXW   
997  61675.0        Zambia   PMO - US  Direct Drop              EXW   
998  39182.0  South Africa   PMO - US  Direct Drop              DDP   
999   5645.0      Botswana   PMO - US  Direct Drop              EXW   

    shipment_mode  late_delivery late product_group    sub_classification  \
0             Air            1.0  Yes          HRDT              HIV test   
1             Air            0.0   No          HRDT              HIV test   
2             Air            0.0   No           ARV                 Adult   
3           Ocean            0.0   No           ARV                 Adult   
4             Air            0.0   No          HRDT  HIV test - Ancillary   
..            ...            ...  ...           ...                   ...   
995           Air            0.0   No           ARV                 Adult   
996           Air            0.0   No          HRDT              HIV test   
997           Air            1.0  Yes          HRDT              HIV test   
998         Ocean            0.0   No           ARV                 Adult   
999           Air            0.0   No          HRDT              HIV test   

     ... line_item_quantity line_item_value pack_price unit_price  \
0    ...             2996.0       266644.00      89.00       0.89   
1    ...               25.0          800.00      32.00       1.60   
2    ...            22925.0       110040.00       4.80       0.08   
3    ...           152535.0       361507.95       2.37       0.04   
4    ...              850.0            8.50       0.01       0.00   
..   ...                ...             ...        ...        ...   
995  ...              121.0         9075.00      75.00       0.62   
996  ...              292.0         9344.00      32.00       1.60   
997  ...             2127.0       170160.00      80.00       0.80   
998  ...           191011.0       861459.61       4.51       0.15   
999  ...              200.0        14398.00      71.99       0.72   

               manufacturing_site first_line_designation  weight_kilograms  \
0         Alere Medical Co., Ltd.                    Yes            1426.0   
1            Trinity Biotech, Plc                    Yes              10.0   
2    Hetero Unit III Hyderabad IN                    Yes            3723.0   
3       Aurobindo Unit III, India                    Yes            7698.0   
4                 Inverness Japan                    Yes              56.0   
..                            ...                    ...               ...   
995     Janssen-Cilag, Latina, IT                    Yes              43.0   
996          Trinity Biotech, Plc                    Yes              99.0   
997       Alere Medical Co., Ltd.                    Yes             881.0   
998     Aurobindo Unit III, India                    Yes           16234.0   
999               Inverness Japan                    Yes              46.0   

     freight_cost_usd  freight_cost_groups  line_item_insurance_usd  
0            33279.83            expensive                   373.83  
1              559.89           reasonable                     1.72  
2            19056.13            expensive                   181.57  
3            11372.23            expensive                   779.41  
4              360.00           reasonable                     0.01  
..                ...                  ...                      ...  
995            199.00           reasonable                    12.72  
996           2162.55           reasonable                    13.10  
997          14019.38            expensive                   210.49  
998          14439.17            expensive                  1421.41  
999           1028.18           reasonable                    23.04  

[1000 rows x 27 columns]
0.061</code></pre>
</div>
</div>
</section>
</section>
<section id="exercise-1.1.2" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="exercise-1.1.2"><span class="header-section-number">1.3</span> Exercise 1.1.2</h3>
<section id="calculating-a-z-score" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-a-z-score">Calculating a z-score</h4>
<p>Since variables have arbitrary ranges and units, we need to standardize them. For example, a hypothesis test that gave different answers if the variables were in Euros instead of US dollars would be of little value. Standardization avoids that.</p>
<p>One standardized value of interest in a hypothesis test is called a z-score. To calculate it, you need three numbers: the sample statistic (point estimate), the hypothesized statistic, and the standard error of the statistic (estimated from the bootstrap distribution).</p>
<p>The sample statistic is available as late_prop_samp.</p>
<p>late_shipments_boot_distn is a bootstrap distribution of the proportion of late shipments, available as a list.</p>
</section>
<section id="instructions-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-1">Instructions</h4>
<ul>
<li>Hypothesize that the proportion of late shipments is 6%.</li>
<li>Calculate the standard error from the standard deviation of the bootstrap distribution.</li>
<li>Calculate the z-score.</li>
</ul>
<div id="f6687797" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the late_shipments dataset</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(late_shipments)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the proportion of late shipments</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>late_prop_samp <span class="op">=</span> (late_shipments[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(late_prop_samp)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed for reproducibility</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of bootstrap samples</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>n_bootstrap_samples <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate bootstrap distribution</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>late_shipments_boot_distn <span class="op">=</span> [</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    (late_shipments.sample(frac<span class="op">=</span><span class="dv">1</span>, replace<span class="op">=</span><span class="va">True</span>)[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_bootstrap_samples)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Hypothesize that the proportion is 6%</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>late_prop_hyp <span class="op">=</span> <span class="fl">0.06</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the standard error</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>std_error <span class="op">=</span> np.std(late_shipments_boot_distn, ddof<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Find z-score of late_prop_samp</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>z_score <span class="op">=</span> (late_prop_samp <span class="op">-</span> late_prop_hyp)<span class="op">/</span>std_error</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Print z_score</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(z_score)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>          id       country managed_by  fulfill_via vendor_inco_term  \
0    36203.0       Nigeria   PMO - US  Direct Drop              EXW   
1    30998.0      Botswana   PMO - US  Direct Drop              EXW   
2    69871.0       Vietnam   PMO - US  Direct Drop              EXW   
3    17648.0  South Africa   PMO - US  Direct Drop              DDP   
4     5647.0        Uganda   PMO - US  Direct Drop              EXW   
..       ...           ...        ...          ...              ...   
995  13608.0        Uganda   PMO - US  Direct Drop              DDP   
996  80394.0    Congo, DRC   PMO - US  Direct Drop              EXW   
997  61675.0        Zambia   PMO - US  Direct Drop              EXW   
998  39182.0  South Africa   PMO - US  Direct Drop              DDP   
999   5645.0      Botswana   PMO - US  Direct Drop              EXW   

    shipment_mode  late_delivery late product_group    sub_classification  \
0             Air            1.0  Yes          HRDT              HIV test   
1             Air            0.0   No          HRDT              HIV test   
2             Air            0.0   No           ARV                 Adult   
3           Ocean            0.0   No           ARV                 Adult   
4             Air            0.0   No          HRDT  HIV test - Ancillary   
..            ...            ...  ...           ...                   ...   
995           Air            0.0   No           ARV                 Adult   
996           Air            0.0   No          HRDT              HIV test   
997           Air            1.0  Yes          HRDT              HIV test   
998         Ocean            0.0   No           ARV                 Adult   
999           Air            0.0   No          HRDT              HIV test   

     ... line_item_quantity line_item_value pack_price unit_price  \
0    ...             2996.0       266644.00      89.00       0.89   
1    ...               25.0          800.00      32.00       1.60   
2    ...            22925.0       110040.00       4.80       0.08   
3    ...           152535.0       361507.95       2.37       0.04   
4    ...              850.0            8.50       0.01       0.00   
..   ...                ...             ...        ...        ...   
995  ...              121.0         9075.00      75.00       0.62   
996  ...              292.0         9344.00      32.00       1.60   
997  ...             2127.0       170160.00      80.00       0.80   
998  ...           191011.0       861459.61       4.51       0.15   
999  ...              200.0        14398.00      71.99       0.72   

               manufacturing_site first_line_designation  weight_kilograms  \
0         Alere Medical Co., Ltd.                    Yes            1426.0   
1            Trinity Biotech, Plc                    Yes              10.0   
2    Hetero Unit III Hyderabad IN                    Yes            3723.0   
3       Aurobindo Unit III, India                    Yes            7698.0   
4                 Inverness Japan                    Yes              56.0   
..                            ...                    ...               ...   
995     Janssen-Cilag, Latina, IT                    Yes              43.0   
996          Trinity Biotech, Plc                    Yes              99.0   
997       Alere Medical Co., Ltd.                    Yes             881.0   
998     Aurobindo Unit III, India                    Yes           16234.0   
999               Inverness Japan                    Yes              46.0   

     freight_cost_usd  freight_cost_groups  line_item_insurance_usd  
0            33279.83            expensive                   373.83  
1              559.89           reasonable                     1.72  
2            19056.13            expensive                   181.57  
3            11372.23            expensive                   779.41  
4              360.00           reasonable                     0.01  
..                ...                  ...                      ...  
995            199.00           reasonable                    12.72  
996           2162.55           reasonable                    13.10  
997          14019.38            expensive                   210.49  
998          14439.17            expensive                  1421.41  
999           1028.18           reasonable                    23.04  

[1000 rows x 27 columns]
0.061
0.1321627029889662</code></pre>
</div>
</div>
</section>
</section>
<section id="sec-Chapter1.2" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="sec-Chapter1.2"><span class="header-section-number">1.4</span> Chapter 1.2: p-values</h3>
<p>Hypothesis tests are like criminal trials.</p>
<section id="criminal-trials" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="criminal-trials">Criminal trials</h4>
<p>There are two possible true states: the defendant either committed the crime, or didn’t. There are also two possible outcomes: a guilty or not guilty verdict. The initial assumption is that the defendant is not guilty, and the prosecution team must present evidence beyond a reasonable doubt that the defendant committed the crime for a guilty verdict to be given.</p>
</section>
<section id="age-of-first-programming-experience" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="age-of-first-programming-experience">Age of first programming experience</h4>
<p>Let’s return to the Stack Overflow survey. The <code>age_first_code_cut</code> variable classifies when the user began programming. If they were 14 or older, they are classified as adult; otherwise, child. Suppose previous research suggests that 35 percent of software developers programmed as children. This raises a question answerable with our dataset. Does our sample provide evidence that a greater proportion of data scientists started programming as children?</p>
</section>
<section id="definitions" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="definitions">Definitions</h4>
<p>Let’s specify some definitions. A hypothesis is a statement about a population parameter. We don’t know the true value of this population parameter; we can only make inferences about it from the data. Hypothesis tests compare two competing hypotheses. These two hypotheses are the null hypothesis, representing the existing idea, and the alternative hypothesis, representing a new idea that challenges the existing one. They are denoted H-naught and H-A, respectively. Here, the null hypothesis is that the proportion of data scientists that started programming as children follows the research on software developers, at 35 percent. The alternative hypothesis is that the percentage is greater than 35.</p>
<ol type="1">
<li>1 “Naught” is British English for “zero”. For historical reasons, “H-naught” is the international convention for pronouncing the null hypothesis.</li>
</ol>
</section>
<section id="criminal-trials-vs.-hypothesis-testing" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="criminal-trials-vs.-hypothesis-testing">Criminal trials vs.&nbsp;hypothesis testing</h4>
<p>Returning to our criminal trial comparison, the defendant can be either guilty or not guilty, and likewise, only one of the hypotheses can be true. Initially, the defendant is assumed to be not guilty and, similarly, we initially assume that the null hypothesis is true. This only changes if the sample provides enough evidence to reject it. Rather than saying we accept the alternative hypothesis, it is convention to refer to rejecting the null hypothesis, or failing to reject the null hypothesis. If the evidence is “beyond a reasonable doubt” that the defendant committed the crime, then a “guilty” verdict is given. The hypothesis testing equivalent of “beyond a reasonable doubt” is known as the significance level - more on this later in the chapter.</p>
</section>
<section id="one-tailed-and-two-tailed-tests" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="one-tailed-and-two-tailed-tests">One-tailed and two-tailed tests</h4>
<p>The tails of a distribution are the left and right edges of its PDF. Hypothesis tests determine whether the sample statistics lie in the tails of the null distribution, which is the distribution of the statistic if the null hypothesis was true. There are three types of tests, and the phrasing of the alternative hypothesis determines which type we should use. If we are checking for a difference compared to a hypothesized value, we look for extreme values in either tail and perform a two-tailed test. If the alternative hypothesis uses language like “less” or “fewer”, we perform a left-tailed test. Words like “greater” or “exceeds” correspond to a right-tailed test. For the Stack Overflow hypothesis test, we need a right-tailed test since we are looking for extreme values in the right tail.</p>
</section>
<section id="p-values" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="p-values">p-values</h4>
<p>p-values measure the strength of support for the null hypothesis, or in other words, they measure the probability of obtaining a result, assuming the null hypothesis is true. Large p-values mean our statistic is producing a result that is likely not in a tail of our null distribution, and chance could be a good explanation for the result. Small p-values mean our statistic is producing a result likely in the tail of our null distribution. Because p-values are probabilities, they are always between zero and one.</p>
</section>
<section id="calculating-the-z-score" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-the-z-score">Calculating the z-score</h4>
<p>To calculate the p-value, we must first calculate the z-score. We calculate the sample statistic, in this case the proportion of data scientists who started programming as children. The hypothesized value from the null hypothesis is 35 percent. We get the standard error from the standard deviation of the bootstrap distribution, and the z-score is the difference between the proportions, divided by the standard error.</p>
</section>
<section id="calculating-the-p-value" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-the-p-value">Calculating the p-value</h4>
<p>We pass the z-score to the standard normal <code>CDF</code>, <code>norm.cdf</code>, from <code>scipy.stats</code> with the default values of mean 0 and standard deviation of 1. As we’re performing a right-tail test, not a left-tail test, the p-value is calculated by taking one minus the <code>norm.cdf</code> result. The p-value is three out of 100,000.</p>
</section>
</section>
<section id="exercise-1.2.1" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="exercise-1.2.1"><span class="header-section-number">1.5</span> Exercise 1.2.1</h3>
<section id="calculating-p-values" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-p-values">Calculating p-values</h4>
<p>In order to determine whether to choose the null hypothesis or the alternative hypothesis, you need to calculate a p-value from the z-score.</p>
<p>You’ll now return to the late shipments dataset and the proportion of late shipments.</p>
<p>The null hypothesis, <span class="math inline">\(H_o\)</span>, is that the proportion of late shipments is six percent.</p>
<p>The alternative hypothesis, <span class="math inline">\(H_A\)</span>, is that the proportion of late shipments is <strong>greater than</strong> six percent.</p>
</section>
<section id="instructions-2" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-2">Instructions</h4>
<ul>
<li>Calculate the z-score of <code>late_prop_samp</code>.</li>
<li>Calculate the p-value for the z-score, using a right-tailed test.</li>
</ul>
<div id="39e73483" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the proportion of late shipments</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>late_prop_samp <span class="op">=</span> (late_shipments[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed for reproducibility</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of bootstrap samples</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>n_bootstrap_samples <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate bootstrap distribution</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>late_shipments_boot_distn <span class="op">=</span> [</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    (late_shipments.sample(frac<span class="op">=</span><span class="dv">1</span>, replace<span class="op">=</span><span class="va">True</span>)[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_bootstrap_samples)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Hypothesize that the proportion is 6%</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>late_prop_hyp <span class="op">=</span> <span class="fl">0.06</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the standard error</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>std_error <span class="op">=</span> np.std(late_shipments_boot_distn, ddof<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Find z-score of late_prop_samp</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>z_score <span class="op">=</span> (late_prop_samp <span class="op">-</span> late_prop_hyp)<span class="op">/</span>std_error</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the z-score of late_prop_samp</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>z_score <span class="op">=</span> (late_prop_samp <span class="op">-</span> late_prop_hyp)<span class="op">/</span>std_error</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the p-value</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>p_value <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> norm.cdf(z_score, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>                 </span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the p-value</span></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(p_value)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>0.4474278004961735</code></pre>
</div>
</div>
</section>
</section>
<section id="chapter-1.3-statistical-significance" class="level3" data-number="1.6">
<h3 data-number="1.6" class="anchored" data-anchor-id="chapter-1.3-statistical-significance"><span class="header-section-number">1.6</span> Chapter 1.3: Statistical significance</h3>
<p>Last time, we introduced p-values.</p>
<section id="p-value-recap" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="p-value-recap">p-value recap</h4>
<p>p-values quantify how much evidence there is for the null hypothesis. Large p-values indicate a lack of evidence for the alternative hypothesis, sticking with the assumed null hypothesis instead. Small p-values make us doubt this original assumption in favor of the alternative hypothesis. What defines the cutoff point between a small p-value and a large one?</p>
</section>
<section id="significance-level" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="significance-level">Significance level</h4>
<p>The cutoff point is known as the significance level, and is denoted alpha. The appropriate significance level depends on the dataset and the discipline worked in. Five percent is the most common choice, but ten percent and one percent are also popular. The significance level gives us a decision process for which hypothesis to support. If the p-value is less than or equal to alpha, we reject the null hypothesis. Otherwise, we fail to reject it. It’s important that we decide what the appropriate significance level should be before we run our test. Otherwise, there is a temptation to decide on a significance level that lets us choose the hypothesis we want.</p>
</section>
<section id="calculating-the-p-value-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-the-p-value-1">Calculating the p-value</h4>
<p>The workflow starts with setting the significance level, in this case point-zero-five. Next, we calculate the sample mean and assign the hypothesized mean. For the z-score, we also need the standard error, which we obtain from the bootstrap distribution. Then we calculate the z-score using the sample mean, hypothesized mean, and standard error, and use the standard normal CDF to get the p-value.</p>
</section>
<section id="making-a-decision" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="making-a-decision">Making a decision</h4>
<p>In this case, the p-value of three times ten to the minus five is less than or equal to 0.5, so we reject the null hypothesis. We have strong evidence for the alternative hypothesis that the proportion of data scientists that started programming as children is greater than 35 percent.</p>
</section>
<section id="confidence-intervals" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="confidence-intervals">Confidence intervals</h4>
<p>To get a sense of the potential values of the population parameter, it’s common to choose a confidence interval level of one minus the significance level. For a significance level of point-zero-five, we’d use a 95 percent confidence interval. Here’s the calculation using the quantile method. The interval provides a range of plausible values for the population proportion of data scientists that programmed as children.</p>
</section>
<section id="types-of-errors" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="types-of-errors">Types of errors</h4>
<p>Returning to the criminal trial analogy, there are two possible truth states and two possible test outcomes, amounting to four combinations. Two of these indicate that the verdict was correct. If the defendant didn’t commit the crime, but the verdict was guilty, they are wrongfully convicted. If the defendant committed the crime, but the verdict was not guilty, they got away with it. These are both errors in justice. Similarly, for hypothesis testing, there are two ways to get it right, and two types of error. If we support the alternative hypothesis when the null hypothesis was correct, we made a false positive error. If we support the null hypothesis when the alternative hypothesis was correct, we made a false negative error. These errors are sometimes known as type one and type two errors, respectively.</p>
</section>
<section id="possible-errors-in-our-example" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="possible-errors-in-our-example">Possible errors in our example</h4>
<p>In the case of data scientists coding as children, if we had a p-value less than or equal to the significance level, and rejected the null hypothesis, it’s possible we made a false positive error. Although we thought data scientists started coding as children at a higher rate, it may not be true in the whole population. Conversely, if the p-value was greater than the significance level, and we failed to reject the null hypothesis, it’s possible we made a false negative error.</p>
</section>
</section>
<section id="exercise-1.3.1" class="level3" data-number="1.7">
<h3 data-number="1.7" class="anchored" data-anchor-id="exercise-1.3.1"><span class="header-section-number">1.7</span> Exercise 1.3.1</h3>
<section id="calculating-a-confidence-interval" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-a-confidence-interval">Calculating a confidence interval</h4>
<p>If you give a single estimate of a sample statistic, you are bound to be wrong by some amount. For example, the hypothesized proportion of late shipments was 6%. Even if evidence suggests the null hypothesis that the proportion of late shipments is equal to this, for any new sample of shipments, the proportion is likely to be a little different due to sampling variability. Consequently, it’s a good idea to state a confidence interval. That is, you say, “we are 95% ‘confident’ that the proportion of late shipments is between A and B” (for some value of A and B).</p>
<p>Sampling in Python <a href="https://campus.datacamp.com/courses/sampling-in-python/bootstrap-distributions-4?ex=10">demonstrated</a> two methods for calculating confidence intervals. Here, you’ll use quantiles of the bootstrap distribution to calculate the confidence interval.</p>
</section>
<section id="instructions-3" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-3">Instructions</h4>
<ul>
<li>Calculate a 95% confidence interval from <code>late_shipments_boot_distn</code> using the quantile method, labeling the lower and upper intervals <code>lower</code> and <code>upper</code>.</li>
<li>Does the confidence interval match up with the conclusion to stick with the original assumption that 6% is a reasonable value for the unknown population parameter?</li>
</ul>
<p>Yes, since 0.06 is included in the 95% confidence interval and we failed to reject <span class="math inline">\(H_O\)</span> due to a large p-value, the results are similar.</p>
<div id="50aa9e42" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the proportion of late shipments</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>late_prop_samp <span class="op">=</span> (late_shipments[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed for reproducibility</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of bootstrap samples</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>n_bootstrap_samples <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate bootstrap distribution</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>late_shipments_boot_distn <span class="op">=</span> [</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    (late_shipments.sample(frac<span class="op">=</span><span class="dv">1</span>, replace<span class="op">=</span><span class="va">True</span>)[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_bootstrap_samples)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate 95% confidence interval using quantile method</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>lower <span class="op">=</span> np.quantile(late_shipments_boot_distn, <span class="fl">0.025</span>)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>upper <span class="op">=</span> np.quantile(late_shipments_boot_distn, <span class="fl">0.975</span>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the confidence interval</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>((lower, upper))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(0.046, 0.076)</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="sec-Chapter2" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-Chapter2"><span class="header-section-number">2</span> Chapter 2: Two-Sample and ANOVA Tests</h2>
<p>In this chapter, you’ll learn how to test for differences in means between two groups using t-tests and extend this to more than two groups using ANOVA and pairwise t-tests.</p>
<section id="sec-Chapter2.1" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="sec-Chapter2.1"><span class="header-section-number">2.1</span> Chapter 2.1: Performing t-tests</h3>
<p>In the previous chapter, we calculated the z-score, which was a test statistic for a single variable.</p>
<section id="two-sample-problems" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="two-sample-problems">Two-sample problems</h4>
<p>Here, we’ll look at a related problem of comparing sample statistics across groups in a variable. In the Stack Overflow dataset, <code>converted_comp</code> is a numerical variable of annual compensation. <code>age_first_code_cut</code> is a categorical variable with two levels: child and adult, which describe when the user started programming. We can ask questions about differences in compensation across the two age groups, such as, are users who first programmed as a child better compensated than those that started as adults?</p>
</section>
<section id="hypotheses" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="hypotheses">Hypotheses</h4>
<p>The null hypothesis is that the population mean for the two groups is the same, and the alternative hypothesis is that the population mean for users who started coding as children is greater than for users who started coding as adults. We can write these hypotheses using equations. Mu represents an unknown population mean, and we use subscripts to denote which group the population mean belongs to. An alternate way of writing the equations is to compare the differences in population means to zero. Zero here corresponds to our hypothesized value for the difference in means.</p>
</section>
<section id="calculating-groupwise-summary-statistics" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-groupwise-summary-statistics">Calculating groupwise summary statistics</h4>
<p>To calculate summary statistics for each group, we start with the sample, group by the categorical variable, and then compute on the numeric variable. A pandas way of doing this is shown, calculating the mean of the <code>converted_comp</code> column after grouping by <code>age_first_code_cut</code>. Here, the child programmers have a mean compensation of 132,000 dollars compared to around 111,000 for adult programmers. Is that increase statistically significant or could it be explained by sampling variability?</p>
</section>
<section id="test-statistics" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="test-statistics">Test statistics</h4>
<p>Although we don’t know the population mean, we estimate it using the sample mean. x-bar is used to denote a sample mean. Then we use subscripts to denote which group a sample mean corresponds to. The difference between these two sample means is the test statistic for the hypothesis test. The z-scores we saw in Chapter 1 are a type of standardized test statistic.</p>
</section>
<section id="standardizing-the-test-statistic" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="standardizing-the-test-statistic">Standardizing the test statistic</h4>
<p>z-scores are calculated by taking the sample statistic, subtracting the mean of this statistic as the population parameter of interest, then dividing by the standard error. In the two sample case, the test statistic, denoted t, uses a similar equation. We take the difference between the sample statistics for the two groups, subtract the population difference between the two groups, then divide by the standard error.</p>
</section>
<section id="standard-error-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="standard-error-1">Standard error</h4>
<p>To calculate the standard error, needed for the denominator of the test statistic equation, bootstrapping tends to be a good option. However, there is an easier way to approximate it. We calculate the standard deviation of the numeric variable for each group in the sample, and the number of observations in each group. Then enter those values into the equation and compute the result.</p>
</section>
<section id="assuming-the-null-hypothesis-is-true" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="assuming-the-null-hypothesis-is-true">Assuming the null hypothesis is true</h4>
<p>Here’s the test statistic equation again. If we assume that the null hypothesis is true, there’s a simplification we can make. The null hypothesis assumes that the population means are equal, and their difference is zero, so the population term in the numerator disappears. Inserting the approximation for the standard error, we now have a way of calculating the test statistic using only calculations on the sample dataset.</p>
</section>
<section id="calculations-assuming-the-null-hypothesis-is-true" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculations-assuming-the-null-hypothesis-is-true">Calculations assuming the null hypothesis is true</h4>
<p>We need the mean, standard deviation, and number of observations for each group to fill in the formula for t. We again use <code>groupby</code> and method combinations with <code>mean</code>, <code>std</code>, and <code>count</code>.</p>
</section>
<section id="calculating-the-test-statistic" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-the-test-statistic">Calculating the test statistic</h4>
<p>Assigning the values to six different variables, the numerator is a subtraction of the sample means, and the denominator is like a weighted hypotenuse. The t-statistic is around 1.78. Just as with z-scores, we can’t draw any conclusions yet; for that, we’ll need to wait for the next unit.</p>
</section>
</section>
<section id="exercise-2.1.1" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="exercise-2.1.1"><span class="header-section-number">2.2</span> Exercise 2.1.1</h3>
<section id="two-sample-mean-test-statistic" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="two-sample-mean-test-statistic">Two sample mean test statistic</h4>
<p>The hypothesis test for determining if there is a difference between the means of two populations uses a different type of test statistic to the z-scores you saw in Chapter 1. It’s called “t”, and it can be calculated from three values from each sample using this equation.</p>
<p><span class="math display">\[
t = \frac{\bar{x}_{child} - \bar{x}_{adult}}{\sqrt{\frac{s_{child}^2}{n_{child}} + \frac{s_{adult}^2}{n_{adult}}}}
\]</span></p>
<p>While trying to determine why some shipments are late, you may wonder if the weight of the shipments that were on time is less than the weight of the shipments that were late. The <code>late_shipments</code> dataset has been split into a “yes” group, where <code>late == "Yes"</code> and a “no” group where <code>late == "No"</code>. The weight of the shipment is given in the <code>weight_kilograms</code> variable.</p>
</section>
<section id="instructions-4" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-4">Instructions</h4>
<ul>
<li>Calculate the numerator of the <span class="math inline">\(t\)</span> test statistic.</li>
<li>Calculate the denominator of the <span class="math inline">\(t\)</span> test statistic.</li>
<li>Use those two numbers to calculate the <span class="math inline">\(t\)</span> test statistic.</li>
</ul>
<div id="0094c199" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>xbar <span class="op">=</span> late_shipments.groupby(<span class="st">"late"</span>)[<span class="st">"weight_kilograms"</span>].mean()</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> late_shipments.groupby(<span class="st">"late"</span>)[<span class="st">"weight_kilograms"</span>].std()</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> late_shipments.groupby(<span class="st">"late"</span>)[<span class="st">"weight_kilograms"</span>].count()</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co"># The mean weight for both category in the 'late' column</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>xbar_no <span class="op">=</span> xbar.get(<span class="st">'No'</span>)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>xbar_yes <span class="op">=</span> xbar.get(<span class="st">'Yes'</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co"># The standard deviation weight for both category in the 'late' column</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>s_no <span class="op">=</span> s.get(<span class="st">'No'</span>)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>s_yes <span class="op">=</span> s.get(<span class="st">'Yes'</span>)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="co"># The sample size for both category in the 'late' column</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>n_no <span class="op">=</span> n.get(<span class="st">'No'</span>)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>n_yes <span class="op">=</span> n.get(<span class="st">'Yes'</span>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the numerator of the test statistic</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>numerator <span class="op">=</span> xbar_yes <span class="op">-</span> xbar_no</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the denominator of the test statistic</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>denominator <span class="op">=</span> np.sqrt(s_no <span class="op">**</span> <span class="dv">2</span><span class="op">/</span>n_no <span class="op">+</span> s_yes <span class="op">**</span> <span class="dv">2</span><span class="op">/</span>n_yes)</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the test statistic</span></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>t_stat <span class="op">=</span> numerator<span class="op">/</span>denominator</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the test statistic</span></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t_stat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>2.3936661778766433</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><em>When testing for differences between means, the test statistic is called ‘t’ rather than ‘z’, and can be calculated using six numbers from the samples. Here, the value is about -2.39 or 2.39, depending on the order you calculated the numerator.</em></p>
</div>
</div>
</div>
</section>
</section>
<section id="sec-Chapter2.2" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="sec-Chapter2.2"><span class="header-section-number">2.3</span> Chapter 2.2: Calculating p-values from t-statistics</h3>
<p>In the <a href="#sec-Chapter2.1" class="quarto-xref">Section&nbsp;2.1</a>, we calculated the test statistic t.</p>
<section id="t-distributions" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="t-distributions">t-distributions</h4>
<p>The test statistic, t, follows a t-distribution. t-distributions have a parameter called the degrees of freedom, or df for short. Here’s a line plot of the PDF of a t-distribution with one degree of freedom in yellow, and the PDF of a normal distribution in blue dashes. Notice that the t-distribution for small degrees of freedom has fatter tails than the normal distribution, but otherwise they look similar.</p>
</section>
<section id="degrees-of-freedom" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="degrees-of-freedom">Degrees of freedom</h4>
<p>As we increase the degrees of freedom, the t-distribution gets closer to the normal distribution. In fact, a normal distribution is a t-distribution with infinite degrees of freedom. Degrees of freedom are defined as the maximum number of logically independent values in the data sample. That’s a fairly tricky concept, so let’s try an example.</p>
</section>
<section id="calculating-degrees-of-freedom" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-degrees-of-freedom">Calculating degrees of freedom</h4>
<p>Suppose our dataset has 5 independent observations, and that four of the values are 2, 6, 8, and 5. Suppose we also know the sample mean is 5. With this knowledge, the fifth value is no longer independent; it must be 4. Even though all five observations in the sample were independent, because we know an additional fact about the sample - that is has a mean of 5 - we only have 4 degrees of freedom. In our two sample case, there are as many degrees of freedom as observations, minus two because we know two sample statistics, the means for each group.</p>
</section>
<section id="hypotheses-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="hypotheses-1">Hypotheses</h4>
<p>Recall the hypotheses for our Stack Overflow question about compensation for the two age groups. Since this is a “greater than” alternative hypothesis, we need a right-tailed test.</p>
</section>
<section id="significance-level-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="significance-level-1">Significance level</h4>
<p>We’re going to calculate a p-value in a moment, but we first need to decide on a significance level. There are several possibilities; let’s use point-one. That means that we reject the null hypothesis in favor of the alternative if the p-value is less-than-or-equal-to point-one.</p>
</section>
<section id="calculating-p-values-one-proportion-vs.-a-value" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-p-values-one-proportion-vs.-a-value">Calculating p-values: one proportion vs.&nbsp;a value</h4>
<p>In <a href="#sec-Chapter1.2" class="quarto-xref">Section&nbsp;1.4</a> , to get the p-value, we transformed the z-score with the normal CDF. Since it was a right-tailed test, we subtracted the result from one. In the previous video, we used an approximation for the test statistic standard error using sample information. Using this approximation adds more uncertainty and that’s why this is a t instead of a z problem. The t distribution allows for more uncertainty when using multiple estimates in a single statistic calculation. Here, the multiple estimates correspond to the sample mean and the sample standard deviation.</p>
</section>
<section id="calculating-p-values-two-means-from-different-groups" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-p-values-two-means-from-different-groups">Calculating p-values: two means from different groups</h4>
<p>Now we are calculating means rather than proportions, the z-score is replaced with a t test statistic. This is the value calculated in the previous video. The calculation also needs the degrees of freedom, which is the total number of observations in both groups, minus two.</p>
<p>To calculate the p-value, we need to transform the test statistic using the t-distribution CDF instead of the normal distribution CDF. Notice the use of <code>t.cdf</code> instead of <code>norm.cdf</code>, and that the <code>df</code> argument is set to the degrees of freedom. This p-value is less than the significance level of <code>0.1</code>, so we should reject the null hypothesis in favor of the alternative hypothesis that Stack Overflow data scientists who started coding as children earn more.</p>
</section>
</section>
<section id="exercise-2.2.1" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="exercise-2.2.1"><span class="header-section-number">2.4</span> Exercise 2.2.1</h3>
<section id="from-t-to-p" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="from-t-to-p">From t to p</h4>
<p>Previously, you calculated the test statistic for the two-sample problem of whether the mean weight of shipments is smaller for shipments that weren’t late (<code>late == "No"</code>) compared to shipments that were late (<code>late == "Yes"</code>). In order to make decisions about it, you need to transform the test statistic with a cumulative distribution function to get a p-value.</p>
<p>Recall the hypotheses:</p>
<p><span class="math inline">\(H_o\)</span>: The mean weight of shipments that weren’t late is the same as the mean weight of shipments that were late.</p>
<p><span class="math inline">\(H_A\)</span>: The mean weight of shipments that weren’t late is less than the mean weight of shipments that were late.</p>
<p>Use a significance level of <code>alpha = 0.05</code>.</p>
</section>
<section id="instructions-5" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-5">Instructions</h4>
<ul>
<li>What type of test does the alternative hypothesis indicate that we need? **<em>Left-tailed</em></li>
<li>Calculate the degrees of freedom for the test.</li>
<li>Compute the p-value using the test statistic, <code>t_stat</code>.</li>
<li>What decision should you make based on the results of the hypothesis test? **<em>Reject the null hypothesis.</em></li>
</ul>
<div id="28df740f" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> t</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>xbar <span class="op">=</span> late_shipments.groupby(<span class="st">"late"</span>)[<span class="st">"weight_kilograms"</span>].mean()</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> late_shipments.groupby(<span class="st">"late"</span>)[<span class="st">"weight_kilograms"</span>].std()</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> late_shipments.groupby(<span class="st">"late"</span>)[<span class="st">"weight_kilograms"</span>].count()</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co"># The mean weight for both category in the 'late' column</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>xbar_no <span class="op">=</span> xbar.get(<span class="st">'No'</span>)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>xbar_yes <span class="op">=</span> xbar.get(<span class="st">'Yes'</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="co"># The standard deviation weight for both category in the 'late' column</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>s_no <span class="op">=</span> s.get(<span class="st">'No'</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>s_yes <span class="op">=</span> s.get(<span class="st">'Yes'</span>)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="co"># The sample size for both category in the 'late' column</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>n_no <span class="op">=</span> n.get(<span class="st">'No'</span>)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>n_yes <span class="op">=</span> n.get(<span class="st">'Yes'</span>)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the numerator of the test statistic</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>numerator <span class="op">=</span> xbar_no <span class="op">-</span> xbar_yes</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the denominator of the test statistic</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>denominator <span class="op">=</span> np.sqrt(s_no <span class="op">**</span> <span class="dv">2</span><span class="op">/</span>n_no <span class="op">+</span> s_yes <span class="op">**</span> <span class="dv">2</span><span class="op">/</span>n_yes)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the test statistic</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>t_stat <span class="op">=</span> numerator<span class="op">/</span>denominator</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the degrees of freedom</span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>degrees_of_freedom <span class="op">=</span> n_no <span class="op">+</span> n_yes <span class="op">-</span> <span class="dv">2</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the p-value from the test stat</span></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>p_value <span class="op">=</span> t.cdf(t_stat, df <span class="op">=</span> degrees_of_freedom)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the p_value</span></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(p_value)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>0.008432382146249523</code></pre>
</div>
</div>
</section>
</section>
<section id="sec-Chapter2.3" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="sec-Chapter2.3"><span class="header-section-number">2.5</span> Chapter 2.3: Paired t-tests</h3>
<p>Previously, we used the t-distribution to compute a p-value from a standardized test statistic related to the difference in means across two groups.</p>
<section id="us-republican-presidents-dataset" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="us-republican-presidents-dataset">US Republican presidents dataset</h4>
<p>Here’s a dataset of US presidential elections. Each row represents a presidential election at the county level. The variables in the dataset are the US state, the county within that state, and the percentage of votes for the Republican candidate in 2008, and in 2012.</p>
<ol type="1">
<li>1 <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ">https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ</a></li>
</ol>
</section>
<section id="hypotheses-2" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="hypotheses-2">Hypotheses</h4>
<p>One question is whether the percentage of votes for the Republican candidate was lower in 2008 compared to 2012. To test this, we form hypotheses. As before, the null hypothesis is that our hunch is wrong, and that the population parameters are the same in each year group. The alternative hypothesis is that the parameter in 2008 was lower than in 2012. Let’s set a significance level of point-zero-five. One feature of this dataset is that the 2008 votes and the 2012 votes are paired, which means they aren’t independent, since they both refer to the same county. This means voting patterns may occur due to county-level demographics and local politics, and we want to capture this pairing in our model.</p>
</section>
<section id="from-two-samples-to-one" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="from-two-samples-to-one">From two samples to one</h4>
<p>For paired analyses, rather than considering the two variables separately, we can consider a single variable of the difference. This is stored in a DataFrame called <code>sample_data</code> with a column named <code>diff</code>. In this histogram of the difference, most values are between minus ten and ten, with at least one outlier.</p>
</section>
<section id="calculate-sample-statistics-of-the-difference" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculate-sample-statistics-of-the-difference">Calculate sample statistics of the difference</h4>
<p>The sample mean, x-bar, is calculated from this difference. It is around minus two-point-eight-eight.</p>
</section>
<section id="revised-hypotheses" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="revised-hypotheses">Revised hypotheses</h4>
<p>We can restate the hypotheses in terms of the single population mean, mu-diff, being equal to or less than zero. The test statistic, <code>t</code>, has a slightly simpler equation compared to the two sample case. We have one statistic, so the number of degrees of freedom is the number of pairs minus one.</p>
</section>
<section id="calculating-the-p-value-2" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-the-p-value-2">Calculating the p-value</h4>
<p>To calculate the test statistic, we need the number of rows in the dataset, one hundred, and the standard deviation of the differences. We already calculated x-bar-diff, the mean of the differences, as minus two-point-eight-eight. Assuming the null hypothesis is true means mu-diff is zero. We now have everything we need to plug into the equation to calculate t. It’s minus five-point-six. The degrees of freedom are one less than n-diff at ninety nine. Finally, we transform <code>t</code> with the t-distribution CDF. The <code>p-value</code> is really small at around nine-point-six times ten to the minus eight. That means we reject the null hypothesis in favor of the alternative hypothesis that the Republican candidates got a smaller percentage of the vote in 2008 compared to 2012.</p>
</section>
<section id="testing-differences-between-two-means-using-ttest" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="testing-differences-between-two-means-using-ttest">Testing differences between two means using <code>ttest()</code></h4>
<p>That was a lot of calculating. Fortunately, there’s an easier way. The <code>pingouin</code> package provides a variety of different methods for hypothesis testing and returns the results as a pandas DataFrame. Its output can be a little friendlier to work with than similar methods from <code>scipy.stats</code>. One method from <code>pingouin</code> is <code>ttest</code> and it works with array-like objects, so the first argument is the Series of differences. For a converted one sample test like this, <code>y</code> specifies the hypothesized difference value from the null hypothesis, which is zero. The type of alternative hypothesis can be specified as two-sided, less, or greater, corresponding to two-tailed, left-tailed, and right-tailed tests, respectively. Here’s the output. We can recognize the value of the test statistic, the degrees of freedom, the alternative direction, and the p-value. The additional output refers to more advanced statistical concepts that are outside the scope of this course.</p>
<ol type="1">
<li>1 Details on Returns from <code>pingouin.ttest()</code> are available in the API docs for pingouin at <a href="https://pingouin-stats.org/generated/pingouin.ttest.html#pingouin.ttest.">https://pingouin-stats.org/generated/pingouin.ttest.html#pingouin.ttest</a></li>
</ol>
</section>
<section id="ttest-with-pairedtrue" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="ttest-with-pairedtrue"><code>ttest()</code> with <code>paired=True</code></h4>
<p>There’s a variation of <code>ttest</code> for paired data that requires even less work. Rather than calculating the difference between the two paired variables, we can just pass them both directly to <code>ttest</code> as <code>x</code> and <code>y</code>, and set <code>paired</code> to <code>True</code>. Notice that the results in the first four columns are the same as before.</p>
</section>
<section id="unpaired-ttest" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="unpaired-ttest">Unpaired <code>ttest()</code></h4>
<p>If we don’t set paired to True and instead perform an unpaired t-test, then the numbers change. The test statistic is closer to zero, there are more degrees of freedom, and the p-value is much larger. Performing an unpaired t-test when our data is paired increases the chances of false negative errors.</p>
</section>
</section>
<section id="exercise-2.3.1" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="exercise-2.3.1"><span class="header-section-number">2.6</span> Exercise 2.3.1</h3>
<section id="visualizing-the-difference" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="visualizing-the-difference">Visualizing the difference</h4>
<p>Before you start running hypothesis tests, it’s a great idea to perform some exploratory data analysis; that is, calculating summary statistics and visualizing distributions.</p>
<p>Here, you’ll look at the proportion of county-level votes for the Democratic candidate in 2012 and 2016, <code>sample_dem_data</code>. Since the counties are the same in both years, these samples are paired. The columns containing the samples are <code>dem_percent_12</code> and <code>dem_percent_16</code>.</p>
</section>
<section id="instructions-6" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-6">Instructions</h4>
<ol type="1">
<li>Create a new <code>diff</code> column containing the percentage of votes for the democratic candidate in 2012 minus the percentage of votes for the democratic candidate in 2016.</li>
<li>Calculate the mean of the <code>diff</code> column as <code>xbar_diff</code>.</li>
<li>Calculate the standard deviation of the <code>diff</code> column as <code>s_diff</code>.</li>
<li>Plot a histogram of the <code>diff</code> column with 20 bins.</li>
</ol>
<div id="812011b2" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> t</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>sample_dem_data <span class="op">=</span> pd.read_feather(<span class="st">'datasets/dem_votes_potus_12_16.feather'</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the differences from 2012 to 2016</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>sample_dem_data[<span class="st">'diff'</span>] <span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_12'</span>] <span class="op">-</span> sample_dem_data[<span class="st">'dem_percent_16'</span>]</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Print sample_dem_data</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sample_dem_data)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the mean of the diff column</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>xbar_diff <span class="op">=</span> sample_dem_data[<span class="st">'diff'</span>].mean()</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Print xbar_diff</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(xbar_diff)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the standard deviation of the diff column</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>s_diff <span class="op">=</span> sample_dem_data[<span class="st">'diff'</span>].std()</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Print s_diff</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s_diff)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot a histogram of diff with 20 bins</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>sample_dem_data[<span class="st">'diff'</span>].hist(bins<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       state       county  dem_percent_12  dem_percent_16       diff
0    Alabama      Bullock       76.305900       74.946921   1.358979
1    Alabama      Chilton       19.453671       15.847352   3.606319
2    Alabama         Clay       26.673672       18.674517   7.999155
3    Alabama      Cullman       14.661752       10.028252   4.633500
4    Alabama     Escambia       36.915731       31.020546   5.895185
..       ...          ...             ...             ...        ...
495  Wyoming        Uinta       19.065464       14.191263   4.874201
496  Wyoming     Washakie       20.131846       13.948610   6.183235
497   Alaska   District 3       33.514582       16.301064  17.213518
498   Alaska  District 18       61.284271       52.810051   8.474220
499   Alaska  District 24       42.913980       39.405286   3.508694

[500 rows x 5 columns]
6.829312660106834
5.040139140132317</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-8-output-2.png" width="566" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="exercise-2.3.2" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="exercise-2.3.2"><span class="header-section-number">2.7</span> Exercise 2.3.2</h3>
<section id="using-ttest" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="using-ttest">Using <code>ttest()</code></h4>
<p>Manually calculating test statistics and transforming them with a CDF to get a p-value is a lot of effort to compare two sample means. The comparison of two sample means is called a t-test, and the <code>pingouin</code> Python package has a <code>.ttest()</code> method to accomplish it. This method provides some flexibility in how you perform the test.</p>
<p>As in the previous exercise, you’ll explore the difference between the proportion of county-level votes for the Democratic candidate in 2012 and 2016 to identify if the difference is significant. The hypotheses are as follows:</p>
<p><span class="math inline">\(H_o\)</span>: The proportion of democratic votes in 2012 and 2016 were the same. <span class="math inline">\(H_A\)</span>: The proportion of democratic votes in 2012 and 2016 were different.</p>
</section>
<section id="instructions-7" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-7">Instructions</h4>
<ol type="1">
<li>Conduct a t-test on the sample differences (the diff column of <code>sample_dem_data</code>), using an appropriate alternative hypothesis chosen from <code>"two-sided"</code>, <code>"less"</code>, and <code>"greater"</code>.</li>
</ol>
<div id="ff3f025b" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>sample_dem_data <span class="op">=</span> pd.read_feather(<span class="st">'datasets/dem_votes_potus_12_16.feather'</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the differences from 2012 to 2016</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>sample_dem_data[<span class="st">'diff'</span>] <span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_12'</span>] <span class="op">-</span> sample_dem_data[<span class="st">'dem_percent_16'</span>]</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Conduct a t-test on diff</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>test_results <span class="op">=</span> pingouin.ttest(x<span class="op">=</span>sample_dem_data[<span class="st">'diff'</span>],</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span><span class="dv">0</span>, alternative<span class="op">=</span><span class="st">'two-sided'</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>                         </span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the test results</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                T  dof alternative          p-val         CI95%   cohen-d  \
T-test  30.298384  499   two-sided  3.600634e-115  [6.39, 7.27]  1.354985   

              BF10  power  
T-test  2.246e+111    1.0  </code></pre>
</div>
</div>
<ol start="2" type="1">
<li>What’s the correct decision from the t-test, assuming <span class="math inline">\(\alpha = 0.01\)</span> ?</li>
</ol>
<p><strong>Answer</strong></p>
<p><em>Reject the null hypothesis</em>.</p>
<ol start="3" type="1">
<li>Conduct a paired test on the democratic votes in 2012 and 2016 (the <code>dem_percent_12</code> and <code>dem_percent_16</code> columns of <code>sample_dem_data</code>), using an appropriate alternative hypothesis.</li>
</ol>
<div id="aafe4603" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>sample_dem_data <span class="op">=</span> pd.read_feather(<span class="st">'datasets/dem_votes_potus_12_16.feather'</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the differences from 2012 to 2016</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>sample_dem_data[<span class="st">'diff'</span>] <span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_12'</span>] <span class="op">-</span> sample_dem_data[<span class="st">'dem_percent_16'</span>]</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Conduct a paired t-test on dem_percent_12 and dem_percent_16</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>paired_test_results <span class="op">=</span> pingouin.ttest(x<span class="op">=</span>sample_dem_data[<span class="st">'dem_percent_12'</span>],</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>sample_dem_data[<span class="st">'dem_percent_16'</span>], paired <span class="op">=</span> <span class="va">True</span>, alternative<span class="op">=</span><span class="st">'two-sided'</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>                              </span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the paired test results</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(paired_test_results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                T  dof alternative          p-val         CI95%   cohen-d  \
T-test  30.298384  499   two-sided  3.600634e-115  [6.39, 7.27]  0.454202   

              BF10  power  
T-test  2.246e+111    1.0  </code></pre>
</div>
</div>
<ol start="4" type="1">
<li>Compare the paired t-test to an (inappropriate) unpaired test on the same data. How does the p-value change?</li>
</ol>
<pre><code>pingouin.ttest(x=sample_dem_data['dem_percent_12'], 
               y=sample_dem_data['dem_percent_16'], 
               alternative="two-sided")</code></pre>
<p><strong>Answer</strong></p>
<p><em>The p-value from the unpaired test is greater than than the p-value from the paired test. When you have paired data, a paired t-test is preferable to the unpaired version because it reduces the chance of a false negative error.</em></p>
<div id="d9758dda" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>sample_dem_data <span class="op">=</span> pd.read_feather(<span class="st">'datasets/dem_votes_potus_12_16.feather'</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>unpaired_test <span class="op">=</span> pingouin.ttest(x<span class="op">=</span>sample_dem_data[<span class="st">'dem_percent_12'</span>], </span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>               y<span class="op">=</span>sample_dem_data[<span class="st">'dem_percent_16'</span>], paired <span class="op">=</span> <span class="va">False</span>, </span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>               alternative<span class="op">=</span><span class="st">"two-sided"</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(unpaired_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>               T  dof alternative         p-val        CI95%   cohen-d  \
T-test  7.181565  998   two-sided  1.345737e-12  [4.96, 8.7]  0.454202   

             BF10  power  
T-test  4.308e+09    1.0  </code></pre>
</div>
</div>
</section>
</section>
<section id="sec-Chapter2.4" class="level3" data-number="2.8">
<h3 data-number="2.8" class="anchored" data-anchor-id="sec-Chapter2.4"><span class="header-section-number">2.8</span> Chapter 2.4: ANOVA tests</h3>
<p>We’ve seen how to compare two groups in the unpaired and paired cases. But what if there are more than two groups?</p>
<section id="job-satisfaction-5-categories" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="job-satisfaction-5-categories">Job satisfaction: 5 categories</h4>
<p>The Stack Overflow survey includes a job satisfaction variable, with five categories from <code>"Very satisfied"</code> down to <code>"Very dissatisfied"</code>.</p>
</section>
<section id="visualizing-multiple-distributions" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="visualizing-multiple-distributions">Visualizing multiple distributions</h4>
<p>Suppose we want to know if mean annual compensation is different for each of the levels of job satisfaction. The first thing to do is visualize the distributions with box plots. Seaborn’s boxplot method provides a nice option here with <code>converted_comp</code> on the horizontal axis and <code>job_sat</code> on the vertical axis using the <code>stack_overflow</code> data. “Very satisfied” looks slightly higher than the others, but to see if they are significantly different, we’ll need to use hypothesis tests.</p>
</section>
<section id="analysis-of-variance-anova" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="analysis-of-variance-anova">Analysis of variance (ANOVA)</h4>
<p>ANOVA tests determine whether there are differences between the groups. We begin by setting our significance level to point-two. This value is larger than in many situations but will help us understand the implications on comparing different numbers of groups later on. We use the <code>pingouin anova</code> method to compare values across multiple groups. We specify the data as <code>stack_overflow</code>, the dependent variable,<code>dv</code>, as <code>converted_comp</code>, and the column of groups to calculate between as <code>job_sat</code>. The p-value is stored in the <code>p-unc</code> column, which is point-zero-zero-one-three, which is smaller than alpha at 20 percent. That means that at least two of the categories of job satisfaction have significant differences between their compensation levels, but this doesn’t tell us which two categories they are.</p>
</section>
<section id="pairwise-tests" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="pairwise-tests">Pairwise tests</h4>
<p>To identify which categories are different, we compare all five job satisfaction categories, testing on each pair in turn. There are ten ways of choosing two items from a set of five, so we have ten tests to perform. Our significance level is still point-two.</p>
<p>To run all these hypothesis tests in one go, we can use <code>pairwise_tests</code>. The first three arguments of data, <code>dv</code>, and between are the same as the <code>anova</code> method. We’ll discuss p-adjust shortly. The result shows a DataFrame where A and B are the two levels being compared on each row. Next, we look at the <code>p-unc</code> column of p-values. Three of these are less than our significance level of point-two.</p>
</section>
<section id="as-the-number-of-groups-increases" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="as-the-number-of-groups-increases">As the number of groups increases…</h4>
<p>In this case we have five groups, resulting in ten pairs. As the number of groups increases, the number of pairs - and hence the number of hypothesis tests we must perform - increases quadratically. The more tests we run, the higher the chance that at least one of them will give a false positive significant result. With a significance level of point-two, if we run one test, the chance of a false positive result is point-two. With five groups and ten tests, the probability of at least one false positive is around point-seven. With twenty groups, it’s almost guaranteed that we’ll get at least one false positive.</p>
</section>
<section id="bonferroni-correction" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="bonferroni-correction">Bonferroni correction</h4>
<p>The solution to this is to apply an adjustment to increase the p-values, reducing the chance of getting a false positive. One common adjustment is the Bonferroni correction. Looking at the <code>p-corr</code> column corresponding to corrected p-values, as opposed to the <code>p-unc</code> column for <code>uncorrected</code>, only two of the pairs appear to have significant differences.</p>
</section>
<section id="more-methods" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="more-methods">More methods</h4>
<p><code>pingouin</code> provides several options for adjusting the p-values with some being more conservative than others. No adjustment with none is the default, but in almost all pairwise t-testing situations choosing a correction method is more appropriate.</p>
</section>
</section>
<section id="exercise-2.4.1" class="level3" data-number="2.9">
<h3 data-number="2.9" class="anchored" data-anchor-id="exercise-2.4.1"><span class="header-section-number">2.9</span> Exercise 2.4.1</h3>
<section id="visualizing-many-categories" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="visualizing-many-categories">Visualizing many categories</h4>
<p>So far in this chapter, we’ve only considered the case of differences in a numeric variable between two categories. Of course, many datasets contain more categories. Before you get to conducting tests on many categories, it’s often helpful to perform exploratory data analysis (EDA), calculating summary statistics for each group and visualizing the distributions of the numeric variable for each category using box plots.</p>
<p>Here, we’ll return to the late shipments data, and how the price of each package (<code>pack_price</code>) varies between the three shipment modes (<code>shipment_mode</code>): <code>"Air"</code>, <code>"Air Charter"</code>, and <code>"Ocean"</code>.</p>
</section>
<section id="instructions-8" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-8">Instructions</h4>
<ol type="1">
<li>Group <code>late_shipments</code> by <code>shipment_mode</code> and calculate the mean <code>pack_price</code> for each group, storing the result in <code>xbar_pack_by_mode</code>.</li>
<li>Group <code>late_shipments</code> by <code>shipment_mode</code> and calculate the standard deviation <code>pack_price</code> for each group, storing the result in <code>s_pack_by_mode</code>.</li>
<li>Create a boxplot from <code>late_shipments</code> with <code>"pack_price"</code> as <code>x</code> and <code>"shipment_mode"</code> as <code>y</code>.</li>
</ol>
<div id="d46e06ef" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the mean pack_price for each shipment_mode</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>xbar_pack_by_mode <span class="op">=</span> late_shipments.groupby(<span class="st">'shipment_mode'</span>)[<span class="st">'pack_price'</span>].mean()</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the grouped means</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(xbar_pack_by_mode)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the standard deviation of the pack_price for each shipment_mode</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>s_pack_by_mode <span class="op">=</span> late_shipments.groupby(<span class="st">"shipment_mode"</span>)[<span class="st">'pack_price'</span>].std()</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the grouped standard deviations</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s_pack_by_mode)</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Boxplot of shipment_mode vs. pack_price</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>sns.boxplot(x<span class="op">=</span><span class="st">"pack_price"</span>, y<span class="op">=</span><span class="st">"shipment_mode"</span>, data<span class="op">=</span>late_shipments)</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>shipment_mode
Air            39.712395
Air Charter     4.226667
Ocean           6.432273
Name: pack_price, dtype: float64
shipment_mode
Air            48.932861
Air Charter     0.992969
Ocean           5.303047
Name: pack_price, dtype: float64</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-12-output-2.png" width="641" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p><em>There certainly looks to be a difference in the pack price between each of the three shipment modes. Do you think the differences are statistically significant?</em></p>
</section>
</section>
<section id="exercise-2.4.2" class="level3" data-number="2.10">
<h3 data-number="2.10" class="anchored" data-anchor-id="exercise-2.4.2"><span class="header-section-number">2.10</span> Exercise 2.4.2</h3>
<section id="conducting-an-anova-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="conducting-an-anova-test">Conducting an ANOVA test</h4>
<p>The box plots made it look like the distribution of pack price was different for each of the three shipment modes. However, it didn’t tell us whether the mean pack price was different in each category. To determine that, we can use an ANOVA test. The null and alternative hypotheses can be written as follows.</p>
<p><span class="math inline">\(H_O\)</span>: Pack prices for every category of shipment mode are the same.</p>
<p><span class="math inline">\(H_A\)</span>: Pack prices for some categories of shipment mode are different.</p>
<p>Use a significance level of 0.1.</p>
</section>
<section id="instructions-9" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-9">Instructions</h4>
<ol type="1">
<li>Run an ANOVA on <code>late_shipments</code> investigating <code>'pack_price'</code> (the dependent variable) between the groups of <code>'shipment_mode'</code></li>
</ol>
<div id="523b3e25" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Run an ANOVA for pack_price across shipment_mode</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>anova_results <span class="op">=</span> pingouin.anova(data<span class="op">=</span>late_shipments, dv<span class="op">=</span><span class="st">'pack_price'</span>, between <span class="op">=</span> <span class="st">'shipment_mode'</span>)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Print anova_results</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(anova_results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>          Source  ddof1  ddof2        F         p-unc       np2
0  shipment_mode      2    997  21.8646  5.089479e-10  0.042018</code></pre>
</div>
</div>
<ol start="2" type="1">
<li>Assuming a significance level of 0.1, should you reject the null hypothesis that there is no difference in pack prices between shipment modes?</li>
</ol>
<p><em>Yes. The p-value is less than or equal to the significance level, so the null hypothesis should be rejected. There is a significant difference in pack prices between the shipment modes. However, we don’t know which shipment modes this applies to.</em></p>
</section>
</section>
<section id="exercise-2.4.3" class="level3" data-number="2.11">
<h3 data-number="2.11" class="anchored" data-anchor-id="exercise-2.4.3"><span class="header-section-number">2.11</span> Exercise 2.4.3</h3>
<section id="pairwise-t-tests" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="pairwise-t-tests">Pairwise t-tests</h4>
<p>The ANOVA test didn’t tell you which categories of shipment mode had significant differences in pack prices. To pinpoint which categories had differences, you could instead use pairwise t-tests.</p>
</section>
<section id="instructions-10" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-10">Instructions</h4>
<ol type="1">
<li>Perform pairwise t-tests on <code>late_shipments</code>’s <code>pack_price</code> variable, grouped by <code>shipment_mode</code>, without doing any p-value adjustment.</li>
<li>Modify the pairwise t-tests to use the Bonferroni p-value adjustment and stored it as <code>modify_pairwise_results</code></li>
<li>Using the Bonferroni correction results and assuming a significance level of 0.1, for which pairs of shipment modes should you reject the null hypothesis that the pack prices are equal?</li>
</ol>
<p><em>“Ocean” and “Air Charter”; “Ocean” and “Air”; “Air Charter” and “Air”. After applying the Bonferroni adjustment, the p-values for the t-tests between each of the three groups are all less than 0.1.</em></p>
<div id="2c6946b7" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform a pairwise t-test on pack price, grouped by shipment mode</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>pairwise_results <span class="op">=</span> pingouin.pairwise_tests(data<span class="op">=</span>late_shipments, dv<span class="op">=</span><span class="st">'pack_price'</span>, between <span class="op">=</span> <span class="st">'shipment_mode'</span>, padjust<span class="op">=</span><span class="st">'none'</span>)  </span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Print pairwise_results</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pairwise_results)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Modify the pairwise t-tests to use Bonferroni p-value adjustment</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>modify_pairwise_results <span class="op">=</span> pingouin.pairwise_tests(data<span class="op">=</span>late_shipments, </span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>                                           dv<span class="op">=</span><span class="st">"pack_price"</span>,</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>                                           between<span class="op">=</span><span class="st">"shipment_mode"</span>,</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>                                           padjust<span class="op">=</span><span class="st">"bonf"</span>)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Print pairwise_results</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(modify_pairwise_results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>        Contrast            A            B  Paired  Parametric          T  \
0  shipment_mode          Air  Air Charter   False        True  21.179625   
1  shipment_mode          Air        Ocean   False        True  19.335760   
2  shipment_mode  Air Charter        Ocean   False        True  -3.170654   

          dof alternative         p-unc       BF10    hedges  
0  600.685682   two-sided  8.748346e-75  5.809e+76  0.726592  
1  986.979785   two-sided  6.934555e-71  1.129e+67  0.711119  
2   35.615026   two-sided  3.123012e-03     15.277 -0.423775  
        Contrast            A            B  Paired  Parametric          T  \
0  shipment_mode          Air  Air Charter   False        True  21.179625   
1  shipment_mode          Air        Ocean   False        True  19.335760   
2  shipment_mode  Air Charter        Ocean   False        True  -3.170654   

          dof alternative         p-unc        p-corr p-adjust       BF10  \
0  600.685682   two-sided  8.748346e-75  2.624504e-74     bonf  5.809e+76   
1  986.979785   two-sided  6.934555e-71  2.080367e-70     bonf  1.129e+67   
2   35.615026   two-sided  3.123012e-03  9.369037e-03     bonf     15.277   

     hedges  
0  0.726592  
1  0.711119  
2 -0.423775  </code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="sec-Chapter3" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="sec-Chapter3"><span class="header-section-number">3</span> Chapter 3: Proportion Tests</h2>
<p>Now it’s time to test for differences in proportions between two groups using proportion tests. Through hands-on exercises, you’ll extend your proportion tests to more than two groups with chi-square independence tests, and return to the one sample case with chi-square goodness of fit tests.</p>
<section id="sec-Chapter3.1" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="sec-Chapter3.1"><span class="header-section-number">3.1</span> Chapter 3.1: One-sample proportion tests</h3>
<p>Let’s return to thinking about testing proportions, as we did in <a href="#sec-Chapter1" class="quarto-xref">Section&nbsp;1</a>.</p>
<section id="chapter-1-recap" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="chapter-1-recap">Chapter 1 recap</h4>
<p>The hypothesis tests in <a href="#sec-Chapter1" class="quarto-xref">Section&nbsp;1</a> measured whether or not an unknown population proportion was equal to some value. We used bootstrapping on the sample to estimate the standard error of the sample statistic. The standard error was then used to calculate a standardized test statistic, the z-score, which was used to get a p-value, so we could decide whether or not to reject the null hypothesis. A bootstrap distribution can be computationally intensive to calculate, so this time we’ll instead calculate the test statistic without it.</p>
</section>
<section id="standardized-test-statistic-for-proportions" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="standardized-test-statistic-for-proportions">Standardized test statistic for proportions</h4>
<p>An unknown population parameter that is a proportion, or population proportion for short, is denoted p.&nbsp;The sample proportion is denoted p-hat, and the hypothesized value for the population proportion is denoted p-zero. As in <a href="#sec-Chapter1" class="quarto-xref">Section&nbsp;1</a>, the standardized test statistic is a z-score. We calculate it by starting with the sample statistic, subtracting its mean, then dividing by its standard error. p-hat minus the mean of p-hat, divided by the standard error of p-hat. Recall from Sampling in Python that the mean of a sampling distribution of sample means, denoted by p-hat, is p, the population proportion. Under the null hypothesis, the unknown proportion p is assumed to be the hypothesized population proportion p-zero. The z-score is now p-hat minus p-zero, divided by the standard error of p-hat.</p>
</section>
<section id="simplifying-the-standard-error-calculations" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="simplifying-the-standard-error-calculations">Simplifying the standard error calculations</h4>
<p>For proportions, under H-naught, the standard error of p-hat equation can be simplified to p-zero times one minus p-zero, divided by the number of observations, then square-rooted. We can substitute this into our equation for the z-score. This is easier to calculate because it only uses p-hat and n, which we get from the sample, and p-zero, which we chose.</p>
</section>
<section id="why-z-instead-of-t" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="why-z-instead-of-t">Why z instead of t?</h4>
<p>We might wonder why we used a z-distribution here, but a t-distribution in <a href="#sec-Chapter2" class="quarto-xref">Section&nbsp;2</a>. This is the test statistic equation for the two sample mean case. The standard deviation of the sample, s, is calculated from the sample mean, x-bar. That means that x-bar is used in the numerator to estimate the population mean, and in the denominator to estimate the population standard deviation. This dual usage increases the uncertainty in our estimate of the population parameter. Since t-distributions are effectively a normal distribution with fatter tails, we can use them to account for this extra uncertainty. In effect, the t-distribution provides extra caution against mistakenly rejecting the null hypothesis. For proportions, we only use p-hat in the numerator, thus avoiding the problem with uncertainty, and a z-distribution is fine.</p>
</section>
<section id="stack-overflow-age-categories" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="stack-overflow-age-categories">Stack Overflow age categories</h4>
<p>Returning to the Stack Overflow survey, let’s hypothesize that half of the users in the population are under thirty and check for a difference. Let’s set a significance level of point-zero-one. In the sample, just over half the users are under thirty.</p>
</section>
<section id="variables-for-z" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="variables-for-z">Variables for z</h4>
<p>Let’s get the numbers needed for the z-score. p-hat is the proportion of sample rows where <code>age_cat</code> equals under thirty. p-zero is point-five according to the null hypothesis. n is the number of rows in the dataset.</p>
</section>
<section id="calculating-the-z-score-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-the-z-score-1">Calculating the z-score</h4>
<p>Inserting the values we calculated into the z-score equation yields a z-score of around three-point-four.</p>
</section>
<section id="calculating-the-p-value-3" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-the-p-value-3">Calculating the p-value</h4>
<p>For left-tailed alternative hypotheses, we transform the z-score into a p-value using <code>norm.cdf</code>. For right-tailed alternative hypotheses, we subtract the <code>norm.cdf</code> result from one. For two-tailed alternative hypotheses, we check whether the test statistic lies in either tail, so the p-value is the sum of these two values: one corresponding to the z-score and the other to its negative on the other side of the distribution. Since the normal distribution PDF is symmetric, this simplifies to twice the right-tailed p-value since the z-score is positive. Here, the p-value is less than the significance level of point-zero-one, so we reject the null hypothesis, concluding that the proportion of users under thirty is not equal to point-five.</p>
</section>
</section>
<section id="exercise-3.1.1" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="exercise-3.1.1"><span class="header-section-number">3.2</span> Exercise 3.1.1</h3>
<section id="test-for-single-proportions" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="test-for-single-proportions">Test for single proportions</h4>
<p>In <a href="#sec-Chapter1" class="quarto-xref">Section&nbsp;1</a>, you calculated a p-value for a test hypothesizing that the proportion of late shipments was greater than 6%. In that chapter, you used a bootstrap distribution to estimate the standard error of the statistic. An alternative is to use an equation for the standard error based on the sample proportion, hypothesized proportion, and sample size.</p>
<p><span class="math display">\[
z = \frac{p - p_0}{\sqrt{\frac{p_0 (1 - p_0)}{n}}}
\]</span></p>
<p>You’ll revisit the p-value using this simpler calculation.</p>
</section>
<section id="instructions-11" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-11">Instructions</h4>
<ol type="1">
<li>Hypothesize that the proportion of late shipments is 6%.</li>
</ol>
<ul>
<li>Calculate the sample proportion of shipments where late equals <code>"Yes"</code>.</li>
<li>Calculate the number of observations in the sample.</li>
</ul>
<ol start="2" type="1">
<li>Calculate the numerator and denominator of the z-score.</li>
</ol>
<ul>
<li>Calculate the z-score as the ratio of these numbers.</li>
</ul>
<ol start="3" type="1">
<li>Transform the z-score into a p-value, remembering that this is a “greater than” alternative hypothesis.</li>
</ol>
<div id="7edf5df0" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Hypothesize that the proportion of late shipments is 6%</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>p_0 <span class="op">=</span> <span class="fl">0.06</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the sample proportion of late shipments</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>p_hat <span class="op">=</span> (late_shipments[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">'Yes'</span>).mean()</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the sample size</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(late_shipments)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Print p_hat and n</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(p_hat, n)</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the numerator and denominator of the test statistic</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>numerator <span class="op">=</span> p_hat <span class="op">-</span> p_0</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>denominator <span class="op">=</span> np.sqrt(p_0 <span class="op">*</span> (<span class="dv">1</span><span class="op">-</span>p_0)<span class="op">/</span>n)</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the test statistic</span></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>z_score <span class="op">=</span> numerator<span class="op">/</span>denominator</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(z_score)</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the p-value from the z-score</span></span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>p_value <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> norm.cdf(z_score)</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the p-value</span></span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(p_value)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>0.061 1000
0.13315591032282698
0.44703503936503364</code></pre>
</div>
</div>
</section>
</section>
<section id="sec-Chapter3.2" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="sec-Chapter3.2"><span class="header-section-number">3.3</span> Chapter 3.2: Two-sample proportion tests</h3>
<p>Great work so far! In the previous lesson, we tested a single proportion against a specific value. As with means, we can also test for differences between proportions in two populations.</p>
<section id="comparing-two-proportions" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="comparing-two-proportions">Comparing two proportions</h4>
<p>The Stack Overflow survey contains a hobbyist variable. The value “Yes” means the user described themselves as a hobbyist and “No” means they described themselves as a professional. We can hypothesize that the proportion of hobbyist users is the same for the under thirty age category as the thirty or over category, which is a two-tailed test. More formally, the null hypothesis is that the difference between the population parameters for each group is zero. Let’s set a significance level of point-zero-five.</p>
</section>
<section id="calculating-the-z-score-2" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="calculating-the-z-score-2">Calculating the z-score</h4>
<p>Here is the z-score equation for a proportion test. Let’s break it down. The sample statistic is the difference in the proportions for each category. That’s the two <code>p-hat</code> values in the numerator. We subtract the hypothesized value of the population parameter, and assuming the null hypothesis is true, it’s zero. The denominator is the standard error of the sample statistic. We can again avoid having to generate a bootstrap distribution to calculate the standard error by using a standard error equation, which is a slightly more complicated version of the one sample case. Note that <code>p-hat</code> is a weighted mean of the sample proportions for each category, also is known as a pooled estimate of the population proportion. <code>p-hat</code> can be calculated using the following equation. This looks horrendous, but Python is great at handling arithmetic. We now only need four numbers from the sample dataset to perform these calculations and calculate the z-score: the proportion of hobbyists in each age group, and the number of observations in each age group.</p>
</section>
<section id="getting-the-numbers-for-the-z-score" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="getting-the-numbers-for-the-z-score">Getting the numbers for the z-score</h4>
<p>To calculate these four numbers, we group by the age category, and calculate the sample proportions using <code>.value_counts</code>, and the row counts using <code>.count</code>. As we’re looking at the proportion of hobbyists, we’ll only be focusing on rows where hobbyist is Yes.</p>
<p>To isolate the hobbyist proportions from <code>p_hats</code>, we can use pandas’ multiIndex subsetting, passing a tuple of the outer column and inner column values. This returns a sample proportion of point-77 for the at least thirty group, and point-84 for the under thirty’s.</p>
<p>The number of observations in each age category can be extracted with simpler pandas subsetting. There are 1050 rows in the at least thirty group and 1211 for the under 30 group.</p>
<p>After that, we can do the arithmetic using our equations for <code>p_hat</code>, the standard error, and the z-score to get the test statistic. This returns a z-score of minus four-point-two-two. Luckily, we can avoid much of this arithmetic.</p>
</section>
<section id="proportion-tests-using-proportions_ztest" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="proportion-tests-using-proportions_ztest">Proportion tests using <code>proportions_ztest()</code></h4>
<p>The <code>proportions_ztest</code> function from <code>statsmodels</code> can calculate the z-score more directly. This function requires two objects as NumPy arrays: the number of hobbyists in each age group, and the total number of rows in each age group. We can get these numbers by grouping by <code>age_cat</code>, and calling <code>.value_counts</code> on the hobbyist column, as shown above. The numbers can then either be read-off or subsetted to create the arrays. Next, we import <code>proportions_ztest</code> from <code>statsmodels.stats.proportions</code>, and pass the arrays to the count and nobs arguments. Because we’re testing for a difference, we specify that this is a two-sided test using the alternative argument. <code>proportions_ztest</code> returns a z-score and a p-value. The p-value is smaller than the five percent significance level we specified, so we can conclude that there is a difference in the proportion of hobbyists between the two age groups.</p>
</section>
</section>
<section id="exercise-3.2.1" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="exercise-3.2.1"><span class="header-section-number">3.4</span> Exercise 3.2.1</h3>
<section id="test-of-two-proportions" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="test-of-two-proportions">Test of two proportions</h4>
<p>You may wonder if the amount paid for freight affects whether or not the shipment was late. Recall that in the <code>late_shipments</code> dataset, whether or not the shipment was <code>late</code> is stored in the late column. Freight costs are stored in the <code>freight_cost_group</code> column, and the categories are <code>"expensive"</code> and <code>"reasonable"</code>.</p>
<p>The hypotheses to test, with <code>"late"</code> corresponding to the proportion of late shipments for that group, are</p>
<p><span class="math display">\[
H_0: \text{late}_{\text{expensive}} - \text{late}_{\text{reasonable}} = 0
\]</span></p>
<p><span class="math display">\[
H_A: \text{late}_{\text{expensive}} - \text{late}_{\text{reasonable}} &gt; 0
\]</span></p>
<p><code>p_hats</code> contains the estimates of population proportions (sample proportions) for each <code>freight_cost_group</code>:</p>
<pre><code>freight_cost_group  late
expensive           Yes    0.079096
reasonable          Yes    0.035165 
Name: late, dtype: float64</code></pre>
<p><code>ns</code> contains the sample sizes for these groups:</p>
<pre><code>freight_cost_group
expensive     531
reasonable    455
Name: late, dtype: int64</code></pre>
</section>
<section id="instructions-12" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-12">Instructions</h4>
<ol type="1">
<li>Calculate the pooled sample proportion, <span class="math inline">\(\hat{p}\)</span>, from <code>p_hats</code> and <code>ns</code>.</li>
</ol>
<p><span class="math display">\[
\hat{p} = \frac{n_{\text{expensive}} \cdot \hat{p}_{\text{expensive}} + n_{\text{reasonable}} \cdot \hat{p}_{\text{reasonable}}}{n_{\text{expensive}} + n_{\text{reasonable}}}
\]</span></p>
<ol start="2" type="1">
<li>Calculate the standard error of the sample using this equation.</li>
</ol>
<p><span class="math display">\[
SE(\hat{p}_{\text{expensive}} - \hat{p}_{\text{reasonable}}) = \sqrt{\frac{\hat{p}(1- \hat{p})}{n_{\text{expensive}}} + \frac{\hat{p}(1- \hat{p})}{n_{\text{reasonable}}}}
\]</span></p>
<ul>
<li>Calculate <code>p_hat</code> multiplied by <code>(1 - p_hat)</code>.</li>
<li>Divide <code>p_hat_times_not_p_hat</code> by the number of <code>"reasonable"</code> rows and by the number of <code>"expensive"</code> rows, and sum those two values.</li>
<li>Calculate <code>std_error</code> by taking the square root of <code>p_hat_times_not_p_hat_over_ns</code>.</li>
</ul>
<ol start="3" type="1">
<li>Calculate the z-score using the following equation.</li>
</ol>
<p><span class="math display">\[
z = \frac{(\hat{p}_{\text{expensive}} - \hat{p}_{\text{reasonable}})}{SE(\hat{p}_{\text{expensive}} - \hat{p}_{\text{reasonable}})}
\]</span></p>
<ol start="4" type="1">
<li>Calculate the p-value from the z-score.</li>
</ol>
<div id="2af20e46" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co"># P_hats and ns</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>p_hats <span class="op">=</span> late_shipments.groupby(<span class="st">'freight_cost_groups'</span>)[<span class="st">'late'</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the resulting Series to a DataFrame for easier manipulation</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>p_hats <span class="op">=</span> p_hats.reset_index(name<span class="op">=</span><span class="st">'proportion'</span>)</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter for rows where 'late' is 'Yes'</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>p_hats <span class="op">=</span> p_hats[p_hats[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">'Yes'</span>]</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the count of each group</span></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>ns <span class="op">=</span> late_shipments.groupby(<span class="st">'freight_cost_groups'</span>)[<span class="st">'late'</span>].count()</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the pooled estimate of the population proportion</span></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>p_hat_expensive <span class="op">=</span> p_hats[p_hats[<span class="st">'freight_cost_groups'</span>] <span class="op">==</span> <span class="st">'expensive'</span>][<span class="st">'proportion'</span>].values[<span class="dv">0</span>]</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>p_hat_reasonable <span class="op">=</span> p_hats[p_hats[<span class="st">'freight_cost_groups'</span>] <span class="op">==</span> <span class="st">'reasonable'</span>][<span class="st">'proportion'</span>].values[<span class="dv">0</span>]</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>p_hat <span class="op">=</span> (ns[<span class="st">'expensive'</span>] <span class="op">*</span> p_hat_expensive <span class="op">+</span> ns[<span class="st">'reasonable'</span>] <span class="op">*</span> p_hat_reasonable) <span class="op">/</span> (ns[<span class="st">'expensive'</span>] <span class="op">+</span> ns[<span class="st">'reasonable'</span>])</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P_hat value: </span><span class="sc">{</span>p_hat<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate p_hat one minus p_hat</span></span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>p_hat_times_not_p_hat <span class="op">=</span> p_hat <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> p_hat)</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Divide this by each of the sample sizes and then sum</span></span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>p_hat_times_not_p_hat_over_ns <span class="op">=</span> (p_hat_times_not_p_hat<span class="op">/</span>ns[<span class="st">"expensive"</span>]) <span class="op">+</span> (p_hat_times_not_p_hat<span class="op">/</span>ns[<span class="st">"reasonable"</span>])</span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the standard error</span></span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>std_error <span class="op">=</span> np.sqrt(p_hat_times_not_p_hat_over_ns)</span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Standard deviation: </span><span class="sc">{</span>std_error<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the z-score</span></span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a>z_score <span class="op">=</span> (p_hat_expensive  <span class="op">-</span> p_hat_reasonable)<span class="op">/</span>std_error</span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Print z_score</span></span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Z Score: </span><span class="sc">{</span>z_score<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the p-value from the z-score</span></span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a>p_value <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> norm.cdf(z_score)</span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Print p_value</span></span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P value: </span><span class="sc">{</span>p_value<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>P_hat value: 0.058823529411764705
Standard deviation: 0.015031300895066685
Z Score: 2.922648567784529
P value: 0.0017353400023595311</code></pre>
</div>
</div>
<p><em>This tiny p-value leads us to suspect there is a larger proportion of late shipments for expensive freight compared to reasonable freight.</em></p>
</section>
</section>
<section id="exercise-3.2.2" class="level3" data-number="3.5">
<h3 data-number="3.5" class="anchored" data-anchor-id="exercise-3.2.2"><span class="header-section-number">3.5</span> Exercise 3.2.2</h3>
<section id="proportions_ztest-for-two-samples" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="proportions_ztest-for-two-samples"><code>proportions_ztest()</code> for two samples</h4>
<p>That took a lot of effort to calculate the p-value, so while it is useful to see how the calculations work, it isn’t practical to do in real-world analyses. For daily usage, it’s better to use the <code>statsmodels</code> package.</p>
<p>Recall the hypotheses.</p>
<p><span class="math display">\[
H_0: \text{late}_{\text{expensive}} - \text{late}_{\text{reasonable}} = 0
\]</span></p>
<p><span class="math display">\[
H_A: \text{late}_{\text{expensive}} - \text{late}_{\text{reasonable}} &gt; 0
\]</span></p>
</section>
<section id="instructions-13" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-13">Instructions</h4>
<ol type="1">
<li>Get the counts of the <code>late</code> column grouped by <code>freight_cost_groups</code>.</li>
<li>Extract the number of <code>"Yes"</code>’s for the two <code>freight_cost_group</code> into a numpy array, specifying the <code>'expensive'</code> count and then <code>'reasonable'</code>.</li>
</ol>
<ul>
<li>Determine the overall number of rows in each <code>freight_cost_group</code> as a numpy array, specifying the <code>'expensive'</code> count and then <code>'reasonable'</code>.</li>
<li>Run a z-test using <code>proportions_ztest()</code>, specifying alternative as <code>"larger"</code>.</li>
</ul>
<div id="74d8e37e" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.stats.proportion <span class="im">import</span> proportions_ztest</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the late column values for each freight_cost_group</span></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>late_by_freight_cost_group <span class="op">=</span> late_shipments.groupby(<span class="st">'freight_cost_groups'</span>)[<span class="st">'late'</span>].value_counts()</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the counts</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(late_by_freight_cost_group)</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>stat <span class="op">=</span> <span class="fl">2.922648567784529</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an array of the "Yes" counts for each freight_cost_group</span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>success_counts <span class="op">=</span> np.array([<span class="dv">42</span>, <span class="dv">16</span>])</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an array of the total number of rows in each freight_cost_group</span></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> np.array([<span class="dv">489</span> <span class="op">+</span> <span class="dv">42</span>, <span class="dv">439</span> <span class="op">+</span> <span class="dv">16</span>])</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Run a z-test on the two proportions</span></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>stat, p_value <span class="op">=</span> proportions_ztest(count <span class="op">=</span> success_counts, nobs <span class="op">=</span> n, alternative <span class="op">=</span> <span class="st">"larger"</span>)</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Z_Stat: </span><span class="sc">{</span>stat<span class="sc">}</span><span class="ss">, P_value: </span><span class="sc">{</span>p_value<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>freight_cost_groups  late
expensive            No      489
                     Yes      42
reasonable           No      439
                     Yes      16
Name: count, dtype: int64
Z_Stat: 2.922648567784529, P_value: 0.001735340002359578</code></pre>
</div>
</div>
</section>
</section>
<section id="sec-Chapter3.3" class="level3" data-number="3.6">
<h3 data-number="3.6" class="anchored" data-anchor-id="sec-Chapter3.3"><span class="header-section-number">3.6</span> Chapter 3.3: Chi-square test of independence</h3>
<p>Just as ANOVA extends t-tests to more than two groups, chi-square tests of independence extend proportion tests to more than two groups.</p>
<section id="revisiting-the-proportion-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="revisiting-the-proportion-test">Revisiting the proportion test</h4>
<p>Here’s the proportions test from the last <a href="#sec-Chapter3.2" class="quarto-xref">Section&nbsp;3.3</a>. The test statistic is the z-score of minus four-point-two-two.</p>
</section>
<section id="independence-of-variables" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="independence-of-variables">Independence of variables</h4>
<p>That proportion test had a positive result. The small p-value suggested that there was evidence that the hobbyist and age category variables had an association. If the proportion of hobbyists was the same for each age category, the variables would be considered statistically independent. More formally, two categorical variables are consider statistically independent when the proportion of successes in the response variable is the same across all categories of the explanatory variable.</p>
</section>
<section id="test-for-independence-of-variables" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="test-for-independence-of-variables">Test for independence of variables</h4>
<p>The <code>pingouin</code> package has an indirect way of testing the difference in the proportions from the previous <a href="#sec-Chapter2.3" class="quarto-xref">Section&nbsp;2.5</a>. To the <code>chi2_independence</code> method, we pass <code>stack_overflow</code> as data, <code>hobbyist</code> as <code>x</code>, and <code>age_cat</code> as <code>y</code>. The correction argument specifies whether or not to apply Yates’ continuity correction, which is a fudge factor for when the sample size is very small and the degrees of freedom is one. Since each group has over one hundred observations, we don’t need it here. The method returns three different pandas DataFrames: the expected counts, the observed counts, and statistics related to the test. Let’s look at stats and focus on the <code>pearson</code> test row and the <code>chi2</code> and <code>pval</code> columns. The p-value is the same as we had with the z-test of around two in one hundred thousand. The <code>chi2</code> value is the squared result of our z-score seen in the previous <a href="#sec-Chapter3.2" class="quarto-xref">Section&nbsp;3.3</a>.</p>
</section>
<section id="job-satisfaction-and-age-category" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="job-satisfaction-and-age-category">Job satisfaction and age category</h4>
<p>Let’s try another example. Recall that the Stack Overflow sample has an age category variable with two categories and a job satisfaction variable with five categories.</p>
</section>
<section id="declaring-the-hypotheses" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="declaring-the-hypotheses">Declaring the hypotheses</h4>
<p>We can declare hypotheses to test for independence of these variables. Here, age category is the response variable, and job satisfaction is the explanatory variable. The null hypothesis is that independence occurs. Let’s use a <code>significance level</code> of <code>point-one</code>. The test statistic is denoted chi-square. It quantifies how far away the observed results are from the expected values if independence was true.</p>
</section>
<section id="exploratory-visualization-proportional-stacked-bar-plot" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="exploratory-visualization-proportional-stacked-bar-plot">Exploratory visualization: proportional stacked bar plot</h4>
<p>Let’s explore the data using a proportional stacked bar plot. We begin by calculating the proportions in each age group. Next, we use the unstack method to convert this table into wide format. Using the plot method and setting kind to bar and stacked to True produces a proportional stacked bar plot. If the age category was independent of job satisfaction, the split between the age categories would be at the same height in each of the five bars. There’s some variation here, but we’ll need a <code>chi-square independence test</code> to determine whether it’s a significant difference.</p>
</section>
<section id="chi-square-independence-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="chi-square-independence-test">Chi-square independence test</h4>
<p>Let’s again use the <code>chi-square independence test</code> from <code>pingouin</code>. We have <code>stack_overflow</code> as the data and <code>job_sat</code> and <code>age_cat</code> as <code>x</code> and <code>y</code>. We leave out a correction here since our <code>degrees of freedom</code> is <code>four</code>, calculated by subtracting one from each of the variable categories and multiplying. The <code>p-value</code> is <code>point-two-three</code>, which is above the significance level we set, so we conclude that age categories are independent of job satisfaction.</p>
</section>
<section id="swapping-the-variables" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="swapping-the-variables">Swapping the variables?</h4>
<p>Swapping the variables, so age category is the response and job satisfaction is the explanatory variable, we see that the splits for each bar are in similar places.</p>
</section>
<section id="chi-square-both-ways" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="chi-square-both-ways">chi-square both ways</h4>
<p>If we run the chi-square test with the variables swapped, then the results are identical. Because of this, we phrase our questions as “are variables X and Y independent?”, rather than “is variable X independent from variable Y?”, since the order doesn’t matter.</p>
</section>
<section id="what-about-direction-and-tails" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="what-about-direction-and-tails">What about direction and tails?</h4>
<p>We didn’t worry about tails in this test, and in fact, the <code>chi2_independence</code> method doesn’t have an alternative argument. This is because the chi-square test statistic is based on the square of observed and expected counts, and square numbers are non-negative. That means that chi-square tests tend to be right-tailed tests.</p>
<ol type="1">
<li>1 Left-tailed chi-square tests are used in statistical forensics to detect if a fit is suspiciously good because the data was fabricated. Chi-square tests of variance can be two-tailed. These are niche uses, though.</li>
</ol>
</section>
</section>
<section id="exercise-3.3.3" class="level3" data-number="3.7">
<h3 data-number="3.7" class="anchored" data-anchor-id="exercise-3.3.3"><span class="header-section-number">3.7</span> Exercise 3.3.3</h3>
<section id="performing-a-chi-square-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="performing-a-chi-square-test">Performing a chi-square test</h4>
<p>The <em>chi-square independence test</em> compares proportions of successes of one categorical variable across the categories of another categorical variable.</p>
<p>Trade deals often use a form of business shorthand in order to specify the exact details of their contract. These are International Chamber of Commerce (ICC) international commercial terms, or <em>incoterms</em> for short.</p>
<p>The <code>late_shipments</code> dataset includes a <code>vendor_inco_term</code> that describes the incoterms that applied to a given shipment. The choices are:</p>
<ul>
<li><code>EXW</code>: “Ex works”. The buyer pays for transportation of the goods.</li>
<li><code>CIP</code>: “Carriage and insurance paid to”. The seller pays for freight and insurance until the goods board a ship.</li>
<li><code>DDP</code>: “Delivered duty paid”. The seller pays for transportation of the goods until they reach a destination port.</li>
<li><code>FCA</code>: “Free carrier”. The seller pays for transportation of the goods. Perhaps the incoterms affect whether or not the freight costs are expensive. Test these hypotheses with a significance level of <code>0.01</code>.</li>
</ul>
<p><span class="math inline">\(H_O\)</span>: <code>vendor_inco_term</code> and <code>freight_cost_group</code> are independent.</p>
<p><span class="math inline">\(H_A\)</span>: <code>vendor_inco_term</code> and <code>freight_cost_group</code> are associated.</p>
</section>
<section id="instructions-14" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-14">Instructions</h4>
<ol type="1">
<li>Calculate the proportion of <code>freight_cost_group</code> in <code>late_shipments</code> grouped by <code>vendor_inco_term</code>.</li>
<li>Unstack the <code>.value_counts()</code> result to be in wide format instead of long.</li>
<li>Create a proportional stacked bar plot with bars filled based on <code>freight_cost_group</code> across the levels of <code>vendor_inco_term</code>.</li>
<li>Perform a chi-square test of independence on <code>freight_cost_group</code> and <code>vendor_inco_term</code> in the <code>late_shipments</code> dataset.</li>
</ol>
<div id="dbad4ecf" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Proportion of freight_cost_group grouped by vendor_inco_term</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>props <span class="op">=</span> late_shipments.groupby(<span class="st">'vendor_inco_term'</span>)[<span class="st">'freight_cost_groups'</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert props to wide format</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>wide_props <span class="op">=</span> props.unstack()</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop 'DDU' row</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>wide_props <span class="op">=</span> wide_props.drop(<span class="st">'DDU'</span>, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Print wide_props</span></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(wide_props)</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Proportional stacked bar plot of freight_cost_group vs. vendor_inco_term</span></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>wide_props.plot(kind<span class="op">=</span><span class="st">'bar'</span>, stacked<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine if freight_cost_group and vendor_inco_term are independent</span></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>expected, observed, stats <span class="op">=</span> pingouin.chi2_independence(data<span class="op">=</span> late_shipments ,x<span class="op">=</span> <span class="st">'freight_cost_groups'</span>, y<span class="op">=</span><span class="st">'vendor_inco_term'</span>)</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Print results</span></span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stats[stats[<span class="st">'test'</span>] <span class="op">==</span> <span class="st">'pearson'</span>]) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>freight_cost_groups  expensive  reasonable
vendor_inco_term                          
CIP                   0.320000    0.680000
DDP                   0.550000    0.450000
EXW                   0.583448    0.416552
FCA                   0.336364    0.663636</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-18-output-2.png" width="571" height="447" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>      test  lambda       chi2  dof          pval    cramer     power
0  pearson     1.0  34.805072  4.0  5.093922e-07  0.186561  0.999235</code></pre>
</div>
</div>
<ol start="5" type="1">
<li>What should you conclude from the hypothesis test?</li>
</ol>
<ul>
<li><strong>Answer</strong>: Reject the null hypothesis and conclude that <code>vendor_inco_term</code> and <code>freight_cost_group</code> are associated.</li>
<li><em>The test to compare proportions of successes in a categorical variable across groups of another categorical variable is called a chi-square test of independence</em>.</li>
</ul>
</section>
</section>
<section id="sec-Chapter3.4" class="level3" data-number="3.8">
<h3 data-number="3.8" class="anchored" data-anchor-id="sec-Chapter3.4"><span class="header-section-number">3.8</span> Chapter 3.4: Chi-square goodness of fit tests</h3>
<p>Last time, we used a chi-square test to compare proportions in two categorical variables. This time, we’ll use another variant of the chi-square test to compare a single categorical variable to a hypothesized distribution.</p>
<section id="purple-links" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="purple-links">Purple links</h4>
<p>The Stack Overflow survey contains a fun question about how users feel when they discover that they already visited the top resource, also called a purple link, when trying to solve a coding problem. We can use the <code>.value-counts</code> method to get the counts of each group in the <code>purple_link</code> column. We also do a little bit of manipulation here to get a nicely structured DataFrame that we can work with later. First, we rename the leftmost column to be <code>purple_link</code>, assign the counts to <code>n</code>, and finally sort by <code>purple_link</code>, so the responses are in alphabetical order. There are four possible answers stored in the <code>purple_link</code> column.</p>
</section>
<section id="declaring-the-hypotheses-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="declaring-the-hypotheses-1">Declaring the hypotheses</h4>
<p>Let’s hypothesize that half of the users in the population would respond “Hello, old friend”, and the other three responses would get one sixth each. We can create a DataFrame for these hypothesized results from a dictionary of key-value pairs for each response. We specify the hypotheses as whether or not the sample matches this hypothesized distribution. The test statistic, chi-squared, measures how far the observed sample distribution of proportions is from the hypothesized distribution. Let’s set the significance level of point-zero-one.</p>
</section>
<section id="hypothesized-counts-by-category" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="hypothesized-counts-by-category">Hypothesized counts by category</h4>
<p>To visualize the <code>purple_link</code> distribution, it will help to have the hypothesized counts for each answer, which are calculated by multiplying the hypothesized proportions by the total number of observations in the sample.</p>
</section>
<section id="visualizing-counts" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="visualizing-counts">Visualizing counts</h4>
<p>Let’s create a visualization to see how well the hypothesized counts appear to model the observed counts. The natural way to visualize the counts of a categorical variable is with a bar plot. First, we use <code>plt.bar</code> to plot the observed <code>purple_link</code> counts, setting the horizontal axis to <code>purple_link</code> and the vertical axis to <code>n</code>. We set the color of the bars and add a label for a legend. We do the same again for the hypothesized counts, but also add transparency with the alpha argument. We can see that two of the responses are reasonably well-modeled by the hypothesized distribution and another two appear quite different, but we’ll need to run a hypothesis test to see if the difference is statistically significant.</p>
</section>
<section id="chi-square-goodness-of-fit-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="chi-square-goodness-of-fit-test">chi-square goodness of fit test</h4>
<p>The one-sample chi-square test is called a goodness of fit test, as we’re testing how well our hypothesized data fits the observed data. To run the test, we use the <code>chisquare</code> method from <code>scipy.stats</code>. There are two required arguments to chisquare: an array-like object for the observed counts, <code>f_obs</code>, and one for the expected counts, <code>f_exp</code>. The p-value returned by the function is very small, much lower than the significance level of point-zero-one, so we conclude that the sample distribution of proportions is different from the hypothesized distribution.</p>
</section>
</section>
<section id="exercise-3.4.1" class="level3" data-number="3.9">
<h3 data-number="3.9" class="anchored" data-anchor-id="exercise-3.4.1"><span class="header-section-number">3.9</span> Exercise 3.4.1</h3>
<section id="visualizing-goodness-of-fit" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="visualizing-goodness-of-fit">Visualizing goodness of fit</h4>
<p>The chi-square goodness of fit test compares proportions of each level of a categorical variable to hypothesized values. Before running such a test, it can be helpful to visually compare the distribution in the sample to the hypothesized distribution.</p>
<p>Recall the vendor incoterms in the <code>late_shipments</code> dataset. You hypothesize that the four values occur with these frequencies in the population of shipments.</p>
<p><code>CIP</code>: 0.05 <code>DDP</code>: 0.1 <code>EXW</code>: 0.75 <code>FCA</code>: 0.1</p>
<p>These frequencies are stored in the <code>hypothesized</code> DataFrame.</p>
<p>The <code>incoterm_counts</code> DataFrame stores the <code>.value_counts()</code> of the <code>vendor_inco_term</code> column.</p>
</section>
<section id="instructions-15" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-15">Instructions</h4>
<ol type="1">
<li>Find the total number of rows in <code>late_shipments</code>.</li>
<li>Add a column named <code>n</code> to the <code>hypothesized</code> DataFrame that is the <code>hypothesized</code> <code>prop</code> column times <code>n_total</code>.</li>
<li>Create a bar graph of <code>'n'</code> versus <code>'vendor_inco_term'</code> for the <code>incoterm_counts</code> data, specifying a red color.</li>
<li>Add blue bars to the plot showing the same results from the <code>hypothesized</code> DataFrame, specifying an <code>alpha</code> of <code>0.5</code>.</li>
</ol>
<div id="56db33db" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the number of rows in late_shipments</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>n_total <span class="op">=</span> <span class="bu">len</span>(late_shipments)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Print n_total</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(n_total)</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>hypothesized <span class="op">=</span> pd.DataFrame({</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vendor_inco_term'</span>: [<span class="st">'CIP'</span>, <span class="st">'DDP'</span>, <span class="st">'EXW'</span>, <span class="st">'FCA'</span>],</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'prop'</span>: [<span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.75</span>, <span class="fl">0.1</span>]</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Create value counts for vendor_inco_term column</span></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>incoterm_counts <span class="op">=</span> late_shipments[<span class="st">'vendor_inco_term'</span>].value_counts()<span class="op">\</span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>.rename_axis(<span class="st">'vendor_inco_term'</span>)<span class="op">\</span></span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>.reset_index(name <span class="op">=</span> <span class="st">'n'</span>)<span class="op">\</span></span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a>.sort_values(<span class="st">'vendor_inco_term'</span>)</span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Create n column that is prop column * n_total</span></span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>hypothesized[<span class="st">'n'</span>] <span class="op">=</span> hypothesized[<span class="st">'prop'</span>] <span class="op">*</span> n_total</span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the modified hypothesized DataFrame</span></span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(hypothesized)</span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot a red bar graph of n vs. vendor_inco_term for incoterm_counts</span></span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a>plt.bar(incoterm_counts[<span class="st">'vendor_inco_term'</span>],incoterm_counts[<span class="st">'n'</span>], color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">"Observed"</span>)</span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-36"><a href="#cb40-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a blue bar plot for the hypothesized counts</span></span>
<span id="cb40-37"><a href="#cb40-37" aria-hidden="true" tabindex="-1"></a>plt.bar(hypothesized[<span class="st">'vendor_inco_term'</span>], hypothesized[<span class="st">'n'</span>], color <span class="op">=</span> <span class="st">'blue'</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>,label<span class="op">=</span><span class="st">"Hypothesized"</span>)</span>
<span id="cb40-38"><a href="#cb40-38" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb40-39"><a href="#cb40-39" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1000
  vendor_inco_term  prop      n
0              CIP  0.05   50.0
1              DDP  0.10  100.0
2              EXW  0.75  750.0
3              FCA  0.10  100.0</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-19-output-2.png" width="575" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="exercise-3.4.2" class="level3" data-number="3.10">
<h3 data-number="3.10" class="anchored" data-anchor-id="exercise-3.4.2"><span class="header-section-number">3.10</span> Exercise 3.4.2</h3>
<section id="performing-a-goodness-of-fit-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="performing-a-goodness-of-fit-test">Performing a goodness of fit test</h4>
<p>The bar plot of <code>vendor_inco_term</code> suggests that the distribution across the four categories was quite close to the hypothesized distribution. You’ll need to perform a <em>chi-square goodness of fit test</em> to see whether the differences are statistically significant.</p>
<p>Recall the hypotheses for this type of test:</p>
<p><span class="math inline">\(H_O\)</span>: The sample matches with the hypothesized distribution.</p>
<p><span class="math inline">\(H_A\)</span>: The sample does not match with the hypothesized distribution.</p>
<p>To decide which hypothesis to choose, we’ll set a significance level of <code>0.1</code>.</p>
</section>
<section id="instructions-16" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-16">Instructions</h4>
<ol type="1">
<li>Using the <code>incoterm_counts</code> and <code>hypothesized</code> datasets, perform a chi-square goodness of fit test on the incoterm counts, <code>n</code>.</li>
</ol>
<div id="e6c2472d" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> chisquare</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the number of rows in late_shipments</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>n_total <span class="op">=</span> <span class="bu">len</span>(late_shipments)</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Hypothesized dataset</span></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>hypothesized <span class="op">=</span> pd.DataFrame({</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vendor_inco_term'</span>: [<span class="st">'CIP'</span>, <span class="st">'DDP'</span>, <span class="st">'EXW'</span>, <span class="st">'FCA'</span>],</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'prop'</span>: [<span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.75</span>, <span class="fl">0.1</span>]</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Create value counts for vendor_inco_term column</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>incoterm_counts <span class="op">=</span> late_shipments[<span class="st">'vendor_inco_term'</span>].value_counts()<span class="op">\</span></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>.rename_axis(<span class="st">'vendor_inco_term'</span>)<span class="op">\</span></span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>.reset_index(name <span class="op">=</span> <span class="st">'n'</span>)<span class="op">\</span></span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>.sort_values(<span class="st">'vendor_inco_term'</span>)</span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter out 'DDU'</span></span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>incoterm_counts <span class="op">=</span> incoterm_counts[incoterm_counts[<span class="st">'vendor_inco_term'</span>] <span class="op">!=</span> <span class="st">'DDU'</span>]</span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Create n column that is prop column * n_total</span></span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a>hypothesized[<span class="st">'n'</span>] <span class="op">=</span> hypothesized[<span class="st">'prop'</span>] <span class="op">*</span> n_total</span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure the sums of observed and expected frequencies match</span></span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a>observed_sum <span class="op">=</span> incoterm_counts[<span class="st">'n'</span>].<span class="bu">sum</span>()</span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>expected_sum <span class="op">=</span> hypothesized[<span class="st">'n'</span>].<span class="bu">sum</span>()</span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust the expected frequencies to match the observed sum</span></span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a>hypothesized[<span class="st">'n'</span>] <span class="op">=</span> hypothesized[<span class="st">'n'</span>] <span class="op">*</span> (observed_sum <span class="op">/</span> expected_sum)</span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform a goodness of fit test on the incoterm counts n</span></span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a>gof_test <span class="op">=</span> chisquare(f_obs<span class="op">=</span> incoterm_counts[<span class="st">'n'</span>], f_exp <span class="op">=</span> hypothesized[<span class="st">'n'</span>])</span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Print gof_test results</span></span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Chi-Square goodness of fit test: </span><span class="sc">{</span>gof_test<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Chi-Square goodness of fit test: Power_divergenceResult(statistic=2.3633633633633613, pvalue=0.5004909543758689)</code></pre>
</div>
</div>
<ol start="2" type="1">
<li><strong>Question</strong></li>
</ol>
<ul>
<li>What should you conclude from the hypothesis test? <em>Fail to reject the null hypothesis and conclude that n follows the distribution specified by hypothesized. The test to compare the proportions of a categorical variable to a hypothesized distribution is called a chi-square goodness of fit test.</em></li>
</ul>
</section>
</section>
</section>
<section id="sec-Chapter4" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="sec-Chapter4"><span class="header-section-number">4</span> CHAPTER 4: Non-Parametric Tests</h2>
<p>Finally, it’s time to learn about the assumptions made by parametric hypothesis tests, and see how non-parametric tests can be used when those assumptions aren’t met.</p>
<section id="sec-Chapter4.1" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="sec-Chapter4.1"><span class="header-section-number">4.1</span> Chapter 4.1: Assumptions in hypothesis testing</h3>
<p>Each hypothesis test we’ve seen so far makes assumptions about the data. It’s only when these assumptions are met that it is appropriate to use that hypothesis test.</p>
<section id="randomness" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="randomness">Randomness</h4>
<p>Whether it uses one or multiple samples, every hypothesis test assumes that each sample is randomly sourced from its population. If we don’t have a random sample, then it won’t be representative of the population. To check this assumption, we need to know where our data came from. There are no statistical or coding tests we can perform to check this. If in doubt, ask the people involved in data collection, or a domain expert that understands the population being sampled.</p>
<ol type="1">
<li>1 <a href="https://lawaloa.github.io/Sampling/">Sampling techniques are discussed in “Sampling in Python”</a>.</li>
</ol>
</section>
<section id="independence-of-observations" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="independence-of-observations">Independence of observations</h4>
<p>Tests also assume that each observation is independent. There are some special cases like paired t-tests where dependencies between two samples are allowed, but these change the calculations, so we need to understand where such dependencies occur. As we saw with the paired t-test, not accounting for dependencies results in an increased chance of false negative and false positive errors. Not accounting for dependencies is a difficult problem to diagnose during analysis. Ideally, it needs to be discussed before data collection.</p>
</section>
<section id="large-sample-size" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="large-sample-size">Large sample size</h4>
<p>Hypothesis tests also assume that our sample is large enough that the Central Limit Theorem applies, and the sample distribution can be assumed to be normally distributed. Smaller samples incur greater uncertainty, which may mean that the Central Limit Theorem does not apply and the sampling distribution might not be normally distributed. The increased uncertainty of a small sample means we get wider confidence intervals on the parameter we are trying to estimate. If the Central Limit Theorem does not apply, the calculations on the sample, and any conclusions drawn from them, could be nonsense, which increases the chance of false negative and false positive errors. How big our sample needs to be to be “big enough” depends on the test.</p>
</section>
<section id="large-sample-size-t-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="large-sample-size-t-test">Large sample size: t-test</h4>
<p>For one sample t-tests, a popular heuristic is that we need at least thirty observations in our sample. For the two sample case or ANOVA, we need thirty observations from each group. That means we can’t compensate for one minority group sample by making the majority group bigger. In the paired case, we need thirty pairs of observations. Sometimes we can get away with less than 30 in each of these tests; the important thing is that the null distribution appears normal. This is often the case at around 30 and that’s the reason for this somewhat arbitrary threshold.</p>
</section>
<section id="large-sample-size-proportion-tests" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="large-sample-size-proportion-tests">Large sample size: proportion tests</h4>
<p>For one sample proportion tests, the sample is considered big enough if it contains at least ten successes and ten failures. Notice that if the probability of success is close to zero or close to one, then we need a bigger sample. In the two sample case, we require ten successes and ten failures from each sample.</p>
</section>
<section id="large-sample-size-chi-square-tests" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="large-sample-size-chi-square-tests">Large sample size: chi-square tests</h4>
<p>The chi-square test is slightly more forgiving and only requires five successes and five failures in each group, rather than ten.</p>
</section>
<section id="sanity-check" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="sanity-check">Sanity check</h4>
<p>One more check we can perform is to calculate a bootstrap distribution and visualize it with a histogram. If we don’t see a bell-shaped normal curve, then one of the assumptions hasn’t been met. In that case, we should revisit the data collection process, and see if any of the three assumptions of randomness, independence, and sample size do not hold.</p>
</section>
</section>
<section id="exercise-4.1.1" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="exercise-4.1.1"><span class="header-section-number">4.2</span> Exercise 4.1.1</h3>
<section id="testing-sample-size" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="testing-sample-size">Testing sample size</h4>
<p>In order to conduct a hypothesis test and be sure that the result is fair, a sample must meet three requirements: it is a random sample of the population, the observations are independent, and there are enough observations. Of these, only the last condition is easily testable with code.</p>
<p>The minimum sample size depends on the type of hypothesis tests you want to perform. You’ll now test some scenarios on the <code>late_shipments</code> dataset.</p>
<p>Note that the <code>.all()</code> method from pandas can be used to check if all elements are true. For example, given a DataFrame df with numeric entries, you check to see if all its elements are less than 5, using <code>(df &lt; 5).all()</code>.</p>
</section>
<section id="instructions-17" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-17">Instructions</h4>
<ol type="1">
<li>Get the count of each value in the freight_cost_group column of late_shipments. Insert a suitable number to inspect whether the counts are “big enough” for a two sample t-test.</li>
<li>Get the count of each value in the late column of late_shipments. Insert a suitable number to inspect whether the counts are “big enough” for a one sample proportion test.</li>
<li>Get the count of each value in the <code>freight_cost_group</code> column of <code>late_shipments</code> grouped by <code>vendor_inco_term</code>. Insert a suitable number to inspect whether the counts are <code>"big enough"</code> for a chi-square independence test.</li>
<li>Get the count of each value in the <code>shipment_mode</code> column of <code>late_shipments</code>. Insert a suitable number to inspect whether the counts are “big enough” for an ANOVA test.</li>
</ol>
<div id="3bb62bfe" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> chisquare</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the freight_cost_group values</span></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>counts_1 <span class="op">=</span> late_shipments[<span class="st">'freight_cost_groups'</span>].value_counts()</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(counts_1)</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect whether the counts are big enough</span></span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>((counts_1 <span class="op">&gt;=</span> <span class="dv">30</span>).<span class="bu">all</span>())</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the late values</span></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>counts_2 <span class="op">=</span> late_shipments[<span class="st">'late'</span>].value_counts()</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(counts_2)</span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect whether the counts are big enough</span></span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>((counts_2 <span class="op">&gt;=</span> <span class="dv">10</span>).<span class="bu">all</span>())</span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the values of freight_cost_group grouped by vendor_inco_term</span></span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a>counts_3 <span class="op">=</span> late_shipments.groupby(<span class="st">'vendor_inco_term'</span>)[<span class="st">'freight_cost_groups'</span>].value_counts()<span class="op">\</span></span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a>.drop(<span class="st">'DDU'</span>)</span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb44-33"><a href="#cb44-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(counts_3)</span>
<span id="cb44-34"><a href="#cb44-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-35"><a href="#cb44-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect whether the counts are big enough</span></span>
<span id="cb44-36"><a href="#cb44-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>((counts_3 <span class="op">&gt;=</span> <span class="dv">5</span>).<span class="bu">all</span>())</span>
<span id="cb44-37"><a href="#cb44-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-38"><a href="#cb44-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the shipment_mode values</span></span>
<span id="cb44-39"><a href="#cb44-39" aria-hidden="true" tabindex="-1"></a>counts_4 <span class="op">=</span> late_shipments[<span class="st">'shipment_mode'</span>].value_counts()</span>
<span id="cb44-40"><a href="#cb44-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-41"><a href="#cb44-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb44-42"><a href="#cb44-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Count_4:"</span>, counts_4)</span>
<span id="cb44-43"><a href="#cb44-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-44"><a href="#cb44-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect whether the counts are big enough</span></span>
<span id="cb44-45"><a href="#cb44-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>((counts_4 <span class="op">&gt;=</span> <span class="dv">30</span>).<span class="bu">all</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>freight_cost_groups
expensive     531
reasonable    455
Name: count, dtype: int64
True
late
No     939
Yes     61
Name: count, dtype: int64
True
vendor_inco_term  freight_cost_groups
CIP               reasonable              34
                  expensive               16
DDP               expensive               55
                  reasonable              45
EXW               expensive              423
                  reasonable             302
FCA               reasonable              73
                  expensive               37
Name: count, dtype: int64
True
Count_4: shipment_mode
Air            906
Ocean           88
Air Charter      6
Name: count, dtype: int64
False</code></pre>
</div>
</div>
</section>
</section>
<section id="sec-Chapter4.2" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="sec-Chapter4.2"><span class="header-section-number">4.3</span> Chapter 4.2: Non-parametric tests</h3>
<p>So what do we do if the assumptions for the hypothesis tests we’ve seen so far aren’t met?</p>
<section id="parametric-tests" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="parametric-tests">Parametric tests</h4>
<p>The tests that we’ve seen so far are known as parametric tests. Tests like the z-test, t-test, and ANOVA are all based on the assumption that the population is normally distributed. Parametric tests also require sample sizes that are “big enough” that the Central Limit Theorem applies.</p>
</section>
<section id="smaller-republican-votes-data" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="smaller-republican-votes-data">Smaller Republican votes data</h4>
<p>Let’s study a case where the sample size requirement isn’t met with a subset of the US Presidential voting results for Republican candidates that we examined in a previous chapter. Here, <code>repub_votes_small</code> contains only five counties randomly sampled from the larger dataset of 2008 and 2012 county-level returns.</p>
</section>
<section id="results-with-pingouin.ttest" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="results-with-pingouin.ttest">Results with <code>pingouin.ttest()</code></h4>
<p>Let’s try performing a paired t-test on this small sample. Recall that we require 30 pairs to feel confident in using a t-test, and this sample only contains five. We set a significance level of one percent and use the <code>ttest</code> method from <code>pingouin</code> to perform the left-tailed paired t-test. The small p-value indicates we should reject the null hypothesis, leading us to suspect that the 2008 election had a smaller percentage of Republican votes than the 2012 election.</p>
</section>
<section id="non-parametric-tests" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="non-parametric-tests">Non-parametric tests</h4>
<p>In situations where we aren’t sure about these assumptions, or we are certain that the assumptions aren’t met, we can use non-parametric tests. They do not make the normal distribution assumptions or the sample size conditions that we saw in the previous video. There are many different ways to perform tests without these parametric assumptions. In this chapter, we’ll focus on those relating to ranks. Consider the list, x. The first value of x, one, is the smallest value and the second value, fifteen, is the fifth smallest. These orderings from smallest to largest are known as the ranks of the elements of x. We can access them with the <code>rankdata</code> method from <code>scipy.stats</code>. Let’s now use a non-parametric test to see what kind of results it gives. Remember that non-parametric tests work better than the parametric alternative in situations where the sample size is small or the data cannot be assumed to be normally distributed. We will use the Wilcoxon-signed rank test, which was developed by Frank Wilcoxon in 1945 and was one of the first non-parametric procedures developed. We’ll go over the inner workings of the test before implementing it using another <code>pingouin</code> method.</p>
</section>
<section id="wilcoxon-signed-rank-test-step-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="wilcoxon-signed-rank-test-step-1">Wilcoxon-signed rank test (Step 1)</h4>
<p>The Wilcoxon-signed rank test requires us to calculate the absolute differences in the pairs of data and then rank them. First, we take the differences in the paired values.</p>
</section>
<section id="wilcoxon-signed-rank-test-step-2" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="wilcoxon-signed-rank-test-step-2">Wilcoxon-signed rank test (Step 2)</h4>
<p>Next, we take the absolute value of the differences, using the <code>.abs</code> method, and place them in the <code>abs_diff</code> column.</p>
</section>
<section id="wilcoxon-signed-rank-test-step-3" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="wilcoxon-signed-rank-test-step-3">Wilcoxon-signed rank test (Step 3)</h4>
<p>Then, we rank these absolute differences using the <code>rankdata</code> method from <code>scipy.stats</code>.</p>
</section>
<section id="wilcoxon-signed-rank-test-step-4" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="wilcoxon-signed-rank-test-step-4">Wilcoxon-signed rank test (Step 4)</h4>
<p>The last part of our calculation involves calculating a test statistic called W. W uses the signs of the diff column to split the ranks into two groups: one for rows with negative differences and one for positive differences. T-minus is defined as the sum of the ranks with negative differences, and T-plus is the sum of the ranks with positive differences. For this example, all the differences are negative, so the T-minus value is the sum of the five ranks, and T-plus is zero. The test statistic W is the smaller of T-minus and T-plus, which in this case, is zero. We can calculate W, and its corresponding p-value, using a <code>pingouin</code> method instead of manual calculation.</p>
</section>
<section id="implementation-with-pingouin.wilcoxon" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="implementation-with-pingouin.wilcoxon">Implementation with <code>pingouin.wilcoxon()</code></h4>
<p>The <code>.wilcoxon</code> method from <code>pingouin</code> takes very similar arguments to the <code>.ttest</code> method, except it doesn’t have a paired argument. The function returns a W value of zero - the same as our manual calculation! This corresponds to a p-value of around three percent, which is over ten times larger than the p-value from the t-test, so we should feel more confident with this result given the small sample size. The Wilcoxon test indicates that we do not have evidence that the 2008 Republican percentages are smaller than the 2012 percentages using this small sample of five rows.</p>
</section>
</section>
<section id="exercise-4.2.1" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="exercise-4.2.1"><span class="header-section-number">4.4</span> Exercise 4.2.1</h3>
<section id="wilcoxon-signed-rank-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="wilcoxon-signed-rank-test">Wilcoxon signed-rank test</h4>
<p>You’ll explore the difference between the proportion of county-level votes for the Democratic candidate in 2012 and 2016 to identify if the difference is significant.</p>
</section>
<section id="instructions-18" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-18">Instructions</h4>
<ol type="1">
<li>Conduct a paired t-test on the percentage columns using an appropriate alternative hypothesis.</li>
<li>Conduct a Wilcoxon-signed rank test on the same columns.</li>
</ol>
<div id="efe5da0f" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>sample_dem_data <span class="op">=</span> pd.read_feather(<span class="st">'datasets/dem_votes_potus_12_16.feather'</span>)</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Conduct a paired t-test on dem_percent_12 and dem_percent_16</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>paired_test_results <span class="op">=</span> pingouin.ttest(x<span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_12'</span>],</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_16'</span>], paired<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Print paired t-test results</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(paired_test_results)</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Conduct a Wilcoxon test on dem_percent_12 and dem_percent_16</span></span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>wilcoxon_test_results <span class="op">=</span> pingouin.wilcoxon(x<span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_12'</span>],</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_16'</span>])</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Print Wilcoxon test results</span></span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(wilcoxon_test_results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                T  dof alternative          p-val         CI95%   cohen-d  \
T-test  30.298384  499   two-sided  3.600634e-115  [6.39, 7.27]  0.454202   

              BF10  power  
T-test  2.246e+111    1.0  
           W-val alternative         p-val       RBC      CLES
Wilcoxon  2401.0   two-sided  1.780396e-77  0.961661  0.644816</code></pre>
</div>
</div>
</section>
</section>
<section id="chapter-4.3-non-parametric-anova-and-unpaired-t-tests" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="chapter-4.3-non-parametric-anova-and-unpaired-t-tests"><span class="header-section-number">4.5</span> Chapter 4.3: Non-parametric ANOVA and unpaired t-tests</h3>
<p>In the previous chapter <a href="#sec-Chapter4.2" class="quarto-xref">Section&nbsp;4.3</a>, we explored some non-parametric techniques and how they compare to their parametric counterparts. We’ll continue on that theme here focusing on non-parametric alternatives to tests of independent numeric samples.</p>
<section id="wilcoxon-mann-whitney-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="wilcoxon-mann-whitney-test">Wilcoxon-Mann-Whitney test</h4>
<p>We can avoid assumptions about normally distributed data by performing hypothesis tests on the ranks of a numeric input. The Wilcoxon-Mann-Whitney test is, very roughly speaking, a t-test on ranked data. This test is similar to the Wilcoxon test we saw in the last video, but works on unpaired data instead.</p>
</section>
<section id="wilcoxon-mann-whitney-test-setup" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="wilcoxon-mann-whitney-test-setup">Wilcoxon-Mann-Whitney test setup</h4>
<p>Let’s return to the StackOverflow survey and the relationship between converted compensation and the age respondents began coding. We start by focusing on just those two columns in a new DataFrame called <code>age_vs_comp</code>. To conduct a Wilcoxon-Mann-Whitney test with <code>pingouin</code>, we first need to convert our data from long to wide format. This is accomplished with the <code>pivot</code> method from pandas, which unlike <code>pivot_table</code>, does not aggregate; instead, it returns the raw values for each group across the rows. We now have our data in two columns named adult and child with the values corresponding to the <code>converted_comp</code> entries for each row. An adult value of NaN corresponds to a child entry and a child value of NaN corresponds to an adult entry.</p>
</section>
<section id="wilcoxon-mann-whitney-test-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="wilcoxon-mann-whitney-test-1">Wilcoxon-Mann-Whitney test</h4>
<p>Let’s set a significance level of one percent. We can run a Wilcoxon-Mann-Whitney test using <code>mwu</code> from <code>pingouin</code>. It accepts x and y arguments corresponding to the two columns of numbers we want to compare, in this case, child and adult. alternative sets the type of alternative hypothesis, in this case, that those who code first as children have a higher income than those who code first as adults, which is a right-tailed test. Here, the p-value is shown as around ten to the negative nineteenth power, which is significantly smaller than the significance level.</p>
</section>
<section id="kruskal-wallis-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="kruskal-wallis-test">Kruskal-Wallis test</h4>
<p>In the same way that ANOVA extends t-tests to more than two groups, the Kruskal-Wallis test extends the Wilcoxon-Mann-Whitney test to more than two groups. That is, the Kruskal-Wallis test is a non-parametric version of ANOVA. We use the <code>Kruskal</code> method from <code>pingouin</code> to perform a Kruskal-Wallis test to investigate if there is a difference in converted_comp between job satisfaction groups. Unlike the Wilcoxon-Mann-Whitney test, we don’t need to pivot our data here since the <code>Kruskal</code> method works on long data. We pass in <code>stack_overflow</code> as data, the dependent variable, dv, as <code>converted_comp</code>, and we are comparing between the groups of <code>job_sat</code>. Again, the p-value here is very small and smaller than our significance level. This provides evidence that at least one of the mean compensation totals is different than the others across these five job satisfaction groups.</p>
</section>
</section>
<section id="exercise-4.3.1" class="level3" data-number="4.6">
<h3 data-number="4.6" class="anchored" data-anchor-id="exercise-4.3.1"><span class="header-section-number">4.6</span> Exercise 4.3.1</h3>
<section id="wilcoxon-mann-whitney" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="wilcoxon-mann-whitney">Wilcoxon-Mann-Whitney</h4>
<p>Another class of non-parametric hypothesis tests are called <em>rank sum tests</em>. Ranks are the positions of numeric values from smallest to largest. Think of them as positions in running events: whoever has the fastest (smallest) time is rank 1, second fastest is rank 2, and so on.</p>
<p>By calculating on the ranks of data instead of the actual values, you can avoid making assumptions about the distribution of the test statistic. It’s more robust in the same way that a median is more robust than a mean.</p>
<p>One common rank-based test is the Wilcoxon-Mann-Whitney test, which is like a non-parametric t-test.</p>
</section>
<section id="instructions-19" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-19">Instructions</h4>
<ul>
<li>Select <code>weight_kilograms</code> and late from <code>late_shipments</code>, assigning the name <code>weight_vs_late</code>.</li>
<li>Convert <code>weight_vs_late</code> from long-to-wide format, setting columns to <code>'late'</code>.</li>
<li>Run a Wilcoxon-Mann-Whitney test for a difference in <code>weight_kilograms</code> when the shipment was late and on-time.</li>
</ul>
<div id="8ceceaba" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Select the weight_kilograms and late columns</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>weight_vs_late <span class="op">=</span> late_shipments[[<span class="st">'weight_kilograms'</span>, <span class="st">'late'</span>]]</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert weight_vs_late into wide format</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>weight_vs_late_wide <span class="op">=</span> weight_vs_late.pivot(columns<span class="op">=</span><span class="st">'late'</span>, </span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>                                           values<span class="op">=</span><span class="st">'weight_kilograms'</span>)</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Run a two-sided Wilcoxon-Mann-Whitney test on weight_kilograms vs. late</span></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>wmw_test <span class="op">=</span> pingouin.mwu(x<span class="op">=</span>weight_vs_late_wide[<span class="st">'No'</span>],</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span> weight_vs_late_wide[<span class="st">'Yes'</span>])</span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the test results</span></span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(wmw_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       U-val alternative     p-val       RBC      CLES
MWU  19134.0   two-sided  0.000014 -0.331902  0.334049</code></pre>
</div>
</div>
</section>
</section>
<section id="exercise-4.3.2" class="level3" data-number="4.7">
<h3 data-number="4.7" class="anchored" data-anchor-id="exercise-4.3.2"><span class="header-section-number">4.7</span> Exercise 4.3.2</h3>
<section id="kruskal-wallis" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="kruskal-wallis">Kruskal-Wallis</h4>
<p>Recall that the Kruskal-Wallis test is a non-parametric version of an ANOVA test, comparing the means across multiple groups.</p>
</section>
<section id="instructions-20" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="instructions-20">Instructions</h4>
<ul>
<li>Run a Kruskal-Wallis test on <code>weight_kilograms</code> between the different shipment modes in <code>late_shipments</code>.</li>
</ul>
<div id="0b9cc9dc" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Run a Kruskal-Wallis test on weight_kilograms vs. shipment_mode</span></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>kw_test <span class="op">=</span> pingouin.kruskal(data<span class="op">=</span>late_shipments, dv<span class="op">=</span><span class="st">'weight_kilograms'</span>,</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>between<span class="op">=</span> <span class="st">'shipment_mode'</span>)</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(kw_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                Source  ddof1           H         p-unc
Kruskal  shipment_mode      2  125.096618  6.848799e-28</code></pre>
</div>
</div>
</section>
<section id="conclusion" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="conclusion">Conclusion</h4>
<p><em>The Kruskal-Wallis test yielded a very small p-value, so there is evidence that at least one of the three groups of shipment mode has a different weight distribution than the others. Th Kruskal-Wallis test is comparable to an ANOVA, which tests for a difference in means across multiple groups.</em></p>
</section>
</section>
</section>
<section id="reference" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="reference"><span class="header-section-number">5</span> Reference</h2>
<p>Hypothesis Testing in Python Course for Associate Data Scientist in Python Carrer Track in DataCamp Inc by James Chapman.</p>
<!-- -->

</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb52" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Hypothesis Testing in Python"</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: "Lawal's Note"</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliation: "Associate Data Science Course in Python by DataCamp Inc"</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2025-01-14"</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> true</span></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a><span class="an">highlight-style:</span><span class="co"> pygments</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a><span class="co">  pdf:</span></span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a><span class="co">    geometry:</span></span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a><span class="co">      - top=30mm</span></span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a><span class="co">      - left=20mm</span></span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-width: 4</span></span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-height: 3</span></span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a><span class="co">    pdf-engine: xelatex</span></span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a><span class="co">  docx: default</span></span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a><span class="co">  warning: false</span></span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a><span class="co">  echo: true</span></span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a><span class="co">  eval: true</span></span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a><span class="co">  output: true</span></span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a><span class="co">  error: false</span></span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a><span class="co">  cache: false</span></span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a><span class="co">  include: true</span></span>
<span id="cb52-30"><a href="#cb52-30" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb52-31"><a href="#cb52-31" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb52-32"><a href="#cb52-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-33"><a href="#cb52-33" aria-hidden="true" tabindex="-1"></a><span class="al">![](SOA_Hypo.jpg)</span></span>
<span id="cb52-34"><a href="#cb52-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-35"><a href="#cb52-35" aria-hidden="true" tabindex="-1"></a><span class="fu">## Chapter 1: Hypothesis Testing Fundamentals {#sec-Chapter1}</span></span>
<span id="cb52-36"><a href="#cb52-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-37"><a href="#cb52-37" aria-hidden="true" tabindex="-1"></a>How does hypothesis testing work and what problems can it solve? To find out, you’ll walk through the workflow for a one sample proportion test. In doing so, you'll encounter important concepts like z-scores, p-values, and false negative and false positive errors.</span>
<span id="cb52-38"><a href="#cb52-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-39"><a href="#cb52-39" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 1.1: Hypothesis tests and z-scores {#sec-Chapter1.1}</span></span>
<span id="cb52-40"><a href="#cb52-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-41"><a href="#cb52-41" aria-hidden="true" tabindex="-1"></a>Hi, I'm James. Welcome to this course on hypothesis testing in Python. To start, let's look at a real-world example where a hypothesis test was crucial in a decision-making process.</span>
<span id="cb52-42"><a href="#cb52-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-43"><a href="#cb52-43" aria-hidden="true" tabindex="-1"></a><span class="fu">#### A/B testing {.unnumbered}</span></span>
<span id="cb52-44"><a href="#cb52-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-45"><a href="#cb52-45" aria-hidden="true" tabindex="-1"></a>In 2013, Electronic Arts, or EA, launched a video game called SimCity 5. Leading up to its release, they wanted to increase pre-order sales. They used an experimental design technique called A/B testing, which has roots in hypothesis testing, to test different advertising scenarios and see which improved sales the most. Website visitors were split into a control group and a treatment group. Each group saw a different version of the game's pre-order sales page.</span>
<span id="cb52-46"><a href="#cb52-46" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>1 Image credit: "Electronic Arts" by majaX1 CC BY-NC-SA 2.0</span>
<span id="cb52-47"><a href="#cb52-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-48"><a href="#cb52-48" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Retail webpage A/B test {.unnumbered}</span></span>
<span id="cb52-49"><a href="#cb52-49" aria-hidden="true" tabindex="-1"></a>Here's each version of the SimCity 5 pre-order page. The control group saw the version with a banner advertising money off their next purchase with each pre-order. The treatment group saw the version without the banner. EA compared the percentage of checkouts for the two groups to see which performed best. Our naive guess would be that the advertisement increased pre-order sales.</span>
<span id="cb52-50"><a href="#cb52-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-51"><a href="#cb52-51" aria-hidden="true" tabindex="-1"></a><span class="fu">#### A/B test results {.unnumbered}</span></span>
<span id="cb52-52"><a href="#cb52-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-53"><a href="#cb52-53" aria-hidden="true" tabindex="-1"></a>The results of the A/B test were surprising. The treatment page without the advertisement resulted in 43 percent higher sales than the control page with the advert. The experiment proved that our intuition that more discount adverts would result in more sales was false. We might ask ourselves, was the 43 percent difference a meaningful difference between the control and treatment groups, or was it just random chance? To get this answer, we'd need the original dataset from EA, which isn't publicly available. However, the method to answering this question of significance would involve techniques from both the Sampling in Python course and from this course.</span>
<span id="cb52-54"><a href="#cb52-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-55"><a href="#cb52-55" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Stack Overflow Developer Survey 2020 {.unnumbered}</span></span>
<span id="cb52-56"><a href="#cb52-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-57"><a href="#cb52-57" aria-hidden="true" tabindex="-1"></a>Each year, Stack Overflow surveys its users, who are primarily software developers, about themselves, how they use Stack Overflow, their work, and the development tools they use. In this course, we'll look at a subset of the survey responses from users who identified as Data Scientists.</span>
<span id="cb52-58"><a href="#cb52-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-59"><a href="#cb52-59" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Hypothesizing about the mean {.unnumbered}</span></span>
<span id="cb52-60"><a href="#cb52-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-61"><a href="#cb52-61" aria-hidden="true" tabindex="-1"></a>Let's hypothesize that the mean annual compensation of the population of data scientists is 110,000 dollars. We can initially examine the mean annual compensation from the sample survey data. Annual compensation, converted to dollars, is stored in the <span class="in">`converted_comp`</span> column. The sample mean is a type of point estimate, which is another name for a summary statistic. We can calculate it with pandas using the <span class="in">`.mean`</span> method on the <span class="in">`converted_comp`</span> Series. The result is different from our hypothesis, but is it meaningfully different?</span>
<span id="cb52-62"><a href="#cb52-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-63"><a href="#cb52-63" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Generating a bootstrap distribution {.unnumbered}</span></span>
<span id="cb52-64"><a href="#cb52-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-65"><a href="#cb52-65" aria-hidden="true" tabindex="-1"></a>To answer this, we need to generate a bootstrap distribution of sample means. This is done by resampling the dataset, calculating the sample mean for that resample, then repeating those steps to create a list of sample means.</span>
<span id="cb52-66"><a href="#cb52-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-67"><a href="#cb52-67" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>1 [Bootstrap distributions are taught in Chapter 4 of Sampling in Python(https://lawaloa.github.io/Sampling/#chapter-4-bootstrap-distributions){target="_blank"}</span>
<span id="cb52-68"><a href="#cb52-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-69"><a href="#cb52-69" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Visualizing the bootstrap distribution {.unnumbered}</span></span>
<span id="cb52-70"><a href="#cb52-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-71"><a href="#cb52-71" aria-hidden="true" tabindex="-1"></a>The histogram of the bootstrap distribution is a bell shape. Its bell shape means that it's roughly normally distributed. Notice that 110,000 is on the left of the distribution.</span>
<span id="cb52-72"><a href="#cb52-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-73"><a href="#cb52-73" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Standard error {.unnumbered}</span></span>
<span id="cb52-74"><a href="#cb52-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-75"><a href="#cb52-75" aria-hidden="true" tabindex="-1"></a>Recall that the standard deviation of the sample statistics in the bootstrap distribution estimates the standard error of the statistic.</span>
<span id="cb52-76"><a href="#cb52-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-77"><a href="#cb52-77" aria-hidden="true" tabindex="-1"></a><span class="fu">#### z-scores {.unnumbered}</span></span>
<span id="cb52-78"><a href="#cb52-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-79"><a href="#cb52-79" aria-hidden="true" tabindex="-1"></a>Since variables have arbitrary units and ranges, before we test our hypothesis, we need to standardize the values. A common way of standardizing values is to subtract the mean, and divide by the standard deviation. For hypothesis testing, we use a variation where we take the sample statistic, subtract the hypothesized parameter value, and divide by the standard error. The result is called a z-score.</span>
<span id="cb52-80"><a href="#cb52-80" aria-hidden="true" tabindex="-1"></a>Here are the values we calculated earlier. The sample mean annual compensation for data scientists of around 120,000 dollars, minus the hypothesized compensation of 110,000, divided by the standard error gives a z-score of one-point-seven-zero-seven.</span>
<span id="cb52-81"><a href="#cb52-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-82"><a href="#cb52-82" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-83"><a href="#cb52-83" aria-hidden="true" tabindex="-1"></a>\text{Standard value} = \frac{\text{value} - \text{mean}}{\text{standard deviation}}</span>
<span id="cb52-84"><a href="#cb52-84" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-85"><a href="#cb52-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-86"><a href="#cb52-86" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-87"><a href="#cb52-87" aria-hidden="true" tabindex="-1"></a>z = \frac{\text{sample statistic} - \text{hypothesized parameter value}}{\text{standard error}}</span>
<span id="cb52-88"><a href="#cb52-88" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-89"><a href="#cb52-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-90"><a href="#cb52-90" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Testing the hypothesis {.unnumbered}</span></span>
<span id="cb52-91"><a href="#cb52-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-92"><a href="#cb52-92" aria-hidden="true" tabindex="-1"></a>Is that a big or small number? Determining that is the goal of this course.</span>
<span id="cb52-93"><a href="#cb52-93" aria-hidden="true" tabindex="-1"></a>In particular, we can now state one of the uses of hypothesis testing: determining whether a sample statistic is close to or far away from an expected value.</span>
<span id="cb52-94"><a href="#cb52-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-95"><a href="#cb52-95" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Standard normal (z) distribution {.unnumbered}</span></span>
<span id="cb52-96"><a href="#cb52-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-97"><a href="#cb52-97" aria-hidden="true" tabindex="-1"></a>One final thing. Here's a plot of the probability density function for the standard normal distribution, which is a normal distribution with mean of zero and standard deviation of one. It's often called the z-distribution, and z-scores are related to this distribution. We'll encounter the z-distribution throughout this course.</span>
<span id="cb52-98"><a href="#cb52-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-99"><a href="#cb52-99" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 1.1.1</span></span>
<span id="cb52-100"><a href="#cb52-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-101"><a href="#cb52-101" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating the sample mean {.unnumbered}</span></span>
<span id="cb52-102"><a href="#cb52-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-103"><a href="#cb52-103" aria-hidden="true" tabindex="-1"></a>The <span class="in">`late_shipments`</span> dataset contains supply chain data on the delivery of medical supplies. Each row represents one delivery of a part. The <span class="in">`late`</span> columns denotes whether or not the part was delivered late. A value of <span class="in">`"Yes"`</span> means that the part was delivered late, and a value of <span class="in">`"No"`</span> means the part was delivered on time.</span>
<span id="cb52-104"><a href="#cb52-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-105"><a href="#cb52-105" aria-hidden="true" tabindex="-1"></a>You'll begin your analysis by calculating a point estimate (or sample statistic), namely the proportion of late shipments.</span>
<span id="cb52-106"><a href="#cb52-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-107"><a href="#cb52-107" aria-hidden="true" tabindex="-1"></a>In pandas, a value's proportion in a categorical DataFrame column can be quickly calculated using the syntax:</span>
<span id="cb52-108"><a href="#cb52-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-109"><a href="#cb52-109" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-110"><a href="#cb52-110" aria-hidden="true" tabindex="-1"></a><span class="in">prop = (df['col'] == val).mean()</span></span>
<span id="cb52-111"><a href="#cb52-111" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-112"><a href="#cb52-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-113"><a href="#cb52-113" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions</span></span>
<span id="cb52-114"><a href="#cb52-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-115"><a href="#cb52-115" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Print the <span class="in">`late_shipments`</span> dataset.</span>
<span id="cb52-116"><a href="#cb52-116" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Calculate the proportion of late shipments in the sample; that is, the mean cases where the <span class="in">`late`</span> column is <span class="in">`"Yes"`</span>.</span>
<span id="cb52-117"><a href="#cb52-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-120"><a href="#cb52-120" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-121"><a href="#cb52-121" aria-hidden="true" tabindex="-1"></a><span class="co"># Import pandas</span></span>
<span id="cb52-122"><a href="#cb52-122" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-123"><a href="#cb52-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-124"><a href="#cb52-124" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-125"><a href="#cb52-125" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-126"><a href="#cb52-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-127"><a href="#cb52-127" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the late_shipments dataset</span></span>
<span id="cb52-128"><a href="#cb52-128" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(late_shipments)</span>
<span id="cb52-129"><a href="#cb52-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-130"><a href="#cb52-130" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the proportion of late shipments</span></span>
<span id="cb52-131"><a href="#cb52-131" aria-hidden="true" tabindex="-1"></a>late_prop_samp <span class="op">=</span> (late_shipments[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb52-132"><a href="#cb52-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-133"><a href="#cb52-133" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb52-134"><a href="#cb52-134" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(late_prop_samp)</span>
<span id="cb52-135"><a href="#cb52-135" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-136"><a href="#cb52-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-137"><a href="#cb52-137" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 1.1.2</span></span>
<span id="cb52-138"><a href="#cb52-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-139"><a href="#cb52-139" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating a z-score {.unnumbered}</span></span>
<span id="cb52-140"><a href="#cb52-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-141"><a href="#cb52-141" aria-hidden="true" tabindex="-1"></a>Since variables have arbitrary ranges and units, we need to standardize them. For example, a hypothesis test that gave different answers if the variables were in Euros instead of US dollars would be of little value. Standardization avoids that.</span>
<span id="cb52-142"><a href="#cb52-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-143"><a href="#cb52-143" aria-hidden="true" tabindex="-1"></a>One standardized value of interest in a hypothesis test is called a z-score. To calculate it, you need three numbers: the sample statistic (point estimate), the hypothesized statistic, and the standard error of the statistic (estimated from the bootstrap distribution).</span>
<span id="cb52-144"><a href="#cb52-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-145"><a href="#cb52-145" aria-hidden="true" tabindex="-1"></a>The sample statistic is available as late_prop_samp.</span>
<span id="cb52-146"><a href="#cb52-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-147"><a href="#cb52-147" aria-hidden="true" tabindex="-1"></a>late_shipments_boot_distn is a bootstrap distribution of the proportion of late shipments, available as a list.</span>
<span id="cb52-148"><a href="#cb52-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-149"><a href="#cb52-149" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-150"><a href="#cb52-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-151"><a href="#cb52-151" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Hypothesize that the proportion of late shipments is 6%.</span>
<span id="cb52-152"><a href="#cb52-152" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate the standard error from the standard deviation of the bootstrap distribution.</span>
<span id="cb52-153"><a href="#cb52-153" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate the z-score.</span>
<span id="cb52-154"><a href="#cb52-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-157"><a href="#cb52-157" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-158"><a href="#cb52-158" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-159"><a href="#cb52-159" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-160"><a href="#cb52-160" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-161"><a href="#cb52-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-162"><a href="#cb52-162" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-163"><a href="#cb52-163" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-164"><a href="#cb52-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-165"><a href="#cb52-165" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the late_shipments dataset</span></span>
<span id="cb52-166"><a href="#cb52-166" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(late_shipments)</span>
<span id="cb52-167"><a href="#cb52-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-168"><a href="#cb52-168" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the proportion of late shipments</span></span>
<span id="cb52-169"><a href="#cb52-169" aria-hidden="true" tabindex="-1"></a>late_prop_samp <span class="op">=</span> (late_shipments[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb52-170"><a href="#cb52-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-171"><a href="#cb52-171" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb52-172"><a href="#cb52-172" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(late_prop_samp)</span>
<span id="cb52-173"><a href="#cb52-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-174"><a href="#cb52-174" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed for reproducibility</span></span>
<span id="cb52-175"><a href="#cb52-175" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb52-176"><a href="#cb52-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-177"><a href="#cb52-177" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of bootstrap samples</span></span>
<span id="cb52-178"><a href="#cb52-178" aria-hidden="true" tabindex="-1"></a>n_bootstrap_samples <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb52-179"><a href="#cb52-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-180"><a href="#cb52-180" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate bootstrap distribution</span></span>
<span id="cb52-181"><a href="#cb52-181" aria-hidden="true" tabindex="-1"></a>late_shipments_boot_distn <span class="op">=</span> [</span>
<span id="cb52-182"><a href="#cb52-182" aria-hidden="true" tabindex="-1"></a>    (late_shipments.sample(frac<span class="op">=</span><span class="dv">1</span>, replace<span class="op">=</span><span class="va">True</span>)[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb52-183"><a href="#cb52-183" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_bootstrap_samples)</span>
<span id="cb52-184"><a href="#cb52-184" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb52-185"><a href="#cb52-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-186"><a href="#cb52-186" aria-hidden="true" tabindex="-1"></a><span class="co"># Hypothesize that the proportion is 6%</span></span>
<span id="cb52-187"><a href="#cb52-187" aria-hidden="true" tabindex="-1"></a>late_prop_hyp <span class="op">=</span> <span class="fl">0.06</span></span>
<span id="cb52-188"><a href="#cb52-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-189"><a href="#cb52-189" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the standard error</span></span>
<span id="cb52-190"><a href="#cb52-190" aria-hidden="true" tabindex="-1"></a>std_error <span class="op">=</span> np.std(late_shipments_boot_distn, ddof<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb52-191"><a href="#cb52-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-192"><a href="#cb52-192" aria-hidden="true" tabindex="-1"></a><span class="co"># Find z-score of late_prop_samp</span></span>
<span id="cb52-193"><a href="#cb52-193" aria-hidden="true" tabindex="-1"></a>z_score <span class="op">=</span> (late_prop_samp <span class="op">-</span> late_prop_hyp)<span class="op">/</span>std_error</span>
<span id="cb52-194"><a href="#cb52-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-195"><a href="#cb52-195" aria-hidden="true" tabindex="-1"></a><span class="co"># Print z_score</span></span>
<span id="cb52-196"><a href="#cb52-196" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(z_score)</span>
<span id="cb52-197"><a href="#cb52-197" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-198"><a href="#cb52-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-199"><a href="#cb52-199" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 1.2: p-values {#sec-Chapter1.2}</span></span>
<span id="cb52-200"><a href="#cb52-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-201"><a href="#cb52-201" aria-hidden="true" tabindex="-1"></a>Hypothesis tests are like criminal trials.</span>
<span id="cb52-202"><a href="#cb52-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-203"><a href="#cb52-203" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Criminal trials {.unnumbered}</span></span>
<span id="cb52-204"><a href="#cb52-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-205"><a href="#cb52-205" aria-hidden="true" tabindex="-1"></a>There are two possible true states: the defendant either committed the crime, or didn't. There are also two possible outcomes: a guilty or not guilty verdict. The initial assumption is that the defendant is not guilty, and the prosecution team must present evidence beyond a reasonable doubt that the defendant committed the crime for a guilty verdict to be given.</span>
<span id="cb52-206"><a href="#cb52-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-207"><a href="#cb52-207" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Age of first programming experience {.unnumbered}</span></span>
<span id="cb52-208"><a href="#cb52-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-209"><a href="#cb52-209" aria-hidden="true" tabindex="-1"></a>Let's return to the Stack Overflow survey. The <span class="in">`age_first_code_cut`</span> variable classifies when the user began programming. If they were 14 or older, they are classified as adult; otherwise, child. Suppose previous research suggests that 35 percent of software developers programmed as children. This raises a question answerable with our dataset. Does our sample provide evidence that a greater proportion of data scientists started programming as children?</span>
<span id="cb52-210"><a href="#cb52-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-211"><a href="#cb52-211" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Definitions {.unnumbered}</span></span>
<span id="cb52-212"><a href="#cb52-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-213"><a href="#cb52-213" aria-hidden="true" tabindex="-1"></a>Let's specify some definitions. A hypothesis is a statement about a population parameter. We don't know the true value of this population parameter; we can only make inferences about it from the data. Hypothesis tests compare two competing hypotheses. These two hypotheses are the null hypothesis, representing the existing idea, and the alternative hypothesis, representing a new idea that challenges the existing one. They are denoted H-naught and H-A, respectively. Here, the null hypothesis is that the proportion of data scientists that started programming as children follows the research on software developers, at 35 percent. The alternative hypothesis is that the percentage is greater than 35.</span>
<span id="cb52-214"><a href="#cb52-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-215"><a href="#cb52-215" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>1 "Naught" is British English for "zero". For historical reasons, "H-naught" is the international convention for pronouncing the null hypothesis.</span>
<span id="cb52-216"><a href="#cb52-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-217"><a href="#cb52-217" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Criminal trials vs. hypothesis testing {.unnumbered}</span></span>
<span id="cb52-218"><a href="#cb52-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-219"><a href="#cb52-219" aria-hidden="true" tabindex="-1"></a>Returning to our criminal trial comparison, the defendant can be either guilty or not guilty, and likewise, only one of the hypotheses can be true. Initially, the defendant is assumed to be not guilty and, similarly, we initially assume that the null hypothesis is true. This only changes if the sample provides enough evidence to reject it. Rather than saying we accept the alternative hypothesis, it is convention to refer to rejecting the null hypothesis, or failing to reject the null hypothesis. If the evidence is "beyond a reasonable doubt" that the defendant committed the crime, then a "guilty" verdict is given. The hypothesis testing equivalent of "beyond a reasonable doubt" is known as the significance level - more on this later in the chapter.</span>
<span id="cb52-220"><a href="#cb52-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-221"><a href="#cb52-221" aria-hidden="true" tabindex="-1"></a><span class="fu">#### One-tailed and two-tailed tests {.unnumbered}</span></span>
<span id="cb52-222"><a href="#cb52-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-223"><a href="#cb52-223" aria-hidden="true" tabindex="-1"></a>The tails of a distribution are the left and right edges of its PDF. Hypothesis tests determine whether the sample statistics lie in the tails of the null distribution, which is the distribution of the statistic if the null hypothesis was true. There are three types of tests, and the phrasing of the alternative hypothesis determines which type we should use. If we are checking for a difference compared to a hypothesized value, we look for extreme values in either tail and perform a two-tailed test. If the alternative hypothesis uses language like "less" or "fewer", we perform a left-tailed test. Words like "greater" or "exceeds" correspond to a right-tailed test. For the Stack Overflow hypothesis test, we need a right-tailed test since we are looking for extreme values in the right tail.</span>
<span id="cb52-224"><a href="#cb52-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-225"><a href="#cb52-225" aria-hidden="true" tabindex="-1"></a><span class="fu">#### p-values {.unnumbered}</span></span>
<span id="cb52-226"><a href="#cb52-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-227"><a href="#cb52-227" aria-hidden="true" tabindex="-1"></a>p-values measure the strength of support for the null hypothesis, or in other words, they measure the probability of obtaining a result, assuming the null hypothesis is true. Large p-values mean our statistic is producing a result that is likely not in a tail of our null distribution, and chance could be a good explanation for the result. Small p-values mean our statistic is producing a result likely in the tail of our null distribution. Because p-values are probabilities, they are always between zero and one.</span>
<span id="cb52-228"><a href="#cb52-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-229"><a href="#cb52-229" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating the z-score {.unnumbered}</span></span>
<span id="cb52-230"><a href="#cb52-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-231"><a href="#cb52-231" aria-hidden="true" tabindex="-1"></a>To calculate the p-value, we must first calculate the z-score. We calculate the sample statistic, in this case the proportion of data scientists who started programming as children. The hypothesized value from the null hypothesis is 35 percent. We get the standard error from the standard deviation of the bootstrap distribution, and the z-score is the difference between the proportions, divided by the standard error.</span>
<span id="cb52-232"><a href="#cb52-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-233"><a href="#cb52-233" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating the p-value {.unnumbered}</span></span>
<span id="cb52-234"><a href="#cb52-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-235"><a href="#cb52-235" aria-hidden="true" tabindex="-1"></a>We pass the z-score to the standard normal <span class="in">`CDF`</span>, <span class="in">`norm.cdf`</span>, from <span class="in">`scipy.stats`</span> with the default values of mean 0 and standard deviation of 1. As we're performing a right-tail test, not a left-tail test, the p-value is calculated by taking one minus the <span class="in">`norm.cdf`</span> result. The p-value is three out of 100,000.</span>
<span id="cb52-236"><a href="#cb52-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-237"><a href="#cb52-237" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 1.2.1</span></span>
<span id="cb52-238"><a href="#cb52-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-239"><a href="#cb52-239" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating p-values {.unnumbered}</span></span>
<span id="cb52-240"><a href="#cb52-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-241"><a href="#cb52-241" aria-hidden="true" tabindex="-1"></a>In order to determine whether to choose the null hypothesis or the alternative hypothesis, you need to calculate a p-value from the z-score.</span>
<span id="cb52-242"><a href="#cb52-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-243"><a href="#cb52-243" aria-hidden="true" tabindex="-1"></a>You'll now return to the late shipments dataset and the proportion of late shipments.</span>
<span id="cb52-244"><a href="#cb52-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-245"><a href="#cb52-245" aria-hidden="true" tabindex="-1"></a>The null hypothesis, $H_o$, is that the proportion of late shipments is six percent.</span>
<span id="cb52-246"><a href="#cb52-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-247"><a href="#cb52-247" aria-hidden="true" tabindex="-1"></a>The alternative hypothesis, $H_A$, is that the proportion of late shipments is **greater than** six percent.</span>
<span id="cb52-248"><a href="#cb52-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-249"><a href="#cb52-249" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-250"><a href="#cb52-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-251"><a href="#cb52-251" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate the z-score of <span class="in">`late_prop_samp`</span>.</span>
<span id="cb52-252"><a href="#cb52-252" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate the p-value for the z-score, using a right-tailed test.</span>
<span id="cb52-253"><a href="#cb52-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-256"><a href="#cb52-256" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-257"><a href="#cb52-257" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-258"><a href="#cb52-258" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-259"><a href="#cb52-259" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-260"><a href="#cb52-260" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb52-261"><a href="#cb52-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-262"><a href="#cb52-262" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-263"><a href="#cb52-263" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-264"><a href="#cb52-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-265"><a href="#cb52-265" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the proportion of late shipments</span></span>
<span id="cb52-266"><a href="#cb52-266" aria-hidden="true" tabindex="-1"></a>late_prop_samp <span class="op">=</span> (late_shipments[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb52-267"><a href="#cb52-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-268"><a href="#cb52-268" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed for reproducibility</span></span>
<span id="cb52-269"><a href="#cb52-269" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb52-270"><a href="#cb52-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-271"><a href="#cb52-271" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of bootstrap samples</span></span>
<span id="cb52-272"><a href="#cb52-272" aria-hidden="true" tabindex="-1"></a>n_bootstrap_samples <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb52-273"><a href="#cb52-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-274"><a href="#cb52-274" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate bootstrap distribution</span></span>
<span id="cb52-275"><a href="#cb52-275" aria-hidden="true" tabindex="-1"></a>late_shipments_boot_distn <span class="op">=</span> [</span>
<span id="cb52-276"><a href="#cb52-276" aria-hidden="true" tabindex="-1"></a>    (late_shipments.sample(frac<span class="op">=</span><span class="dv">1</span>, replace<span class="op">=</span><span class="va">True</span>)[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb52-277"><a href="#cb52-277" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_bootstrap_samples)</span>
<span id="cb52-278"><a href="#cb52-278" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb52-279"><a href="#cb52-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-280"><a href="#cb52-280" aria-hidden="true" tabindex="-1"></a><span class="co"># Hypothesize that the proportion is 6%</span></span>
<span id="cb52-281"><a href="#cb52-281" aria-hidden="true" tabindex="-1"></a>late_prop_hyp <span class="op">=</span> <span class="fl">0.06</span></span>
<span id="cb52-282"><a href="#cb52-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-283"><a href="#cb52-283" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the standard error</span></span>
<span id="cb52-284"><a href="#cb52-284" aria-hidden="true" tabindex="-1"></a>std_error <span class="op">=</span> np.std(late_shipments_boot_distn, ddof<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb52-285"><a href="#cb52-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-286"><a href="#cb52-286" aria-hidden="true" tabindex="-1"></a><span class="co"># Find z-score of late_prop_samp</span></span>
<span id="cb52-287"><a href="#cb52-287" aria-hidden="true" tabindex="-1"></a>z_score <span class="op">=</span> (late_prop_samp <span class="op">-</span> late_prop_hyp)<span class="op">/</span>std_error</span>
<span id="cb52-288"><a href="#cb52-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-289"><a href="#cb52-289" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the z-score of late_prop_samp</span></span>
<span id="cb52-290"><a href="#cb52-290" aria-hidden="true" tabindex="-1"></a>z_score <span class="op">=</span> (late_prop_samp <span class="op">-</span> late_prop_hyp)<span class="op">/</span>std_error</span>
<span id="cb52-291"><a href="#cb52-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-292"><a href="#cb52-292" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the p-value</span></span>
<span id="cb52-293"><a href="#cb52-293" aria-hidden="true" tabindex="-1"></a>p_value <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> norm.cdf(z_score, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb52-294"><a href="#cb52-294" aria-hidden="true" tabindex="-1"></a>                 </span>
<span id="cb52-295"><a href="#cb52-295" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the p-value</span></span>
<span id="cb52-296"><a href="#cb52-296" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(p_value)</span>
<span id="cb52-297"><a href="#cb52-297" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-298"><a href="#cb52-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-299"><a href="#cb52-299" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 1.3: Statistical significance</span></span>
<span id="cb52-300"><a href="#cb52-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-301"><a href="#cb52-301" aria-hidden="true" tabindex="-1"></a>Last time, we introduced p-values.</span>
<span id="cb52-302"><a href="#cb52-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-303"><a href="#cb52-303" aria-hidden="true" tabindex="-1"></a><span class="fu">#### p-value recap {.unnumbered}</span></span>
<span id="cb52-304"><a href="#cb52-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-305"><a href="#cb52-305" aria-hidden="true" tabindex="-1"></a>p-values quantify how much evidence there is for the null hypothesis. Large p-values indicate a lack of evidence for the alternative hypothesis, sticking with the assumed null hypothesis instead. Small p-values make us doubt this original assumption in favor of the alternative hypothesis. What defines the cutoff point between a small p-value and a large one?</span>
<span id="cb52-306"><a href="#cb52-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-307"><a href="#cb52-307" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Significance level {.unnumbered}</span></span>
<span id="cb52-308"><a href="#cb52-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-309"><a href="#cb52-309" aria-hidden="true" tabindex="-1"></a>The cutoff point is known as the significance level, and is denoted alpha. The appropriate significance level depends on the dataset and the discipline worked in. Five percent is the most common choice, but ten percent and one percent are also popular. The significance level gives us a decision process for which hypothesis to support. If the p-value is less than or equal to alpha, we reject the null hypothesis. Otherwise, we fail to reject it. It's important that we decide what the appropriate significance level should be before we run our test. Otherwise, there is a temptation to decide on a significance level that lets us choose the hypothesis we want.</span>
<span id="cb52-310"><a href="#cb52-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-311"><a href="#cb52-311" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating the p-value {.unnumbered}</span></span>
<span id="cb52-312"><a href="#cb52-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-313"><a href="#cb52-313" aria-hidden="true" tabindex="-1"></a>The workflow starts with setting the significance level, in this case point-zero-five. Next, we calculate the sample mean and assign the hypothesized mean. For the z-score, we also need the standard error, which we obtain from the bootstrap distribution. Then we calculate the z-score using the sample mean, hypothesized mean, and standard error, and use the standard normal CDF to get the p-value.</span>
<span id="cb52-314"><a href="#cb52-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-315"><a href="#cb52-315" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Making a decision {.unnumbered}</span></span>
<span id="cb52-316"><a href="#cb52-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-317"><a href="#cb52-317" aria-hidden="true" tabindex="-1"></a>In this case, the p-value of three times ten to the minus five is less than or equal to 0.5, so we reject the null hypothesis. We have strong evidence for the alternative hypothesis that the proportion of data scientists that started programming as children is greater than 35 percent.</span>
<span id="cb52-318"><a href="#cb52-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-319"><a href="#cb52-319" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Confidence intervals {.unnumbered}</span></span>
<span id="cb52-320"><a href="#cb52-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-321"><a href="#cb52-321" aria-hidden="true" tabindex="-1"></a>To get a sense of the potential values of the population parameter, it's common to choose a confidence interval level of one minus the significance level. For a significance level of point-zero-five, we'd use a 95 percent confidence interval. Here's the calculation using the quantile method. The interval provides a range of plausible values for the population proportion of data scientists that programmed as children.</span>
<span id="cb52-322"><a href="#cb52-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-323"><a href="#cb52-323" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Types of errors {.unnumbered}</span></span>
<span id="cb52-324"><a href="#cb52-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-325"><a href="#cb52-325" aria-hidden="true" tabindex="-1"></a>Returning to the criminal trial analogy, there are two possible truth states and two possible test outcomes, amounting to four combinations. Two of these indicate that the verdict was correct. If the defendant didn't commit the crime, but the verdict was guilty, they are wrongfully convicted. If the defendant committed the crime, but the verdict was not guilty, they got away with it. These are both errors in justice. Similarly, for hypothesis testing, there are two ways to get it right, and two types of error. If we support the alternative hypothesis when the null hypothesis was correct, we made a false positive error. If we support the null hypothesis when the alternative hypothesis was correct, we made a false negative error. These errors are sometimes known as type one and type two errors, respectively.</span>
<span id="cb52-326"><a href="#cb52-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-327"><a href="#cb52-327" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Possible errors in our example {.unnumbered}</span></span>
<span id="cb52-328"><a href="#cb52-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-329"><a href="#cb52-329" aria-hidden="true" tabindex="-1"></a>In the case of data scientists coding as children, if we had a p-value less than or equal to the significance level, and rejected the null hypothesis, it's possible we made a false positive error. Although we thought data scientists started coding as children at a higher rate, it may not be true in the whole population. Conversely, if the p-value was greater than the significance level, and we failed to reject the null hypothesis, it's possible we made a false negative error.</span>
<span id="cb52-330"><a href="#cb52-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-331"><a href="#cb52-331" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 1.3.1</span></span>
<span id="cb52-332"><a href="#cb52-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-333"><a href="#cb52-333" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating a confidence interval {.unnumbered}</span></span>
<span id="cb52-334"><a href="#cb52-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-335"><a href="#cb52-335" aria-hidden="true" tabindex="-1"></a>If you give a single estimate of a sample statistic, you are bound to be wrong by some amount. For example, the hypothesized proportion of late shipments was 6%. Even if evidence suggests the null hypothesis that the proportion of late shipments is equal to this, for any new sample of shipments, the proportion is likely to be a little different due to sampling variability. Consequently, it's a good idea to state a confidence interval. That is, you say, "we are 95% 'confident' that the proportion of late shipments is between A and B" (for some value of A and B).</span>
<span id="cb52-336"><a href="#cb52-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-337"><a href="#cb52-337" aria-hidden="true" tabindex="-1"></a>Sampling in Python <span class="co">[</span><span class="ot">demonstrated</span><span class="co">](https://campus.datacamp.com/courses/sampling-in-python/bootstrap-distributions-4?ex=10)</span> two methods for calculating confidence intervals. Here, you'll use quantiles of the bootstrap distribution to calculate the confidence interval.</span>
<span id="cb52-338"><a href="#cb52-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-339"><a href="#cb52-339" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-340"><a href="#cb52-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-341"><a href="#cb52-341" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate a 95% confidence interval from <span class="in">`late_shipments_boot_distn`</span> using the quantile method, labeling the lower and upper intervals <span class="in">`lower`</span> and <span class="in">`upper`</span>.</span>
<span id="cb52-342"><a href="#cb52-342" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Does the confidence interval match up with the conclusion to stick with the original assumption that 6% is a reasonable value for the unknown population parameter?</span>
<span id="cb52-343"><a href="#cb52-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-344"><a href="#cb52-344" aria-hidden="true" tabindex="-1"></a>Yes, since 0.06 is included in the 95% confidence interval and we failed to reject $H_O$ due to a large p-value, the results are similar.</span>
<span id="cb52-345"><a href="#cb52-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-348"><a href="#cb52-348" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-349"><a href="#cb52-349" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-350"><a href="#cb52-350" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-351"><a href="#cb52-351" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-352"><a href="#cb52-352" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb52-353"><a href="#cb52-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-354"><a href="#cb52-354" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-355"><a href="#cb52-355" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-356"><a href="#cb52-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-357"><a href="#cb52-357" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the proportion of late shipments</span></span>
<span id="cb52-358"><a href="#cb52-358" aria-hidden="true" tabindex="-1"></a>late_prop_samp <span class="op">=</span> (late_shipments[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb52-359"><a href="#cb52-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-360"><a href="#cb52-360" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed for reproducibility</span></span>
<span id="cb52-361"><a href="#cb52-361" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb52-362"><a href="#cb52-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-363"><a href="#cb52-363" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of bootstrap samples</span></span>
<span id="cb52-364"><a href="#cb52-364" aria-hidden="true" tabindex="-1"></a>n_bootstrap_samples <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb52-365"><a href="#cb52-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-366"><a href="#cb52-366" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate bootstrap distribution</span></span>
<span id="cb52-367"><a href="#cb52-367" aria-hidden="true" tabindex="-1"></a>late_shipments_boot_distn <span class="op">=</span> [</span>
<span id="cb52-368"><a href="#cb52-368" aria-hidden="true" tabindex="-1"></a>    (late_shipments.sample(frac<span class="op">=</span><span class="dv">1</span>, replace<span class="op">=</span><span class="va">True</span>)[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">"Yes"</span>).mean()</span>
<span id="cb52-369"><a href="#cb52-369" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_bootstrap_samples)</span>
<span id="cb52-370"><a href="#cb52-370" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb52-371"><a href="#cb52-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-372"><a href="#cb52-372" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate 95% confidence interval using quantile method</span></span>
<span id="cb52-373"><a href="#cb52-373" aria-hidden="true" tabindex="-1"></a>lower <span class="op">=</span> np.quantile(late_shipments_boot_distn, <span class="fl">0.025</span>)</span>
<span id="cb52-374"><a href="#cb52-374" aria-hidden="true" tabindex="-1"></a>upper <span class="op">=</span> np.quantile(late_shipments_boot_distn, <span class="fl">0.975</span>)</span>
<span id="cb52-375"><a href="#cb52-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-376"><a href="#cb52-376" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the confidence interval</span></span>
<span id="cb52-377"><a href="#cb52-377" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>((lower, upper))</span>
<span id="cb52-378"><a href="#cb52-378" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-379"><a href="#cb52-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-380"><a href="#cb52-380" aria-hidden="true" tabindex="-1"></a><span class="fu">## Chapter 2: Two-Sample and ANOVA Tests {#sec-Chapter2}</span></span>
<span id="cb52-381"><a href="#cb52-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-382"><a href="#cb52-382" aria-hidden="true" tabindex="-1"></a>In this chapter, you’ll learn how to test for differences in means between two groups using t-tests and extend this to more than two groups using ANOVA and pairwise t-tests.</span>
<span id="cb52-383"><a href="#cb52-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-384"><a href="#cb52-384" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 2.1: Performing t-tests {#sec-Chapter2.1}</span></span>
<span id="cb52-385"><a href="#cb52-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-386"><a href="#cb52-386" aria-hidden="true" tabindex="-1"></a>In the previous chapter, we calculated the z-score, which was a test statistic for a single variable.</span>
<span id="cb52-387"><a href="#cb52-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-388"><a href="#cb52-388" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Two-sample problems {.unnumbered}</span></span>
<span id="cb52-389"><a href="#cb52-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-390"><a href="#cb52-390" aria-hidden="true" tabindex="-1"></a>Here, we'll look at a related problem of comparing sample statistics across groups in a variable. In the Stack Overflow dataset, <span class="in">`converted_comp`</span> is a numerical variable of annual compensation. <span class="in">`age_first_code_cut`</span> is a categorical variable with two levels: child and adult, which describe when the user started programming. We can ask questions about differences in compensation across the two age groups, such as, are users who first programmed as a child better compensated than those that started as adults?</span>
<span id="cb52-391"><a href="#cb52-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-392"><a href="#cb52-392" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Hypotheses {.unnumbered}</span></span>
<span id="cb52-393"><a href="#cb52-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-394"><a href="#cb52-394" aria-hidden="true" tabindex="-1"></a>The null hypothesis is that the population mean for the two groups is the same, and the alternative hypothesis is that the population mean for users who started coding as children is greater than for users who started coding as adults. We can write these hypotheses using equations. Mu represents an unknown population mean, and we use subscripts to denote which group the population mean belongs to. An alternate way of writing the equations is to compare the differences in population means to zero. Zero here corresponds to our hypothesized value for the difference in means.</span>
<span id="cb52-395"><a href="#cb52-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-396"><a href="#cb52-396" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating groupwise summary statistics {.unnumbered}</span></span>
<span id="cb52-397"><a href="#cb52-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-398"><a href="#cb52-398" aria-hidden="true" tabindex="-1"></a>To calculate summary statistics for each group, we start with the sample, group by the categorical variable, and then compute on the numeric variable. A pandas way of doing this is shown, calculating the mean of the <span class="in">`converted_comp`</span> column after grouping by <span class="in">`age_first_code_cut`</span>. Here, the child programmers have a mean compensation of 132,000 dollars compared to around 111,000 for adult programmers. Is that increase statistically significant or could it be explained by sampling variability?</span>
<span id="cb52-399"><a href="#cb52-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-400"><a href="#cb52-400" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Test statistics {.unnumbered}</span></span>
<span id="cb52-401"><a href="#cb52-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-402"><a href="#cb52-402" aria-hidden="true" tabindex="-1"></a>Although we don't know the population mean, we estimate it using the sample mean. x-bar is used to denote a sample mean. Then we use subscripts to denote which group a sample mean corresponds to. The difference between these two sample means is the test statistic for the hypothesis test. The z-scores we saw in Chapter 1 are a type of standardized test statistic.</span>
<span id="cb52-403"><a href="#cb52-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-404"><a href="#cb52-404" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Standardizing the test statistic {.unnumbered}</span></span>
<span id="cb52-405"><a href="#cb52-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-406"><a href="#cb52-406" aria-hidden="true" tabindex="-1"></a>z-scores are calculated by taking the sample statistic, subtracting the mean of this statistic as the population parameter of interest, then dividing by the standard error. In the two sample case, the test statistic, denoted t, uses a similar equation. We take the difference between the sample statistics for the two groups, subtract the population difference between the two groups, then divide by the standard error.</span>
<span id="cb52-407"><a href="#cb52-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-408"><a href="#cb52-408" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Standard error {.unnumbered}</span></span>
<span id="cb52-409"><a href="#cb52-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-410"><a href="#cb52-410" aria-hidden="true" tabindex="-1"></a>To calculate the standard error, needed for the denominator of the test statistic equation, bootstrapping tends to be a good option. However, there is an easier way to approximate it. We calculate the standard deviation of the numeric variable for each group in the sample, and the number of observations in each group. Then enter those values into the equation and compute the result.</span>
<span id="cb52-411"><a href="#cb52-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-412"><a href="#cb52-412" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Assuming the null hypothesis is true {.unnumbered}</span></span>
<span id="cb52-413"><a href="#cb52-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-414"><a href="#cb52-414" aria-hidden="true" tabindex="-1"></a>Here's the test statistic equation again. If we assume that the null hypothesis is true, there's a simplification we can make. The null hypothesis assumes that the population means are equal, and their difference is zero, so the population term in the numerator disappears. Inserting the approximation for the standard error, we now have a way of calculating the test statistic using only calculations on the sample dataset.</span>
<span id="cb52-415"><a href="#cb52-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-416"><a href="#cb52-416" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculations assuming the null hypothesis is true {.unnumbered}</span></span>
<span id="cb52-417"><a href="#cb52-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-418"><a href="#cb52-418" aria-hidden="true" tabindex="-1"></a>We need the mean, standard deviation, and number of observations for each group to fill in the formula for t. We again use <span class="in">`groupby`</span> and method combinations with <span class="in">`mean`</span>, <span class="in">`std`</span>, and <span class="in">`count`</span>.</span>
<span id="cb52-419"><a href="#cb52-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-420"><a href="#cb52-420" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating the test statistic {.unnumbered}</span></span>
<span id="cb52-421"><a href="#cb52-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-422"><a href="#cb52-422" aria-hidden="true" tabindex="-1"></a>Assigning the values to six different variables, the numerator is a subtraction of the sample means, and the denominator is like a weighted hypotenuse. The t-statistic is around 1.78. Just as with z-scores, we can't draw any conclusions yet; for that, we'll need to wait for the next unit.</span>
<span id="cb52-423"><a href="#cb52-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-424"><a href="#cb52-424" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 2.1.1</span></span>
<span id="cb52-425"><a href="#cb52-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-426"><a href="#cb52-426" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Two sample mean test statistic {.unnumbered}</span></span>
<span id="cb52-427"><a href="#cb52-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-428"><a href="#cb52-428" aria-hidden="true" tabindex="-1"></a>The hypothesis test for determining if there is a difference between the means of two populations uses a different type of test statistic to the z-scores you saw in Chapter 1. It's called "t", and it can be calculated from three values from each sample using this equation.</span>
<span id="cb52-429"><a href="#cb52-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-430"><a href="#cb52-430" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-431"><a href="#cb52-431" aria-hidden="true" tabindex="-1"></a>t = \frac{\bar{x}_{child} - \bar{x}_{adult}}{\sqrt{\frac{s_{child}^2}{n_{child}} + \frac{s_{adult}^2}{n_{adult}}}}</span>
<span id="cb52-432"><a href="#cb52-432" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb52-433"><a href="#cb52-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-434"><a href="#cb52-434" aria-hidden="true" tabindex="-1"></a>While trying to determine why some shipments are late, you may wonder if the weight of the shipments that were on time is less than the weight of the shipments that were late. The <span class="in">`late_shipments`</span> dataset has been split into a "yes" group, where <span class="in">`late == "Yes"`</span> and a "no" group where <span class="in">`late == "No"`</span>. The weight of the shipment is given in the <span class="in">`weight_kilograms`</span> variable.</span>
<span id="cb52-435"><a href="#cb52-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-436"><a href="#cb52-436" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-437"><a href="#cb52-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-438"><a href="#cb52-438" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate the numerator of the $t$ test statistic.</span>
<span id="cb52-439"><a href="#cb52-439" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate the denominator of the $t$ test statistic.</span>
<span id="cb52-440"><a href="#cb52-440" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use those two numbers to calculate the $t$ test statistic.</span>
<span id="cb52-441"><a href="#cb52-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-444"><a href="#cb52-444" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-445"><a href="#cb52-445" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-446"><a href="#cb52-446" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-447"><a href="#cb52-447" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-448"><a href="#cb52-448" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb52-449"><a href="#cb52-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-450"><a href="#cb52-450" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-451"><a href="#cb52-451" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-452"><a href="#cb52-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-453"><a href="#cb52-453" aria-hidden="true" tabindex="-1"></a>xbar <span class="op">=</span> late_shipments.groupby(<span class="st">"late"</span>)[<span class="st">"weight_kilograms"</span>].mean()</span>
<span id="cb52-454"><a href="#cb52-454" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> late_shipments.groupby(<span class="st">"late"</span>)[<span class="st">"weight_kilograms"</span>].std()</span>
<span id="cb52-455"><a href="#cb52-455" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> late_shipments.groupby(<span class="st">"late"</span>)[<span class="st">"weight_kilograms"</span>].count()</span>
<span id="cb52-456"><a href="#cb52-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-457"><a href="#cb52-457" aria-hidden="true" tabindex="-1"></a><span class="co"># The mean weight for both category in the 'late' column</span></span>
<span id="cb52-458"><a href="#cb52-458" aria-hidden="true" tabindex="-1"></a>xbar_no <span class="op">=</span> xbar.get(<span class="st">'No'</span>)</span>
<span id="cb52-459"><a href="#cb52-459" aria-hidden="true" tabindex="-1"></a>xbar_yes <span class="op">=</span> xbar.get(<span class="st">'Yes'</span>)</span>
<span id="cb52-460"><a href="#cb52-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-461"><a href="#cb52-461" aria-hidden="true" tabindex="-1"></a><span class="co"># The standard deviation weight for both category in the 'late' column</span></span>
<span id="cb52-462"><a href="#cb52-462" aria-hidden="true" tabindex="-1"></a>s_no <span class="op">=</span> s.get(<span class="st">'No'</span>)</span>
<span id="cb52-463"><a href="#cb52-463" aria-hidden="true" tabindex="-1"></a>s_yes <span class="op">=</span> s.get(<span class="st">'Yes'</span>)</span>
<span id="cb52-464"><a href="#cb52-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-465"><a href="#cb52-465" aria-hidden="true" tabindex="-1"></a><span class="co"># The sample size for both category in the 'late' column</span></span>
<span id="cb52-466"><a href="#cb52-466" aria-hidden="true" tabindex="-1"></a>n_no <span class="op">=</span> n.get(<span class="st">'No'</span>)</span>
<span id="cb52-467"><a href="#cb52-467" aria-hidden="true" tabindex="-1"></a>n_yes <span class="op">=</span> n.get(<span class="st">'Yes'</span>)</span>
<span id="cb52-468"><a href="#cb52-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-469"><a href="#cb52-469" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the numerator of the test statistic</span></span>
<span id="cb52-470"><a href="#cb52-470" aria-hidden="true" tabindex="-1"></a>numerator <span class="op">=</span> xbar_yes <span class="op">-</span> xbar_no</span>
<span id="cb52-471"><a href="#cb52-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-472"><a href="#cb52-472" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the denominator of the test statistic</span></span>
<span id="cb52-473"><a href="#cb52-473" aria-hidden="true" tabindex="-1"></a>denominator <span class="op">=</span> np.sqrt(s_no <span class="op">**</span> <span class="dv">2</span><span class="op">/</span>n_no <span class="op">+</span> s_yes <span class="op">**</span> <span class="dv">2</span><span class="op">/</span>n_yes)</span>
<span id="cb52-474"><a href="#cb52-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-475"><a href="#cb52-475" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the test statistic</span></span>
<span id="cb52-476"><a href="#cb52-476" aria-hidden="true" tabindex="-1"></a>t_stat <span class="op">=</span> numerator<span class="op">/</span>denominator</span>
<span id="cb52-477"><a href="#cb52-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-478"><a href="#cb52-478" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the test statistic</span></span>
<span id="cb52-479"><a href="#cb52-479" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t_stat)</span>
<span id="cb52-480"><a href="#cb52-480" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-481"><a href="#cb52-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-482"><a href="#cb52-482" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb52-483"><a href="#cb52-483" aria-hidden="true" tabindex="-1"></a>*When testing for differences between means, the test statistic is called 't' rather than 'z', and can be calculated using six numbers from the samples. Here, the value is about -2.39 or 2.39, depending on the order you calculated the numerator.*</span>
<span id="cb52-484"><a href="#cb52-484" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb52-485"><a href="#cb52-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-486"><a href="#cb52-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-487"><a href="#cb52-487" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 2.2: Calculating p-values from t-statistics {#sec-Chapter2.2}</span></span>
<span id="cb52-488"><a href="#cb52-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-489"><a href="#cb52-489" aria-hidden="true" tabindex="-1"></a>In the @sec-Chapter2.1, we calculated the test statistic t.</span>
<span id="cb52-490"><a href="#cb52-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-491"><a href="#cb52-491" aria-hidden="true" tabindex="-1"></a><span class="fu">#### t-distributions {.unnumbered}</span></span>
<span id="cb52-492"><a href="#cb52-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-493"><a href="#cb52-493" aria-hidden="true" tabindex="-1"></a>The test statistic, t, follows a t-distribution. t-distributions have a parameter called the degrees of freedom, or df for short. Here's a line plot of the PDF of a t-distribution with one degree of freedom in yellow, and the PDF of a normal distribution in blue dashes. Notice that the t-distribution for small degrees of freedom has fatter tails than the normal distribution, but otherwise they look similar.</span>
<span id="cb52-494"><a href="#cb52-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-495"><a href="#cb52-495" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Degrees of freedom {.unnumbered}</span></span>
<span id="cb52-496"><a href="#cb52-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-497"><a href="#cb52-497" aria-hidden="true" tabindex="-1"></a>As we increase the degrees of freedom, the t-distribution gets closer to the normal distribution. In fact, a normal distribution is a t-distribution with infinite degrees of freedom. Degrees of freedom are defined as the maximum number of logically independent values in the data sample. That's a fairly tricky concept, so let's try an example.</span>
<span id="cb52-498"><a href="#cb52-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-499"><a href="#cb52-499" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating degrees of freedom {.unnumbered}</span></span>
<span id="cb52-500"><a href="#cb52-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-501"><a href="#cb52-501" aria-hidden="true" tabindex="-1"></a>Suppose our dataset has 5 independent observations, and that four of the values are 2, 6, 8, and 5. Suppose we also know the sample mean is 5. With this knowledge, the fifth value is no longer independent; it must be 4. Even though all five observations in the sample were independent, because we know an additional fact about the sample - that is has a mean of 5 - we only have 4 degrees of freedom. In our two sample case, there are as many degrees of freedom as observations, minus two because we know two sample statistics, the means for each group.</span>
<span id="cb52-502"><a href="#cb52-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-503"><a href="#cb52-503" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Hypotheses {.unnumbered}</span></span>
<span id="cb52-504"><a href="#cb52-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-505"><a href="#cb52-505" aria-hidden="true" tabindex="-1"></a>Recall the hypotheses for our Stack Overflow question about compensation for the two age groups. Since this is a "greater than" alternative hypothesis, we need a right-tailed test.</span>
<span id="cb52-506"><a href="#cb52-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-507"><a href="#cb52-507" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Significance level {.unnumbered}</span></span>
<span id="cb52-508"><a href="#cb52-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-509"><a href="#cb52-509" aria-hidden="true" tabindex="-1"></a>We're going to calculate a p-value in a moment, but we first need to decide on a significance level. There are several possibilities; let's use point-one. That means that we reject the null hypothesis in favor of the alternative if the p-value is less-than-or-equal-to point-one.</span>
<span id="cb52-510"><a href="#cb52-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-511"><a href="#cb52-511" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating p-values: one proportion vs. a value {.unnumbered}</span></span>
<span id="cb52-512"><a href="#cb52-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-513"><a href="#cb52-513" aria-hidden="true" tabindex="-1"></a>In @sec-Chapter1.2 , to get the p-value, we transformed the z-score with the normal CDF. Since it was a right-tailed test, we subtracted the result from one. In the previous video, we used an approximation for the test statistic standard error using sample information. Using this approximation adds more uncertainty and that's why this is a t instead of a z problem. The t distribution allows for more uncertainty when using multiple estimates in a single statistic calculation. Here, the multiple estimates correspond to the sample mean and the sample standard deviation.</span>
<span id="cb52-514"><a href="#cb52-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-515"><a href="#cb52-515" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating p-values: two means from different groups {.unnumbered}</span></span>
<span id="cb52-516"><a href="#cb52-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-517"><a href="#cb52-517" aria-hidden="true" tabindex="-1"></a>Now we are calculating means rather than proportions, the z-score is replaced with a t test statistic. This is the value calculated in the previous video. The calculation also needs the degrees of freedom, which is the total number of observations in both groups, minus two.</span>
<span id="cb52-518"><a href="#cb52-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-519"><a href="#cb52-519" aria-hidden="true" tabindex="-1"></a>To calculate the p-value, we need to transform the test statistic using the t-distribution CDF instead of the normal distribution CDF. Notice the use of <span class="in">`t.cdf`</span> instead of <span class="in">`norm.cdf`</span>, and that the <span class="in">`df`</span> argument is set to the degrees of freedom. This p-value is less than the significance level of <span class="in">`0.1`</span>, so we should reject the null hypothesis in favor of the alternative hypothesis that Stack Overflow data scientists who started coding as children earn more.</span>
<span id="cb52-520"><a href="#cb52-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-521"><a href="#cb52-521" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 2.2.1</span></span>
<span id="cb52-522"><a href="#cb52-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-523"><a href="#cb52-523" aria-hidden="true" tabindex="-1"></a><span class="fu">#### From t to p {.unnumbered}</span></span>
<span id="cb52-524"><a href="#cb52-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-525"><a href="#cb52-525" aria-hidden="true" tabindex="-1"></a>Previously, you calculated the test statistic for the two-sample problem of whether the mean weight of shipments is smaller for shipments that weren't late (<span class="in">`late == "No"`</span>) compared to shipments that were late (<span class="in">`late == "Yes"`</span>). In order to make decisions about it, you need to transform the test statistic with a cumulative distribution function to get a p-value.</span>
<span id="cb52-526"><a href="#cb52-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-527"><a href="#cb52-527" aria-hidden="true" tabindex="-1"></a>Recall the hypotheses:</span>
<span id="cb52-528"><a href="#cb52-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-529"><a href="#cb52-529" aria-hidden="true" tabindex="-1"></a>$H_o$: The mean weight of shipments that weren't late is the same as the mean weight of shipments that were late.</span>
<span id="cb52-530"><a href="#cb52-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-531"><a href="#cb52-531" aria-hidden="true" tabindex="-1"></a>$H_A$: The mean weight of shipments that weren't late is less than the mean weight of shipments that were late.</span>
<span id="cb52-532"><a href="#cb52-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-533"><a href="#cb52-533" aria-hidden="true" tabindex="-1"></a>Use a significance level of <span class="in">`alpha = 0.05`</span>.</span>
<span id="cb52-534"><a href="#cb52-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-535"><a href="#cb52-535" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-536"><a href="#cb52-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-537"><a href="#cb52-537" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>What type of test does the alternative hypothesis indicate that we need? ***Left-tailed*</span>
<span id="cb52-538"><a href="#cb52-538" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate the degrees of freedom for the test.</span>
<span id="cb52-539"><a href="#cb52-539" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Compute the p-value using the test statistic, <span class="in">`t_stat`</span>.</span>
<span id="cb52-540"><a href="#cb52-540" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>What decision should you make based on the results of the hypothesis test? ***Reject the null hypothesis.*</span>
<span id="cb52-541"><a href="#cb52-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-544"><a href="#cb52-544" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-545"><a href="#cb52-545" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-546"><a href="#cb52-546" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-547"><a href="#cb52-547" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-548"><a href="#cb52-548" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> t</span>
<span id="cb52-549"><a href="#cb52-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-550"><a href="#cb52-550" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-551"><a href="#cb52-551" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-552"><a href="#cb52-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-553"><a href="#cb52-553" aria-hidden="true" tabindex="-1"></a>xbar <span class="op">=</span> late_shipments.groupby(<span class="st">"late"</span>)[<span class="st">"weight_kilograms"</span>].mean()</span>
<span id="cb52-554"><a href="#cb52-554" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> late_shipments.groupby(<span class="st">"late"</span>)[<span class="st">"weight_kilograms"</span>].std()</span>
<span id="cb52-555"><a href="#cb52-555" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> late_shipments.groupby(<span class="st">"late"</span>)[<span class="st">"weight_kilograms"</span>].count()</span>
<span id="cb52-556"><a href="#cb52-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-557"><a href="#cb52-557" aria-hidden="true" tabindex="-1"></a><span class="co"># The mean weight for both category in the 'late' column</span></span>
<span id="cb52-558"><a href="#cb52-558" aria-hidden="true" tabindex="-1"></a>xbar_no <span class="op">=</span> xbar.get(<span class="st">'No'</span>)</span>
<span id="cb52-559"><a href="#cb52-559" aria-hidden="true" tabindex="-1"></a>xbar_yes <span class="op">=</span> xbar.get(<span class="st">'Yes'</span>)</span>
<span id="cb52-560"><a href="#cb52-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-561"><a href="#cb52-561" aria-hidden="true" tabindex="-1"></a><span class="co"># The standard deviation weight for both category in the 'late' column</span></span>
<span id="cb52-562"><a href="#cb52-562" aria-hidden="true" tabindex="-1"></a>s_no <span class="op">=</span> s.get(<span class="st">'No'</span>)</span>
<span id="cb52-563"><a href="#cb52-563" aria-hidden="true" tabindex="-1"></a>s_yes <span class="op">=</span> s.get(<span class="st">'Yes'</span>)</span>
<span id="cb52-564"><a href="#cb52-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-565"><a href="#cb52-565" aria-hidden="true" tabindex="-1"></a><span class="co"># The sample size for both category in the 'late' column</span></span>
<span id="cb52-566"><a href="#cb52-566" aria-hidden="true" tabindex="-1"></a>n_no <span class="op">=</span> n.get(<span class="st">'No'</span>)</span>
<span id="cb52-567"><a href="#cb52-567" aria-hidden="true" tabindex="-1"></a>n_yes <span class="op">=</span> n.get(<span class="st">'Yes'</span>)</span>
<span id="cb52-568"><a href="#cb52-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-569"><a href="#cb52-569" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the numerator of the test statistic</span></span>
<span id="cb52-570"><a href="#cb52-570" aria-hidden="true" tabindex="-1"></a>numerator <span class="op">=</span> xbar_no <span class="op">-</span> xbar_yes</span>
<span id="cb52-571"><a href="#cb52-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-572"><a href="#cb52-572" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the denominator of the test statistic</span></span>
<span id="cb52-573"><a href="#cb52-573" aria-hidden="true" tabindex="-1"></a>denominator <span class="op">=</span> np.sqrt(s_no <span class="op">**</span> <span class="dv">2</span><span class="op">/</span>n_no <span class="op">+</span> s_yes <span class="op">**</span> <span class="dv">2</span><span class="op">/</span>n_yes)</span>
<span id="cb52-574"><a href="#cb52-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-575"><a href="#cb52-575" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the test statistic</span></span>
<span id="cb52-576"><a href="#cb52-576" aria-hidden="true" tabindex="-1"></a>t_stat <span class="op">=</span> numerator<span class="op">/</span>denominator</span>
<span id="cb52-577"><a href="#cb52-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-578"><a href="#cb52-578" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the degrees of freedom</span></span>
<span id="cb52-579"><a href="#cb52-579" aria-hidden="true" tabindex="-1"></a>degrees_of_freedom <span class="op">=</span> n_no <span class="op">+</span> n_yes <span class="op">-</span> <span class="dv">2</span></span>
<span id="cb52-580"><a href="#cb52-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-581"><a href="#cb52-581" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the p-value from the test stat</span></span>
<span id="cb52-582"><a href="#cb52-582" aria-hidden="true" tabindex="-1"></a>p_value <span class="op">=</span> t.cdf(t_stat, df <span class="op">=</span> degrees_of_freedom)</span>
<span id="cb52-583"><a href="#cb52-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-584"><a href="#cb52-584" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the p_value</span></span>
<span id="cb52-585"><a href="#cb52-585" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(p_value)</span>
<span id="cb52-586"><a href="#cb52-586" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-587"><a href="#cb52-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-588"><a href="#cb52-588" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 2.3: Paired t-tests {#sec-Chapter2.3}</span></span>
<span id="cb52-589"><a href="#cb52-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-590"><a href="#cb52-590" aria-hidden="true" tabindex="-1"></a>Previously, we used the t-distribution to compute a p-value from a standardized test statistic related to the difference in means across two groups.</span>
<span id="cb52-591"><a href="#cb52-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-592"><a href="#cb52-592" aria-hidden="true" tabindex="-1"></a><span class="fu">#### US Republican presidents dataset {.unnumbered}</span></span>
<span id="cb52-593"><a href="#cb52-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-594"><a href="#cb52-594" aria-hidden="true" tabindex="-1"></a>Here's a dataset of US presidential elections. Each row represents a presidential election at the county level. The variables in the dataset are the US state, the county within that state, and the percentage of votes for the Republican candidate in 2008, and in 2012.</span>
<span id="cb52-595"><a href="#cb52-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-596"><a href="#cb52-596" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>1 <span class="co">[</span><span class="ot">https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ</span><span class="co">](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ)</span></span>
<span id="cb52-597"><a href="#cb52-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-598"><a href="#cb52-598" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Hypotheses {.unnumbered}</span></span>
<span id="cb52-599"><a href="#cb52-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-600"><a href="#cb52-600" aria-hidden="true" tabindex="-1"></a>One question is whether the percentage of votes for the Republican candidate was lower in 2008 compared to 2012. To test this, we form hypotheses. As before, the null hypothesis is that our hunch is wrong, and that the population parameters are the same in each year group. The alternative hypothesis is that the parameter in 2008 was lower than in 2012. Let's set a significance level of point-zero-five. One feature of this dataset is that the 2008 votes and the 2012 votes are paired, which means they aren't independent, since they both refer to the same county. This means voting patterns may occur due to county-level demographics and local politics, and we want to capture this pairing in our model.</span>
<span id="cb52-601"><a href="#cb52-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-602"><a href="#cb52-602" aria-hidden="true" tabindex="-1"></a><span class="fu">#### From two samples to one {.unnumbered}</span></span>
<span id="cb52-603"><a href="#cb52-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-604"><a href="#cb52-604" aria-hidden="true" tabindex="-1"></a>For paired analyses, rather than considering the two variables separately, we can consider a single variable of the difference. This is stored in a DataFrame called <span class="in">`sample_data`</span> with a column named <span class="in">`diff`</span>. In this histogram of the difference, most values are between minus ten and ten, with at least one outlier.</span>
<span id="cb52-605"><a href="#cb52-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-606"><a href="#cb52-606" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculate sample statistics of the difference {.unnumbered}</span></span>
<span id="cb52-607"><a href="#cb52-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-608"><a href="#cb52-608" aria-hidden="true" tabindex="-1"></a>The sample mean, x-bar, is calculated from this difference. It is around minus two-point-eight-eight.</span>
<span id="cb52-609"><a href="#cb52-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-610"><a href="#cb52-610" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Revised hypotheses {.unnumbered}</span></span>
<span id="cb52-611"><a href="#cb52-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-612"><a href="#cb52-612" aria-hidden="true" tabindex="-1"></a>We can restate the hypotheses in terms of the single population mean, mu-diff, being equal to or less than zero. The test statistic, <span class="in">`t`</span>, has a slightly simpler equation compared to the two sample case. We have one statistic, so the number of degrees of freedom is the number of pairs minus one.</span>
<span id="cb52-613"><a href="#cb52-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-614"><a href="#cb52-614" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating the p-value {.unnumbered}</span></span>
<span id="cb52-615"><a href="#cb52-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-616"><a href="#cb52-616" aria-hidden="true" tabindex="-1"></a>To calculate the test statistic, we need the number of rows in the dataset, one hundred, and the standard deviation of the differences. We already calculated x-bar-diff, the mean of the differences, as minus two-point-eight-eight. Assuming the null hypothesis is true means mu-diff is zero. We now have everything we need to plug into the equation to calculate t. It's minus five-point-six. The degrees of freedom are one less than n-diff at ninety nine. Finally, we transform <span class="in">`t`</span> with the t-distribution CDF. The <span class="in">`p-value`</span> is really small at around nine-point-six times ten to the minus eight. That means we reject the null hypothesis in favor of the alternative hypothesis that the Republican candidates got a smaller percentage of the vote in 2008 compared to 2012.</span>
<span id="cb52-617"><a href="#cb52-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-618"><a href="#cb52-618" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Testing differences between two means using `ttest()` {.unnumbered}</span></span>
<span id="cb52-619"><a href="#cb52-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-620"><a href="#cb52-620" aria-hidden="true" tabindex="-1"></a>That was a lot of calculating. Fortunately, there's an easier way. The <span class="in">`pingouin`</span> package provides a variety of different methods for hypothesis testing and returns the results as a pandas DataFrame. Its output can be a little friendlier to work with than similar methods from <span class="in">`scipy.stats`</span>. One method from <span class="in">`pingouin`</span> is <span class="in">`ttest`</span> and it works with array-like objects, so the first argument is the Series of differences. For a converted one sample test like this, <span class="in">`y`</span> specifies the hypothesized difference value from the null hypothesis, which is zero. The type of alternative hypothesis can be specified as two-sided, less, or greater, corresponding to two-tailed, left-tailed, and right-tailed tests, respectively. Here's the output. We can recognize the value of the test statistic, the degrees of freedom, the alternative direction, and the p-value. The additional output refers to more advanced statistical concepts that are outside the scope of this course.</span>
<span id="cb52-621"><a href="#cb52-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-622"><a href="#cb52-622" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>1 Details on Returns from <span class="in">`pingouin.ttest()`</span> are available in the API docs for pingouin at <span class="co">[</span><span class="ot">https://pingouin-stats.org/generated/pingouin.ttest.html#pingouin.ttest</span><span class="co">](https://pingouin-stats.org/generated/pingouin.ttest.html#pingouin.ttest.)</span></span>
<span id="cb52-623"><a href="#cb52-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-624"><a href="#cb52-624" aria-hidden="true" tabindex="-1"></a><span class="fu">#### `ttest()` with `paired=True` {.unnumbered}</span></span>
<span id="cb52-625"><a href="#cb52-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-626"><a href="#cb52-626" aria-hidden="true" tabindex="-1"></a>There's a variation of <span class="in">`ttest`</span> for paired data that requires even less work. Rather than calculating the difference between the two paired variables, we can just pass them both directly to <span class="in">`ttest`</span> as <span class="in">`x`</span> and <span class="in">`y`</span>, and set <span class="in">`paired`</span> to <span class="in">`True`</span>. Notice that the results in the first four columns are the same as before.</span>
<span id="cb52-627"><a href="#cb52-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-628"><a href="#cb52-628" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Unpaired `ttest()` {.unnumbered}</span></span>
<span id="cb52-629"><a href="#cb52-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-630"><a href="#cb52-630" aria-hidden="true" tabindex="-1"></a>If we don't set paired to True and instead perform an unpaired t-test, then the numbers change. The test statistic is closer to zero, there are more degrees of freedom, and the p-value is much larger. Performing an unpaired t-test when our data is paired increases the chances of false negative errors.</span>
<span id="cb52-631"><a href="#cb52-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-632"><a href="#cb52-632" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 2.3.1</span></span>
<span id="cb52-633"><a href="#cb52-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-634"><a href="#cb52-634" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Visualizing the difference {.unnumbered}</span></span>
<span id="cb52-635"><a href="#cb52-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-636"><a href="#cb52-636" aria-hidden="true" tabindex="-1"></a>Before you start running hypothesis tests, it's a great idea to perform some exploratory data analysis; that is, calculating summary statistics and visualizing distributions.</span>
<span id="cb52-637"><a href="#cb52-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-638"><a href="#cb52-638" aria-hidden="true" tabindex="-1"></a>Here, you'll look at the proportion of county-level votes for the Democratic candidate in 2012 and 2016, <span class="in">`sample_dem_data`</span>. Since the counties are the same in both years, these samples are paired. The columns containing the samples are <span class="in">`dem_percent_12`</span> and <span class="in">`dem_percent_16`</span>.</span>
<span id="cb52-639"><a href="#cb52-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-640"><a href="#cb52-640" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-641"><a href="#cb52-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-642"><a href="#cb52-642" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Create a new <span class="in">`diff`</span> column containing the percentage of votes for the democratic candidate in 2012 minus the percentage of votes for the democratic candidate in 2016.</span>
<span id="cb52-643"><a href="#cb52-643" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Calculate the mean of the <span class="in">`diff`</span> column as <span class="in">`xbar_diff`</span>.</span>
<span id="cb52-644"><a href="#cb52-644" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Calculate the standard deviation of the <span class="in">`diff`</span> column as <span class="in">`s_diff`</span>.</span>
<span id="cb52-645"><a href="#cb52-645" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Plot a histogram of the <span class="in">`diff`</span> column with 20 bins.</span>
<span id="cb52-646"><a href="#cb52-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-649"><a href="#cb52-649" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-650"><a href="#cb52-650" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-651"><a href="#cb52-651" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-652"><a href="#cb52-652" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-653"><a href="#cb52-653" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> t</span>
<span id="cb52-654"><a href="#cb52-654" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb52-655"><a href="#cb52-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-656"><a href="#cb52-656" aria-hidden="true" tabindex="-1"></a>sample_dem_data <span class="op">=</span> pd.read_feather(<span class="st">'datasets/dem_votes_potus_12_16.feather'</span>)</span>
<span id="cb52-657"><a href="#cb52-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-658"><a href="#cb52-658" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the differences from 2012 to 2016</span></span>
<span id="cb52-659"><a href="#cb52-659" aria-hidden="true" tabindex="-1"></a>sample_dem_data[<span class="st">'diff'</span>] <span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_12'</span>] <span class="op">-</span> sample_dem_data[<span class="st">'dem_percent_16'</span>]</span>
<span id="cb52-660"><a href="#cb52-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-661"><a href="#cb52-661" aria-hidden="true" tabindex="-1"></a><span class="co"># Print sample_dem_data</span></span>
<span id="cb52-662"><a href="#cb52-662" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sample_dem_data)</span>
<span id="cb52-663"><a href="#cb52-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-664"><a href="#cb52-664" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the mean of the diff column</span></span>
<span id="cb52-665"><a href="#cb52-665" aria-hidden="true" tabindex="-1"></a>xbar_diff <span class="op">=</span> sample_dem_data[<span class="st">'diff'</span>].mean()</span>
<span id="cb52-666"><a href="#cb52-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-667"><a href="#cb52-667" aria-hidden="true" tabindex="-1"></a><span class="co"># Print xbar_diff</span></span>
<span id="cb52-668"><a href="#cb52-668" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(xbar_diff)</span>
<span id="cb52-669"><a href="#cb52-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-670"><a href="#cb52-670" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the standard deviation of the diff column</span></span>
<span id="cb52-671"><a href="#cb52-671" aria-hidden="true" tabindex="-1"></a>s_diff <span class="op">=</span> sample_dem_data[<span class="st">'diff'</span>].std()</span>
<span id="cb52-672"><a href="#cb52-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-673"><a href="#cb52-673" aria-hidden="true" tabindex="-1"></a><span class="co"># Print s_diff</span></span>
<span id="cb52-674"><a href="#cb52-674" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s_diff)</span>
<span id="cb52-675"><a href="#cb52-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-676"><a href="#cb52-676" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot a histogram of diff with 20 bins</span></span>
<span id="cb52-677"><a href="#cb52-677" aria-hidden="true" tabindex="-1"></a>sample_dem_data[<span class="st">'diff'</span>].hist(bins<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb52-678"><a href="#cb52-678" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb52-679"><a href="#cb52-679" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-680"><a href="#cb52-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-681"><a href="#cb52-681" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 2.3.2</span></span>
<span id="cb52-682"><a href="#cb52-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-683"><a href="#cb52-683" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Using `ttest()` {.unnumbered}</span></span>
<span id="cb52-684"><a href="#cb52-684" aria-hidden="true" tabindex="-1"></a>Manually calculating test statistics and transforming them with a CDF to get a p-value is a lot of effort to compare two sample means. The comparison of two sample means is called a t-test, and the   <span class="in">`pingouin`</span> Python package has a <span class="in">`.ttest()`</span> method to accomplish it. This method provides some flexibility in how you perform the test.</span>
<span id="cb52-685"><a href="#cb52-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-686"><a href="#cb52-686" aria-hidden="true" tabindex="-1"></a>As in the previous exercise, you'll explore the difference between the proportion of county-level votes for the Democratic candidate in 2012 and 2016 to identify if the difference is significant. The hypotheses are as follows:</span>
<span id="cb52-687"><a href="#cb52-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-688"><a href="#cb52-688" aria-hidden="true" tabindex="-1"></a>$H_o$: The proportion of democratic votes in 2012 and 2016 were the same. </span>
<span id="cb52-689"><a href="#cb52-689" aria-hidden="true" tabindex="-1"></a>$H_A$: The proportion of democratic votes in 2012 and 2016 were different.</span>
<span id="cb52-690"><a href="#cb52-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-691"><a href="#cb52-691" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-692"><a href="#cb52-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-693"><a href="#cb52-693" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Conduct a t-test on the sample differences (the diff column of <span class="in">`sample_dem_data`</span>), using an appropriate alternative hypothesis chosen from <span class="in">`"two-sided"`</span>, <span class="in">`"less"`</span>, and <span class="in">`"greater"`</span>.</span>
<span id="cb52-694"><a href="#cb52-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-697"><a href="#cb52-697" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-698"><a href="#cb52-698" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-699"><a href="#cb52-699" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-700"><a href="#cb52-700" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-701"><a href="#cb52-701" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb52-702"><a href="#cb52-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-703"><a href="#cb52-703" aria-hidden="true" tabindex="-1"></a>sample_dem_data <span class="op">=</span> pd.read_feather(<span class="st">'datasets/dem_votes_potus_12_16.feather'</span>)</span>
<span id="cb52-704"><a href="#cb52-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-705"><a href="#cb52-705" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the differences from 2012 to 2016</span></span>
<span id="cb52-706"><a href="#cb52-706" aria-hidden="true" tabindex="-1"></a>sample_dem_data[<span class="st">'diff'</span>] <span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_12'</span>] <span class="op">-</span> sample_dem_data[<span class="st">'dem_percent_16'</span>]</span>
<span id="cb52-707"><a href="#cb52-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-708"><a href="#cb52-708" aria-hidden="true" tabindex="-1"></a><span class="co"># Conduct a t-test on diff</span></span>
<span id="cb52-709"><a href="#cb52-709" aria-hidden="true" tabindex="-1"></a>test_results <span class="op">=</span> pingouin.ttest(x<span class="op">=</span>sample_dem_data[<span class="st">'diff'</span>],</span>
<span id="cb52-710"><a href="#cb52-710" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span><span class="dv">0</span>, alternative<span class="op">=</span><span class="st">'two-sided'</span>)</span>
<span id="cb52-711"><a href="#cb52-711" aria-hidden="true" tabindex="-1"></a>                         </span>
<span id="cb52-712"><a href="#cb52-712" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the test results</span></span>
<span id="cb52-713"><a href="#cb52-713" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_results)</span>
<span id="cb52-714"><a href="#cb52-714" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-715"><a href="#cb52-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-716"><a href="#cb52-716" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>What's the correct decision from the t-test, assuming $\alpha = 0.01$ ?</span>
<span id="cb52-717"><a href="#cb52-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-718"><a href="#cb52-718" aria-hidden="true" tabindex="-1"></a>**Answer**</span>
<span id="cb52-719"><a href="#cb52-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-720"><a href="#cb52-720" aria-hidden="true" tabindex="-1"></a>*Reject the null hypothesis*.</span>
<span id="cb52-721"><a href="#cb52-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-722"><a href="#cb52-722" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Conduct a paired test on the democratic votes in 2012 and 2016 (the <span class="in">`dem_percent_12`</span> and <span class="in">`dem_percent_16`</span> columns of <span class="in">`sample_dem_data`</span>), using an appropriate alternative hypothesis.</span>
<span id="cb52-723"><a href="#cb52-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-726"><a href="#cb52-726" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-727"><a href="#cb52-727" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-728"><a href="#cb52-728" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-729"><a href="#cb52-729" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-730"><a href="#cb52-730" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb52-731"><a href="#cb52-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-732"><a href="#cb52-732" aria-hidden="true" tabindex="-1"></a>sample_dem_data <span class="op">=</span> pd.read_feather(<span class="st">'datasets/dem_votes_potus_12_16.feather'</span>)</span>
<span id="cb52-733"><a href="#cb52-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-734"><a href="#cb52-734" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the differences from 2012 to 2016</span></span>
<span id="cb52-735"><a href="#cb52-735" aria-hidden="true" tabindex="-1"></a>sample_dem_data[<span class="st">'diff'</span>] <span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_12'</span>] <span class="op">-</span> sample_dem_data[<span class="st">'dem_percent_16'</span>]</span>
<span id="cb52-736"><a href="#cb52-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-737"><a href="#cb52-737" aria-hidden="true" tabindex="-1"></a><span class="co"># Conduct a paired t-test on dem_percent_12 and dem_percent_16</span></span>
<span id="cb52-738"><a href="#cb52-738" aria-hidden="true" tabindex="-1"></a>paired_test_results <span class="op">=</span> pingouin.ttest(x<span class="op">=</span>sample_dem_data[<span class="st">'dem_percent_12'</span>],</span>
<span id="cb52-739"><a href="#cb52-739" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>sample_dem_data[<span class="st">'dem_percent_16'</span>], paired <span class="op">=</span> <span class="va">True</span>, alternative<span class="op">=</span><span class="st">'two-sided'</span>)</span>
<span id="cb52-740"><a href="#cb52-740" aria-hidden="true" tabindex="-1"></a>                              </span>
<span id="cb52-741"><a href="#cb52-741" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the paired test results</span></span>
<span id="cb52-742"><a href="#cb52-742" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(paired_test_results)</span>
<span id="cb52-743"><a href="#cb52-743" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-744"><a href="#cb52-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-745"><a href="#cb52-745" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Compare the paired t-test to an (inappropriate) unpaired test on the same data. How does the p-value change?</span>
<span id="cb52-746"><a href="#cb52-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-747"><a href="#cb52-747" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-748"><a href="#cb52-748" aria-hidden="true" tabindex="-1"></a><span class="in">pingouin.ttest(x=sample_dem_data['dem_percent_12'], </span></span>
<span id="cb52-749"><a href="#cb52-749" aria-hidden="true" tabindex="-1"></a><span class="in">               y=sample_dem_data['dem_percent_16'], </span></span>
<span id="cb52-750"><a href="#cb52-750" aria-hidden="true" tabindex="-1"></a><span class="in">               alternative="two-sided")</span></span>
<span id="cb52-751"><a href="#cb52-751" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-752"><a href="#cb52-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-753"><a href="#cb52-753" aria-hidden="true" tabindex="-1"></a>**Answer**</span>
<span id="cb52-754"><a href="#cb52-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-755"><a href="#cb52-755" aria-hidden="true" tabindex="-1"></a>*The p-value from the unpaired test is greater than than the p-value from the paired test. When you have paired data, a paired t-test is preferable to the unpaired version because it reduces the chance of a false negative error.*</span>
<span id="cb52-756"><a href="#cb52-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-759"><a href="#cb52-759" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-760"><a href="#cb52-760" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-761"><a href="#cb52-761" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-762"><a href="#cb52-762" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-763"><a href="#cb52-763" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb52-764"><a href="#cb52-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-765"><a href="#cb52-765" aria-hidden="true" tabindex="-1"></a>sample_dem_data <span class="op">=</span> pd.read_feather(<span class="st">'datasets/dem_votes_potus_12_16.feather'</span>)</span>
<span id="cb52-766"><a href="#cb52-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-767"><a href="#cb52-767" aria-hidden="true" tabindex="-1"></a>unpaired_test <span class="op">=</span> pingouin.ttest(x<span class="op">=</span>sample_dem_data[<span class="st">'dem_percent_12'</span>], </span>
<span id="cb52-768"><a href="#cb52-768" aria-hidden="true" tabindex="-1"></a>               y<span class="op">=</span>sample_dem_data[<span class="st">'dem_percent_16'</span>], paired <span class="op">=</span> <span class="va">False</span>, </span>
<span id="cb52-769"><a href="#cb52-769" aria-hidden="true" tabindex="-1"></a>               alternative<span class="op">=</span><span class="st">"two-sided"</span>)</span>
<span id="cb52-770"><a href="#cb52-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-771"><a href="#cb52-771" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(unpaired_test)</span>
<span id="cb52-772"><a href="#cb52-772" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-773"><a href="#cb52-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-774"><a href="#cb52-774" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 2.4: ANOVA tests {#sec-Chapter2.4}</span></span>
<span id="cb52-775"><a href="#cb52-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-776"><a href="#cb52-776" aria-hidden="true" tabindex="-1"></a>We've seen how to compare two groups in the unpaired and paired cases. But what if there are more than two groups?</span>
<span id="cb52-777"><a href="#cb52-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-778"><a href="#cb52-778" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Job satisfaction: 5 categories {.unnumbered}</span></span>
<span id="cb52-779"><a href="#cb52-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-780"><a href="#cb52-780" aria-hidden="true" tabindex="-1"></a>The Stack Overflow survey includes a job satisfaction variable, with five categories from <span class="in">`"Very satisfied"`</span> down to <span class="in">`"Very dissatisfied"`</span>.</span>
<span id="cb52-781"><a href="#cb52-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-782"><a href="#cb52-782" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Visualizing multiple distributions {.unnumbered}</span></span>
<span id="cb52-783"><a href="#cb52-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-784"><a href="#cb52-784" aria-hidden="true" tabindex="-1"></a>Suppose we want to know if mean annual compensation is different for each of the levels of job satisfaction. The first thing to do is visualize the distributions with box plots. Seaborn's boxplot method provides a nice option here with <span class="in">`converted_comp`</span> on the horizontal axis and <span class="in">`job_sat`</span> on the vertical axis using the <span class="in">`stack_overflow`</span> data. "Very satisfied" looks slightly higher than the others, but to see if they are significantly different, we'll need to use hypothesis tests.</span>
<span id="cb52-785"><a href="#cb52-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-786"><a href="#cb52-786" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Analysis of variance (ANOVA) {.unnumbered}</span></span>
<span id="cb52-787"><a href="#cb52-787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-788"><a href="#cb52-788" aria-hidden="true" tabindex="-1"></a>ANOVA tests determine whether there are differences between the groups. We begin by setting our significance level to point-two. This value is larger than in many situations but will help us understand the implications on comparing different numbers of groups later on. We use the <span class="in">`pingouin anova`</span> method to compare values across multiple groups. We specify the data as <span class="in">`stack_overflow`</span>, the dependent variable,<span class="in">` dv`</span>, as <span class="in">`converted_comp`</span>, and the column of groups to calculate between as <span class="in">`job_sat`</span>. The p-value is stored in the <span class="in">`p-unc`</span> column, which is point-zero-zero-one-three, which is smaller than alpha at 20 percent. That means that at least two of the categories of job satisfaction have significant differences between their compensation levels, but this doesn't tell us which two categories they are.</span>
<span id="cb52-789"><a href="#cb52-789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-790"><a href="#cb52-790" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Pairwise tests {.unnumbered}</span></span>
<span id="cb52-791"><a href="#cb52-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-792"><a href="#cb52-792" aria-hidden="true" tabindex="-1"></a>To identify which categories are different, we compare all five job satisfaction categories, testing on each pair in turn. There are ten ways of choosing two items from a set of five, so we have ten tests to perform. Our significance level is still point-two.</span>
<span id="cb52-793"><a href="#cb52-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-794"><a href="#cb52-794" aria-hidden="true" tabindex="-1"></a>To run all these hypothesis tests in one go, we can use <span class="in">`pairwise_tests`</span>. The first three arguments of data, <span class="in">`dv`</span>, and between are the same as the <span class="in">`anova`</span> method. We'll discuss p-adjust shortly. The result shows a DataFrame where A and B are the two levels being compared on each row. Next, we look at the <span class="in">`p-unc`</span> column of p-values. Three of these are less than our significance level of point-two.</span>
<span id="cb52-795"><a href="#cb52-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-796"><a href="#cb52-796" aria-hidden="true" tabindex="-1"></a><span class="fu">#### As the number of groups increases... {.unnumbered}</span></span>
<span id="cb52-797"><a href="#cb52-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-798"><a href="#cb52-798" aria-hidden="true" tabindex="-1"></a>In this case we have five groups, resulting in ten pairs. As the number of groups increases, the number of pairs - and hence the number of hypothesis tests we must perform - increases quadratically. The more tests we run, the higher the chance that at least one of them will give a false positive significant result. With a significance level of point-two, if we run one test, the chance of a false positive result is point-two. With five groups and ten tests, the probability of at least one false positive is around point-seven. With twenty groups, it's almost guaranteed that we'll get at least one false positive.</span>
<span id="cb52-799"><a href="#cb52-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-800"><a href="#cb52-800" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Bonferroni correction {.unnumbered}</span></span>
<span id="cb52-801"><a href="#cb52-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-802"><a href="#cb52-802" aria-hidden="true" tabindex="-1"></a>The solution to this is to apply an adjustment to increase the p-values, reducing the chance of getting a false positive. One common adjustment is the Bonferroni correction. Looking at the <span class="in">`p-corr`</span> column corresponding to corrected p-values, as opposed to the <span class="in">`p-unc`</span> column for <span class="in">`uncorrected`</span>, only two of the pairs appear to have significant differences.</span>
<span id="cb52-803"><a href="#cb52-803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-804"><a href="#cb52-804" aria-hidden="true" tabindex="-1"></a><span class="fu">#### More methods {.unnumbered}</span></span>
<span id="cb52-805"><a href="#cb52-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-806"><a href="#cb52-806" aria-hidden="true" tabindex="-1"></a><span class="in">`pingouin`</span> provides several options for adjusting the p-values with some being more conservative than others. No adjustment with none is the default, but in almost all pairwise t-testing situations choosing a correction method is more appropriate.</span>
<span id="cb52-807"><a href="#cb52-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-808"><a href="#cb52-808" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 2.4.1</span></span>
<span id="cb52-809"><a href="#cb52-809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-810"><a href="#cb52-810" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Visualizing many categories {.unnumbered}</span></span>
<span id="cb52-811"><a href="#cb52-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-812"><a href="#cb52-812" aria-hidden="true" tabindex="-1"></a>So far in this chapter, we've only considered the case of differences in a numeric variable between two categories. Of course, many datasets contain more categories. Before you get to conducting tests on many categories, it's often helpful to perform exploratory data analysis (EDA), calculating summary statistics for each group and visualizing the distributions of the numeric variable for each category using box plots.</span>
<span id="cb52-813"><a href="#cb52-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-814"><a href="#cb52-814" aria-hidden="true" tabindex="-1"></a>Here, we'll return to the late shipments data, and how the price of each package (<span class="in">`pack_price`</span>) varies between the three shipment modes (<span class="in">`shipment_mode`</span>): <span class="in">`"Air"`</span>, <span class="in">`"Air Charter"`</span>, and <span class="in">`"Ocean"`</span>.</span>
<span id="cb52-815"><a href="#cb52-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-816"><a href="#cb52-816" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-817"><a href="#cb52-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-818"><a href="#cb52-818" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Group <span class="in">`late_shipments`</span> by <span class="in">`shipment_mode`</span> and calculate the mean <span class="in">`pack_price`</span> for each group, storing the result in <span class="in">`xbar_pack_by_mode`</span>.</span>
<span id="cb52-819"><a href="#cb52-819" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Group <span class="in">`late_shipments`</span> by <span class="in">`shipment_mode`</span> and calculate the standard deviation <span class="in">`pack_price`</span> for each group, storing the result in <span class="in">`s_pack_by_mode`</span>.</span>
<span id="cb52-820"><a href="#cb52-820" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Create a boxplot from <span class="in">`late_shipments`</span> with <span class="in">`"pack_price"`</span> as <span class="in">`x`</span> and <span class="in">`"shipment_mode"`</span> as <span class="in">`y`</span>.</span>
<span id="cb52-821"><a href="#cb52-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-824"><a href="#cb52-824" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-825"><a href="#cb52-825" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-826"><a href="#cb52-826" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-827"><a href="#cb52-827" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb52-828"><a href="#cb52-828" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb52-829"><a href="#cb52-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-830"><a href="#cb52-830" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-831"><a href="#cb52-831" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-832"><a href="#cb52-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-833"><a href="#cb52-833" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the mean pack_price for each shipment_mode</span></span>
<span id="cb52-834"><a href="#cb52-834" aria-hidden="true" tabindex="-1"></a>xbar_pack_by_mode <span class="op">=</span> late_shipments.groupby(<span class="st">'shipment_mode'</span>)[<span class="st">'pack_price'</span>].mean()</span>
<span id="cb52-835"><a href="#cb52-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-836"><a href="#cb52-836" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the grouped means</span></span>
<span id="cb52-837"><a href="#cb52-837" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(xbar_pack_by_mode)</span>
<span id="cb52-838"><a href="#cb52-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-839"><a href="#cb52-839" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the standard deviation of the pack_price for each shipment_mode</span></span>
<span id="cb52-840"><a href="#cb52-840" aria-hidden="true" tabindex="-1"></a>s_pack_by_mode <span class="op">=</span> late_shipments.groupby(<span class="st">"shipment_mode"</span>)[<span class="st">'pack_price'</span>].std()</span>
<span id="cb52-841"><a href="#cb52-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-842"><a href="#cb52-842" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the grouped standard deviations</span></span>
<span id="cb52-843"><a href="#cb52-843" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s_pack_by_mode)</span>
<span id="cb52-844"><a href="#cb52-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-845"><a href="#cb52-845" aria-hidden="true" tabindex="-1"></a><span class="co"># Boxplot of shipment_mode vs. pack_price</span></span>
<span id="cb52-846"><a href="#cb52-846" aria-hidden="true" tabindex="-1"></a>sns.boxplot(x<span class="op">=</span><span class="st">"pack_price"</span>, y<span class="op">=</span><span class="st">"shipment_mode"</span>, data<span class="op">=</span>late_shipments)</span>
<span id="cb52-847"><a href="#cb52-847" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb52-848"><a href="#cb52-848" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-849"><a href="#cb52-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-850"><a href="#cb52-850" aria-hidden="true" tabindex="-1"></a>*There certainly looks to be a difference in the pack price between each of the three shipment modes. Do you think the differences are statistically significant?*</span>
<span id="cb52-851"><a href="#cb52-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-852"><a href="#cb52-852" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 2.4.2</span></span>
<span id="cb52-853"><a href="#cb52-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-854"><a href="#cb52-854" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Conducting an ANOVA test {.unnumbered}</span></span>
<span id="cb52-855"><a href="#cb52-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-856"><a href="#cb52-856" aria-hidden="true" tabindex="-1"></a>The box plots made it look like the distribution of pack price was different for each of the three shipment modes. However, it didn't tell us whether the mean pack price was different in each category. To determine that, we can use an ANOVA test. The null and alternative hypotheses can be written as follows.</span>
<span id="cb52-857"><a href="#cb52-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-858"><a href="#cb52-858" aria-hidden="true" tabindex="-1"></a>$H_O$: Pack prices for every category of shipment mode are the same.</span>
<span id="cb52-859"><a href="#cb52-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-860"><a href="#cb52-860" aria-hidden="true" tabindex="-1"></a>$H_A$: Pack prices for some categories of shipment mode are different.</span>
<span id="cb52-861"><a href="#cb52-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-862"><a href="#cb52-862" aria-hidden="true" tabindex="-1"></a>Use a significance level of 0.1.</span>
<span id="cb52-863"><a href="#cb52-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-864"><a href="#cb52-864" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-865"><a href="#cb52-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-866"><a href="#cb52-866" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Run an ANOVA on <span class="in">`late_shipments`</span> investigating <span class="in">`'pack_price'`</span> (the dependent variable) between the groups of <span class="in">`'shipment_mode'`</span></span>
<span id="cb52-867"><a href="#cb52-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-870"><a href="#cb52-870" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-871"><a href="#cb52-871" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-872"><a href="#cb52-872" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-873"><a href="#cb52-873" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb52-874"><a href="#cb52-874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-875"><a href="#cb52-875" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-876"><a href="#cb52-876" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-877"><a href="#cb52-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-878"><a href="#cb52-878" aria-hidden="true" tabindex="-1"></a><span class="co"># Run an ANOVA for pack_price across shipment_mode</span></span>
<span id="cb52-879"><a href="#cb52-879" aria-hidden="true" tabindex="-1"></a>anova_results <span class="op">=</span> pingouin.anova(data<span class="op">=</span>late_shipments, dv<span class="op">=</span><span class="st">'pack_price'</span>, between <span class="op">=</span> <span class="st">'shipment_mode'</span>)</span>
<span id="cb52-880"><a href="#cb52-880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-881"><a href="#cb52-881" aria-hidden="true" tabindex="-1"></a><span class="co"># Print anova_results</span></span>
<span id="cb52-882"><a href="#cb52-882" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(anova_results)</span>
<span id="cb52-883"><a href="#cb52-883" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-884"><a href="#cb52-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-885"><a href="#cb52-885" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Assuming a significance level of 0.1, should you reject the null hypothesis that there is no difference in pack prices between shipment modes?</span>
<span id="cb52-886"><a href="#cb52-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-887"><a href="#cb52-887" aria-hidden="true" tabindex="-1"></a>*Yes. The p-value is less than or equal to the significance level, so the null hypothesis should be rejected. There is a significant difference in pack prices between the shipment modes. However, we don't know which shipment modes this applies to.*</span>
<span id="cb52-888"><a href="#cb52-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-889"><a href="#cb52-889" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 2.4.3</span></span>
<span id="cb52-890"><a href="#cb52-890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-891"><a href="#cb52-891" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Pairwise t-tests {.unnumbered}</span></span>
<span id="cb52-892"><a href="#cb52-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-893"><a href="#cb52-893" aria-hidden="true" tabindex="-1"></a>The ANOVA test didn't tell you which categories of shipment mode had significant differences in pack prices. To pinpoint which categories had differences, you could instead use pairwise t-tests.</span>
<span id="cb52-894"><a href="#cb52-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-895"><a href="#cb52-895" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-896"><a href="#cb52-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-897"><a href="#cb52-897" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Perform pairwise t-tests on <span class="in">`late_shipments`</span>'s <span class="in">`pack_price`</span> variable, grouped by <span class="in">`shipment_mode`</span>, without doing any p-value adjustment.</span>
<span id="cb52-898"><a href="#cb52-898" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Modify the pairwise t-tests to use the Bonferroni p-value adjustment and stored it as <span class="in">`modify_pairwise_results`</span></span>
<span id="cb52-899"><a href="#cb52-899" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Using the Bonferroni correction results and assuming a significance level of 0.1, for which pairs of shipment modes should you reject the null hypothesis that the pack prices are equal? </span>
<span id="cb52-900"><a href="#cb52-900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-901"><a href="#cb52-901" aria-hidden="true" tabindex="-1"></a>*"Ocean" and "Air Charter"; "Ocean" and "Air"; "Air Charter" and "Air". After applying the Bonferroni adjustment, the p-values for the t-tests between each of the three groups are all less than 0.1.*</span>
<span id="cb52-902"><a href="#cb52-902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-905"><a href="#cb52-905" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-906"><a href="#cb52-906" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-907"><a href="#cb52-907" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-908"><a href="#cb52-908" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb52-909"><a href="#cb52-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-910"><a href="#cb52-910" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-911"><a href="#cb52-911" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-912"><a href="#cb52-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-913"><a href="#cb52-913" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform a pairwise t-test on pack price, grouped by shipment mode</span></span>
<span id="cb52-914"><a href="#cb52-914" aria-hidden="true" tabindex="-1"></a>pairwise_results <span class="op">=</span> pingouin.pairwise_tests(data<span class="op">=</span>late_shipments, dv<span class="op">=</span><span class="st">'pack_price'</span>, between <span class="op">=</span> <span class="st">'shipment_mode'</span>, padjust<span class="op">=</span><span class="st">'none'</span>)  </span>
<span id="cb52-915"><a href="#cb52-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-916"><a href="#cb52-916" aria-hidden="true" tabindex="-1"></a><span class="co"># Print pairwise_results</span></span>
<span id="cb52-917"><a href="#cb52-917" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pairwise_results)</span>
<span id="cb52-918"><a href="#cb52-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-919"><a href="#cb52-919" aria-hidden="true" tabindex="-1"></a><span class="co"># Modify the pairwise t-tests to use Bonferroni p-value adjustment</span></span>
<span id="cb52-920"><a href="#cb52-920" aria-hidden="true" tabindex="-1"></a>modify_pairwise_results <span class="op">=</span> pingouin.pairwise_tests(data<span class="op">=</span>late_shipments, </span>
<span id="cb52-921"><a href="#cb52-921" aria-hidden="true" tabindex="-1"></a>                                           dv<span class="op">=</span><span class="st">"pack_price"</span>,</span>
<span id="cb52-922"><a href="#cb52-922" aria-hidden="true" tabindex="-1"></a>                                           between<span class="op">=</span><span class="st">"shipment_mode"</span>,</span>
<span id="cb52-923"><a href="#cb52-923" aria-hidden="true" tabindex="-1"></a>                                           padjust<span class="op">=</span><span class="st">"bonf"</span>)</span>
<span id="cb52-924"><a href="#cb52-924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-925"><a href="#cb52-925" aria-hidden="true" tabindex="-1"></a><span class="co"># Print pairwise_results</span></span>
<span id="cb52-926"><a href="#cb52-926" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(modify_pairwise_results)</span>
<span id="cb52-927"><a href="#cb52-927" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-928"><a href="#cb52-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-929"><a href="#cb52-929" aria-hidden="true" tabindex="-1"></a><span class="fu">## Chapter 3: Proportion Tests {#sec-Chapter3}</span></span>
<span id="cb52-930"><a href="#cb52-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-931"><a href="#cb52-931" aria-hidden="true" tabindex="-1"></a>Now it’s time to test for differences in proportions between two groups using proportion tests. Through hands-on exercises, you’ll extend your proportion tests to more than two groups with chi-square independence tests, and return to the one sample case with chi-square goodness of fit tests.</span>
<span id="cb52-932"><a href="#cb52-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-933"><a href="#cb52-933" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 3.1: One-sample proportion tests {#sec-Chapter3.1}</span></span>
<span id="cb52-934"><a href="#cb52-934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-935"><a href="#cb52-935" aria-hidden="true" tabindex="-1"></a>Let’s return to thinking about testing proportions, as we did in @sec-Chapter1.</span>
<span id="cb52-936"><a href="#cb52-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-937"><a href="#cb52-937" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Chapter 1 recap {.unnumbered}</span></span>
<span id="cb52-938"><a href="#cb52-938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-939"><a href="#cb52-939" aria-hidden="true" tabindex="-1"></a>The hypothesis tests in @sec-Chapter1 measured whether or not an unknown population proportion was equal to some value. We used bootstrapping on the sample to estimate the standard error of the sample statistic. The standard error was then used to calculate a standardized test statistic, the z-score, which was used to get a p-value, so we could decide whether or not to reject the null hypothesis. A bootstrap distribution can be computationally intensive to calculate, so this time we'll instead calculate the test statistic without it.</span>
<span id="cb52-940"><a href="#cb52-940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-941"><a href="#cb52-941" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Standardized test statistic for proportions {.unnumbered}</span></span>
<span id="cb52-942"><a href="#cb52-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-943"><a href="#cb52-943" aria-hidden="true" tabindex="-1"></a>An unknown population parameter that is a proportion, or population proportion for short, is denoted p. The sample proportion is denoted p-hat, and the hypothesized value for the population proportion is denoted p-zero. As in @sec-Chapter1, the standardized test statistic is a z-score. We calculate it by starting with the sample statistic, subtracting its mean, then dividing by its standard error. p-hat minus the mean of p-hat, divided by the standard error of p-hat. Recall from Sampling in Python that the mean of a sampling distribution of sample means, denoted by p-hat, is p, the population proportion. Under the null hypothesis, the unknown proportion p is assumed to be the hypothesized population proportion p-zero. The z-score is now p-hat minus p-zero, divided by the standard error of p-hat.</span>
<span id="cb52-944"><a href="#cb52-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-945"><a href="#cb52-945" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Simplifying the standard error calculations {.unnumbered}</span></span>
<span id="cb52-946"><a href="#cb52-946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-947"><a href="#cb52-947" aria-hidden="true" tabindex="-1"></a>For proportions, under H-naught, the standard error of p-hat equation can be simplified to p-zero times one minus p-zero, divided by the number of observations, then square-rooted. We can substitute this into our equation for the z-score. This is easier to calculate because it only uses p-hat and n, which we get from the sample, and p-zero, which we chose.</span>
<span id="cb52-948"><a href="#cb52-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-949"><a href="#cb52-949" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Why z instead of t? {.unnumbered}</span></span>
<span id="cb52-950"><a href="#cb52-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-951"><a href="#cb52-951" aria-hidden="true" tabindex="-1"></a>We might wonder why we used a z-distribution here, but a t-distribution in @sec-Chapter2. This is the test statistic equation for the two sample mean case. The standard deviation of the sample, s, is calculated from the sample mean, x-bar. That means that x-bar is used in the numerator to estimate the population mean, and in the denominator to estimate the population standard deviation. This dual usage increases the uncertainty in our estimate of the population parameter. Since t-distributions are effectively a normal distribution with fatter tails, we can use them to account for this extra uncertainty. In effect, the t-distribution provides extra caution against mistakenly rejecting the null hypothesis. For proportions, we only use p-hat in the numerator, thus avoiding the problem with uncertainty, and a z-distribution is fine.</span>
<span id="cb52-952"><a href="#cb52-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-953"><a href="#cb52-953" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Stack Overflow age categories {.unnumbered}</span></span>
<span id="cb52-954"><a href="#cb52-954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-955"><a href="#cb52-955" aria-hidden="true" tabindex="-1"></a>Returning to the Stack Overflow survey, let's hypothesize that half of the users in the population are under thirty and check for a difference. Let's set a significance level of point-zero-one. In the sample, just over half the users are under thirty.</span>
<span id="cb52-956"><a href="#cb52-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-957"><a href="#cb52-957" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Variables for z {.unnumbered}</span></span>
<span id="cb52-958"><a href="#cb52-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-959"><a href="#cb52-959" aria-hidden="true" tabindex="-1"></a>Let's get the numbers needed for the z-score. p-hat is the proportion of sample rows where <span class="in">`age_cat`</span> equals under thirty. p-zero is point-five according to the null hypothesis. n is the number of rows in the dataset.</span>
<span id="cb52-960"><a href="#cb52-960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-961"><a href="#cb52-961" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating the z-score {.unnumbered}</span></span>
<span id="cb52-962"><a href="#cb52-962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-963"><a href="#cb52-963" aria-hidden="true" tabindex="-1"></a>Inserting the values we calculated into the z-score equation yields a z-score of around three-point-four.</span>
<span id="cb52-964"><a href="#cb52-964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-965"><a href="#cb52-965" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating the p-value {.unnumbered}</span></span>
<span id="cb52-966"><a href="#cb52-966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-967"><a href="#cb52-967" aria-hidden="true" tabindex="-1"></a>For left-tailed alternative hypotheses, we transform the z-score into a p-value using <span class="in">`norm.cdf`</span>. For right-tailed alternative hypotheses, we subtract the <span class="in">`norm.cdf`</span> result from one. For two-tailed alternative hypotheses, we check whether the test statistic lies in either tail, so the p-value is the sum of these two values: one corresponding to the z-score and the other to its negative on the other side of the distribution. Since the normal distribution PDF is symmetric, this simplifies to twice the right-tailed p-value since the z-score is positive. Here, the p-value is less than the significance level of point-zero-one, so we reject the null hypothesis, concluding that the proportion of users under thirty is not equal to point-five.</span>
<span id="cb52-968"><a href="#cb52-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-969"><a href="#cb52-969" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 3.1.1</span></span>
<span id="cb52-970"><a href="#cb52-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-971"><a href="#cb52-971" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Test for single proportions {.unnumbered}</span></span>
<span id="cb52-972"><a href="#cb52-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-973"><a href="#cb52-973" aria-hidden="true" tabindex="-1"></a>In @sec-Chapter1, you calculated a p-value for a test hypothesizing that the proportion of late shipments was greater than 6%. In that chapter, you used a bootstrap distribution to estimate the standard error of the statistic. An alternative is to use an equation for the standard error based on the sample proportion, hypothesized proportion, and sample size.</span>
<span id="cb52-974"><a href="#cb52-974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-975"><a href="#cb52-975" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-976"><a href="#cb52-976" aria-hidden="true" tabindex="-1"></a>z = \frac{p - p_0}{\sqrt{\frac{p_0 (1 - p_0)}{n}}}</span>
<span id="cb52-977"><a href="#cb52-977" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-978"><a href="#cb52-978" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb52-979"><a href="#cb52-979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-980"><a href="#cb52-980" aria-hidden="true" tabindex="-1"></a>You'll revisit the p-value using this simpler calculation.</span>
<span id="cb52-981"><a href="#cb52-981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-982"><a href="#cb52-982" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-983"><a href="#cb52-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-984"><a href="#cb52-984" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Hypothesize that the proportion of late shipments is 6%.</span>
<span id="cb52-985"><a href="#cb52-985" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Calculate the sample proportion of shipments where late equals <span class="in">`"Yes"`</span>.</span>
<span id="cb52-986"><a href="#cb52-986" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Calculate the number of observations in the sample.</span>
<span id="cb52-987"><a href="#cb52-987" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Calculate the numerator and denominator of the z-score.</span>
<span id="cb52-988"><a href="#cb52-988" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Calculate the z-score as the ratio of these numbers.</span>
<span id="cb52-989"><a href="#cb52-989" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Transform the z-score into a p-value, remembering that this is a "greater than" alternative hypothesis.</span>
<span id="cb52-990"><a href="#cb52-990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-993"><a href="#cb52-993" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-994"><a href="#cb52-994" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-995"><a href="#cb52-995" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-996"><a href="#cb52-996" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-997"><a href="#cb52-997" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb52-998"><a href="#cb52-998" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb52-999"><a href="#cb52-999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1000"><a href="#cb52-1000" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-1001"><a href="#cb52-1001" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-1002"><a href="#cb52-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1003"><a href="#cb52-1003" aria-hidden="true" tabindex="-1"></a><span class="co"># Hypothesize that the proportion of late shipments is 6%</span></span>
<span id="cb52-1004"><a href="#cb52-1004" aria-hidden="true" tabindex="-1"></a>p_0 <span class="op">=</span> <span class="fl">0.06</span></span>
<span id="cb52-1005"><a href="#cb52-1005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1006"><a href="#cb52-1006" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the sample proportion of late shipments</span></span>
<span id="cb52-1007"><a href="#cb52-1007" aria-hidden="true" tabindex="-1"></a>p_hat <span class="op">=</span> (late_shipments[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">'Yes'</span>).mean()</span>
<span id="cb52-1008"><a href="#cb52-1008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1009"><a href="#cb52-1009" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the sample size</span></span>
<span id="cb52-1010"><a href="#cb52-1010" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(late_shipments)</span>
<span id="cb52-1011"><a href="#cb52-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1012"><a href="#cb52-1012" aria-hidden="true" tabindex="-1"></a><span class="co"># Print p_hat and n</span></span>
<span id="cb52-1013"><a href="#cb52-1013" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(p_hat, n)</span>
<span id="cb52-1014"><a href="#cb52-1014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1015"><a href="#cb52-1015" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the numerator and denominator of the test statistic</span></span>
<span id="cb52-1016"><a href="#cb52-1016" aria-hidden="true" tabindex="-1"></a>numerator <span class="op">=</span> p_hat <span class="op">-</span> p_0</span>
<span id="cb52-1017"><a href="#cb52-1017" aria-hidden="true" tabindex="-1"></a>denominator <span class="op">=</span> np.sqrt(p_0 <span class="op">*</span> (<span class="dv">1</span><span class="op">-</span>p_0)<span class="op">/</span>n)</span>
<span id="cb52-1018"><a href="#cb52-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1019"><a href="#cb52-1019" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the test statistic</span></span>
<span id="cb52-1020"><a href="#cb52-1020" aria-hidden="true" tabindex="-1"></a>z_score <span class="op">=</span> numerator<span class="op">/</span>denominator</span>
<span id="cb52-1021"><a href="#cb52-1021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1022"><a href="#cb52-1022" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb52-1023"><a href="#cb52-1023" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(z_score)</span>
<span id="cb52-1024"><a href="#cb52-1024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1025"><a href="#cb52-1025" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the p-value from the z-score</span></span>
<span id="cb52-1026"><a href="#cb52-1026" aria-hidden="true" tabindex="-1"></a>p_value <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> norm.cdf(z_score)</span>
<span id="cb52-1027"><a href="#cb52-1027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1028"><a href="#cb52-1028" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the p-value</span></span>
<span id="cb52-1029"><a href="#cb52-1029" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(p_value)</span>
<span id="cb52-1030"><a href="#cb52-1030" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1031"><a href="#cb52-1031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1032"><a href="#cb52-1032" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 3.2: Two-sample proportion tests {#sec-Chapter3.2}</span></span>
<span id="cb52-1033"><a href="#cb52-1033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1034"><a href="#cb52-1034" aria-hidden="true" tabindex="-1"></a>Great work so far! In the previous lesson, we tested a single proportion against a specific value. As with means, we can also test for differences between proportions in two populations.</span>
<span id="cb52-1035"><a href="#cb52-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1036"><a href="#cb52-1036" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Comparing two proportions {.unnumbered}</span></span>
<span id="cb52-1037"><a href="#cb52-1037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1038"><a href="#cb52-1038" aria-hidden="true" tabindex="-1"></a>The Stack Overflow survey contains a hobbyist variable. The value "Yes" means the user described themselves as a hobbyist and "No" means they described themselves as a professional. We can hypothesize that the proportion of hobbyist users is the same for the under thirty age category as the thirty or over category, which is a two-tailed test. More formally, the null hypothesis is that the difference between the population parameters for each group is zero. Let's set a significance level of point-zero-five.</span>
<span id="cb52-1039"><a href="#cb52-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1040"><a href="#cb52-1040" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculating the z-score {.unnumbered}</span></span>
<span id="cb52-1041"><a href="#cb52-1041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1042"><a href="#cb52-1042" aria-hidden="true" tabindex="-1"></a>Here is the z-score equation for a proportion test. Let's break it down. The sample statistic is the difference in the proportions for each category. That's the two <span class="in">`p-hat`</span> values in the numerator. We subtract the hypothesized value of the population parameter, and assuming the null hypothesis is true, it's zero. The denominator is the standard error of the sample statistic. We can again avoid having to generate a bootstrap distribution to calculate the standard error by using a standard error equation, which is a slightly more complicated version of the one sample case. Note that <span class="in">`p-hat`</span> is a weighted mean of the sample proportions for each category, also is known as a pooled estimate of the population proportion. <span class="in">`p-hat`</span> can be calculated using the following equation. This looks horrendous, but Python is great at handling arithmetic. We now only need four numbers from the sample dataset to perform these calculations and calculate the z-score: the proportion of hobbyists in each age group, and the number of observations in each age group.</span>
<span id="cb52-1043"><a href="#cb52-1043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1044"><a href="#cb52-1044" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Getting the numbers for the z-score {.unnumbered}</span></span>
<span id="cb52-1045"><a href="#cb52-1045" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1046"><a href="#cb52-1046" aria-hidden="true" tabindex="-1"></a>To calculate these four numbers, we group by the age category, and calculate the sample proportions using <span class="in">`.value_counts`</span>, and the row counts using <span class="in">`.count`</span>. As we're looking at the proportion of hobbyists, we'll only be focusing on rows where hobbyist is Yes.</span>
<span id="cb52-1047"><a href="#cb52-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1048"><a href="#cb52-1048" aria-hidden="true" tabindex="-1"></a>To isolate the hobbyist proportions from <span class="in">`p_hats`</span>, we can use pandas' multiIndex subsetting, passing a tuple of the outer column and inner column values. This returns a sample proportion of point-77 for the at least thirty group, and point-84 for the under thirty's.</span>
<span id="cb52-1049"><a href="#cb52-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1050"><a href="#cb52-1050" aria-hidden="true" tabindex="-1"></a>The number of observations in each age category can be extracted with simpler pandas subsetting. There are 1050 rows in the at least thirty group and 1211 for the under 30 group.</span>
<span id="cb52-1051"><a href="#cb52-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1052"><a href="#cb52-1052" aria-hidden="true" tabindex="-1"></a>After that, we can do the arithmetic using our equations for <span class="in">`p_hat`</span>, the standard error, and the z-score to get the test statistic. This returns a z-score of minus four-point-two-two. Luckily, we can avoid much of this arithmetic.</span>
<span id="cb52-1053"><a href="#cb52-1053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1054"><a href="#cb52-1054" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Proportion tests using `proportions_ztest()` {.unnumbered}</span></span>
<span id="cb52-1055"><a href="#cb52-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1056"><a href="#cb52-1056" aria-hidden="true" tabindex="-1"></a>The <span class="in">`proportions_ztest`</span> function from <span class="in">`statsmodels`</span> can calculate the z-score more directly. This function requires two objects as NumPy arrays: the number of hobbyists in each age group, and the total number of rows in each age group. We can get these numbers by grouping by <span class="in">`age_cat`</span>, and calling <span class="in">`.value_counts`</span> on the hobbyist column, as shown above. The numbers can then either be read-off or subsetted to create the arrays. Next, we import <span class="in">`proportions_ztest`</span> from <span class="in">`statsmodels.stats.proportions`</span>, and pass the arrays to the count and nobs arguments. Because we're testing for a difference, we specify that this is a two-sided test using the alternative argument. <span class="in">`proportions_ztest`</span> returns a z-score and a p-value. The p-value is smaller than the five percent significance level we specified, so we can conclude that there is a difference in the proportion of hobbyists between the two age groups.</span>
<span id="cb52-1057"><a href="#cb52-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1058"><a href="#cb52-1058" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 3.2.1</span></span>
<span id="cb52-1059"><a href="#cb52-1059" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1060"><a href="#cb52-1060" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Test of two proportions {.unnumbered}</span></span>
<span id="cb52-1061"><a href="#cb52-1061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1062"><a href="#cb52-1062" aria-hidden="true" tabindex="-1"></a>You may wonder if the amount paid for freight affects whether or not the shipment was late. Recall that in the <span class="in">`late_shipments`</span> dataset, whether or not the shipment was <span class="in">`late`</span> is stored in the late column. Freight costs are stored in the <span class="in">`freight_cost_group`</span> column, and the categories are <span class="in">`"expensive"`</span> and <span class="in">`"reasonable"`</span>.</span>
<span id="cb52-1063"><a href="#cb52-1063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1064"><a href="#cb52-1064" aria-hidden="true" tabindex="-1"></a>The hypotheses to test, with <span class="in">`"late"`</span> corresponding to the proportion of late shipments for that group, are</span>
<span id="cb52-1065"><a href="#cb52-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1066"><a href="#cb52-1066" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1067"><a href="#cb52-1067" aria-hidden="true" tabindex="-1"></a>H_0: \text{late}_{\text{expensive}} - \text{late}_{\text{reasonable}} = 0</span>
<span id="cb52-1068"><a href="#cb52-1068" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1069"><a href="#cb52-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1070"><a href="#cb52-1070" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1071"><a href="#cb52-1071" aria-hidden="true" tabindex="-1"></a>H_A: \text{late}_{\text{expensive}} - \text{late}_{\text{reasonable}} &gt; 0</span>
<span id="cb52-1072"><a href="#cb52-1072" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1073"><a href="#cb52-1073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1074"><a href="#cb52-1074" aria-hidden="true" tabindex="-1"></a><span class="in">`p_hats`</span> contains the estimates of population proportions (sample proportions) for each <span class="in">`freight_cost_group`</span>:</span>
<span id="cb52-1075"><a href="#cb52-1075" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1076"><a href="#cb52-1076" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1077"><a href="#cb52-1077" aria-hidden="true" tabindex="-1"></a><span class="in">freight_cost_group  late</span></span>
<span id="cb52-1078"><a href="#cb52-1078" aria-hidden="true" tabindex="-1"></a><span class="in">expensive           Yes    0.079096</span></span>
<span id="cb52-1079"><a href="#cb52-1079" aria-hidden="true" tabindex="-1"></a><span class="in">reasonable          Yes    0.035165 </span></span>
<span id="cb52-1080"><a href="#cb52-1080" aria-hidden="true" tabindex="-1"></a><span class="in">Name: late, dtype: float64</span></span>
<span id="cb52-1081"><a href="#cb52-1081" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1082"><a href="#cb52-1082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1083"><a href="#cb52-1083" aria-hidden="true" tabindex="-1"></a><span class="in">`ns`</span> contains the sample sizes for these groups:</span>
<span id="cb52-1084"><a href="#cb52-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1085"><a href="#cb52-1085" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1086"><a href="#cb52-1086" aria-hidden="true" tabindex="-1"></a><span class="in">freight_cost_group</span></span>
<span id="cb52-1087"><a href="#cb52-1087" aria-hidden="true" tabindex="-1"></a><span class="in">expensive     531</span></span>
<span id="cb52-1088"><a href="#cb52-1088" aria-hidden="true" tabindex="-1"></a><span class="in">reasonable    455</span></span>
<span id="cb52-1089"><a href="#cb52-1089" aria-hidden="true" tabindex="-1"></a><span class="in">Name: late, dtype: int64</span></span>
<span id="cb52-1090"><a href="#cb52-1090" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1091"><a href="#cb52-1091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1092"><a href="#cb52-1092" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-1093"><a href="#cb52-1093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1094"><a href="#cb52-1094" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Calculate the pooled sample proportion, $\hat{p}$, from <span class="in">`p_hats`</span> and <span class="in">`ns`</span>.</span>
<span id="cb52-1095"><a href="#cb52-1095" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1096"><a href="#cb52-1096" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1097"><a href="#cb52-1097" aria-hidden="true" tabindex="-1"></a>\hat{p} = \frac{n_{\text{expensive}} \cdot \hat{p}_{\text{expensive}} + n_{\text{reasonable}} \cdot \hat{p}_{\text{reasonable}}}{n_{\text{expensive}} + n_{\text{reasonable}}}</span>
<span id="cb52-1098"><a href="#cb52-1098" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1099"><a href="#cb52-1099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1100"><a href="#cb52-1100" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Calculate the standard error of the sample using this equation.</span>
<span id="cb52-1101"><a href="#cb52-1101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1102"><a href="#cb52-1102" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1103"><a href="#cb52-1103" aria-hidden="true" tabindex="-1"></a>SE(\hat{p}_{\text{expensive}} - \hat{p}_{\text{reasonable}}) = \sqrt{\frac{\hat{p}(1- \hat{p})}{n_{\text{expensive}}} + \frac{\hat{p}(1- \hat{p})}{n_{\text{reasonable}}}}</span>
<span id="cb52-1104"><a href="#cb52-1104" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1105"><a href="#cb52-1105" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb52-1106"><a href="#cb52-1106" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate <span class="in">`p_hat`</span> multiplied by <span class="in">`(1 - p_hat)`</span>.</span>
<span id="cb52-1107"><a href="#cb52-1107" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Divide <span class="in">`p_hat_times_not_p_hat`</span> by the number of <span class="in">`"reasonable"`</span> rows and by the number of <span class="in">`"expensive"`</span> rows, and sum those two values.</span>
<span id="cb52-1108"><a href="#cb52-1108" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate <span class="in">`std_error`</span> by taking the square root of <span class="in">`p_hat_times_not_p_hat_over_ns`</span>.</span>
<span id="cb52-1109"><a href="#cb52-1109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1110"><a href="#cb52-1110" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Calculate the z-score using the following equation.</span>
<span id="cb52-1111"><a href="#cb52-1111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1112"><a href="#cb52-1112" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1113"><a href="#cb52-1113" aria-hidden="true" tabindex="-1"></a>z = \frac{(\hat{p}_{\text{expensive}} - \hat{p}_{\text{reasonable}})}{SE(\hat{p}_{\text{expensive}} - \hat{p}_{\text{reasonable}})}</span>
<span id="cb52-1114"><a href="#cb52-1114" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1115"><a href="#cb52-1115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1116"><a href="#cb52-1116" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Calculate the p-value from the z-score.</span>
<span id="cb52-1117"><a href="#cb52-1117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1120"><a href="#cb52-1120" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-1121"><a href="#cb52-1121" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-1122"><a href="#cb52-1122" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-1123"><a href="#cb52-1123" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-1124"><a href="#cb52-1124" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb52-1125"><a href="#cb52-1125" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb52-1126"><a href="#cb52-1126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1127"><a href="#cb52-1127" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-1128"><a href="#cb52-1128" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-1129"><a href="#cb52-1129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1130"><a href="#cb52-1130" aria-hidden="true" tabindex="-1"></a><span class="co"># P_hats and ns</span></span>
<span id="cb52-1131"><a href="#cb52-1131" aria-hidden="true" tabindex="-1"></a>p_hats <span class="op">=</span> late_shipments.groupby(<span class="st">'freight_cost_groups'</span>)[<span class="st">'late'</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb52-1132"><a href="#cb52-1132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1133"><a href="#cb52-1133" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the resulting Series to a DataFrame for easier manipulation</span></span>
<span id="cb52-1134"><a href="#cb52-1134" aria-hidden="true" tabindex="-1"></a>p_hats <span class="op">=</span> p_hats.reset_index(name<span class="op">=</span><span class="st">'proportion'</span>)</span>
<span id="cb52-1135"><a href="#cb52-1135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1136"><a href="#cb52-1136" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter for rows where 'late' is 'Yes'</span></span>
<span id="cb52-1137"><a href="#cb52-1137" aria-hidden="true" tabindex="-1"></a>p_hats <span class="op">=</span> p_hats[p_hats[<span class="st">'late'</span>] <span class="op">==</span> <span class="st">'Yes'</span>]</span>
<span id="cb52-1138"><a href="#cb52-1138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1139"><a href="#cb52-1139" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the count of each group</span></span>
<span id="cb52-1140"><a href="#cb52-1140" aria-hidden="true" tabindex="-1"></a>ns <span class="op">=</span> late_shipments.groupby(<span class="st">'freight_cost_groups'</span>)[<span class="st">'late'</span>].count()</span>
<span id="cb52-1141"><a href="#cb52-1141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1142"><a href="#cb52-1142" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the pooled estimate of the population proportion</span></span>
<span id="cb52-1143"><a href="#cb52-1143" aria-hidden="true" tabindex="-1"></a>p_hat_expensive <span class="op">=</span> p_hats[p_hats[<span class="st">'freight_cost_groups'</span>] <span class="op">==</span> <span class="st">'expensive'</span>][<span class="st">'proportion'</span>].values[<span class="dv">0</span>]</span>
<span id="cb52-1144"><a href="#cb52-1144" aria-hidden="true" tabindex="-1"></a>p_hat_reasonable <span class="op">=</span> p_hats[p_hats[<span class="st">'freight_cost_groups'</span>] <span class="op">==</span> <span class="st">'reasonable'</span>][<span class="st">'proportion'</span>].values[<span class="dv">0</span>]</span>
<span id="cb52-1145"><a href="#cb52-1145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1146"><a href="#cb52-1146" aria-hidden="true" tabindex="-1"></a>p_hat <span class="op">=</span> (ns[<span class="st">'expensive'</span>] <span class="op">*</span> p_hat_expensive <span class="op">+</span> ns[<span class="st">'reasonable'</span>] <span class="op">*</span> p_hat_reasonable) <span class="op">/</span> (ns[<span class="st">'expensive'</span>] <span class="op">+</span> ns[<span class="st">'reasonable'</span>])</span>
<span id="cb52-1147"><a href="#cb52-1147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1148"><a href="#cb52-1148" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb52-1149"><a href="#cb52-1149" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P_hat value: </span><span class="sc">{</span>p_hat<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb52-1150"><a href="#cb52-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1151"><a href="#cb52-1151" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate p_hat one minus p_hat</span></span>
<span id="cb52-1152"><a href="#cb52-1152" aria-hidden="true" tabindex="-1"></a>p_hat_times_not_p_hat <span class="op">=</span> p_hat <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> p_hat)</span>
<span id="cb52-1153"><a href="#cb52-1153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1154"><a href="#cb52-1154" aria-hidden="true" tabindex="-1"></a><span class="co"># Divide this by each of the sample sizes and then sum</span></span>
<span id="cb52-1155"><a href="#cb52-1155" aria-hidden="true" tabindex="-1"></a>p_hat_times_not_p_hat_over_ns <span class="op">=</span> (p_hat_times_not_p_hat<span class="op">/</span>ns[<span class="st">"expensive"</span>]) <span class="op">+</span> (p_hat_times_not_p_hat<span class="op">/</span>ns[<span class="st">"reasonable"</span>])</span>
<span id="cb52-1156"><a href="#cb52-1156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1157"><a href="#cb52-1157" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the standard error</span></span>
<span id="cb52-1158"><a href="#cb52-1158" aria-hidden="true" tabindex="-1"></a>std_error <span class="op">=</span> np.sqrt(p_hat_times_not_p_hat_over_ns)</span>
<span id="cb52-1159"><a href="#cb52-1159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1160"><a href="#cb52-1160" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb52-1161"><a href="#cb52-1161" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Standard deviation: </span><span class="sc">{</span>std_error<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb52-1162"><a href="#cb52-1162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1163"><a href="#cb52-1163" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the z-score</span></span>
<span id="cb52-1164"><a href="#cb52-1164" aria-hidden="true" tabindex="-1"></a>z_score <span class="op">=</span> (p_hat_expensive  <span class="op">-</span> p_hat_reasonable)<span class="op">/</span>std_error</span>
<span id="cb52-1165"><a href="#cb52-1165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1166"><a href="#cb52-1166" aria-hidden="true" tabindex="-1"></a><span class="co"># Print z_score</span></span>
<span id="cb52-1167"><a href="#cb52-1167" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Z Score: </span><span class="sc">{</span>z_score<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb52-1168"><a href="#cb52-1168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1169"><a href="#cb52-1169" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the p-value from the z-score</span></span>
<span id="cb52-1170"><a href="#cb52-1170" aria-hidden="true" tabindex="-1"></a>p_value <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> norm.cdf(z_score)</span>
<span id="cb52-1171"><a href="#cb52-1171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1172"><a href="#cb52-1172" aria-hidden="true" tabindex="-1"></a><span class="co"># Print p_value</span></span>
<span id="cb52-1173"><a href="#cb52-1173" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P value: </span><span class="sc">{</span>p_value<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb52-1174"><a href="#cb52-1174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1175"><a href="#cb52-1175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1176"><a href="#cb52-1176" aria-hidden="true" tabindex="-1"></a>*This tiny p-value leads us to suspect there is a larger proportion of late shipments for expensive freight compared to reasonable freight.*</span>
<span id="cb52-1177"><a href="#cb52-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1178"><a href="#cb52-1178" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 3.2.2</span></span>
<span id="cb52-1179"><a href="#cb52-1179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1180"><a href="#cb52-1180" aria-hidden="true" tabindex="-1"></a><span class="fu">#### `proportions_ztest()` for two samples {.unnumbered}</span></span>
<span id="cb52-1181"><a href="#cb52-1181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1182"><a href="#cb52-1182" aria-hidden="true" tabindex="-1"></a>That took a lot of effort to calculate the p-value, so while it is useful to see how the calculations work, it isn't practical to do in real-world analyses. For daily usage, it's better to use the <span class="in">`statsmodels`</span> package.</span>
<span id="cb52-1183"><a href="#cb52-1183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1184"><a href="#cb52-1184" aria-hidden="true" tabindex="-1"></a>Recall the hypotheses.</span>
<span id="cb52-1185"><a href="#cb52-1185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1186"><a href="#cb52-1186" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1187"><a href="#cb52-1187" aria-hidden="true" tabindex="-1"></a>H_0: \text{late}_{\text{expensive}} - \text{late}_{\text{reasonable}} = 0</span>
<span id="cb52-1188"><a href="#cb52-1188" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1189"><a href="#cb52-1189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1190"><a href="#cb52-1190" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1191"><a href="#cb52-1191" aria-hidden="true" tabindex="-1"></a>H_A: \text{late}_{\text{expensive}} - \text{late}_{\text{reasonable}} &gt; 0</span>
<span id="cb52-1192"><a href="#cb52-1192" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb52-1193"><a href="#cb52-1193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1194"><a href="#cb52-1194" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-1195"><a href="#cb52-1195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1196"><a href="#cb52-1196" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Get the counts of the <span class="in">`late`</span> column grouped by <span class="in">`freight_cost_groups`</span>.</span>
<span id="cb52-1197"><a href="#cb52-1197" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Extract the number of <span class="in">`"Yes"`</span>'s for the two <span class="in">`freight_cost_group`</span> into a numpy array, specifying the <span class="in">`'expensive'`</span> count and then <span class="in">`'reasonable'`</span>.</span>
<span id="cb52-1198"><a href="#cb52-1198" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Determine the overall number of rows in each <span class="in">`freight_cost_group`</span> as a numpy array, specifying the <span class="in">`'expensive'`</span> count and then <span class="in">`'reasonable'`</span>.</span>
<span id="cb52-1199"><a href="#cb52-1199" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Run a z-test using <span class="in">`proportions_ztest()`</span>, specifying alternative as <span class="in">`"larger"`</span>.</span>
<span id="cb52-1200"><a href="#cb52-1200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1203"><a href="#cb52-1203" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-1204"><a href="#cb52-1204" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-1205"><a href="#cb52-1205" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-1206"><a href="#cb52-1206" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-1207"><a href="#cb52-1207" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.stats.proportion <span class="im">import</span> proportions_ztest</span>
<span id="cb52-1208"><a href="#cb52-1208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1209"><a href="#cb52-1209" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-1210"><a href="#cb52-1210" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-1211"><a href="#cb52-1211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1212"><a href="#cb52-1212" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the late column values for each freight_cost_group</span></span>
<span id="cb52-1213"><a href="#cb52-1213" aria-hidden="true" tabindex="-1"></a>late_by_freight_cost_group <span class="op">=</span> late_shipments.groupby(<span class="st">'freight_cost_groups'</span>)[<span class="st">'late'</span>].value_counts()</span>
<span id="cb52-1214"><a href="#cb52-1214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1215"><a href="#cb52-1215" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the counts</span></span>
<span id="cb52-1216"><a href="#cb52-1216" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(late_by_freight_cost_group)</span>
<span id="cb52-1217"><a href="#cb52-1217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1218"><a href="#cb52-1218" aria-hidden="true" tabindex="-1"></a>stat <span class="op">=</span> <span class="fl">2.922648567784529</span></span>
<span id="cb52-1219"><a href="#cb52-1219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1220"><a href="#cb52-1220" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an array of the "Yes" counts for each freight_cost_group</span></span>
<span id="cb52-1221"><a href="#cb52-1221" aria-hidden="true" tabindex="-1"></a>success_counts <span class="op">=</span> np.array([<span class="dv">42</span>, <span class="dv">16</span>])</span>
<span id="cb52-1222"><a href="#cb52-1222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1223"><a href="#cb52-1223" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an array of the total number of rows in each freight_cost_group</span></span>
<span id="cb52-1224"><a href="#cb52-1224" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> np.array([<span class="dv">489</span> <span class="op">+</span> <span class="dv">42</span>, <span class="dv">439</span> <span class="op">+</span> <span class="dv">16</span>])</span>
<span id="cb52-1225"><a href="#cb52-1225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1226"><a href="#cb52-1226" aria-hidden="true" tabindex="-1"></a><span class="co"># Run a z-test on the two proportions</span></span>
<span id="cb52-1227"><a href="#cb52-1227" aria-hidden="true" tabindex="-1"></a>stat, p_value <span class="op">=</span> proportions_ztest(count <span class="op">=</span> success_counts, nobs <span class="op">=</span> n, alternative <span class="op">=</span> <span class="st">"larger"</span>)</span>
<span id="cb52-1228"><a href="#cb52-1228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1229"><a href="#cb52-1229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1230"><a href="#cb52-1230" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb52-1231"><a href="#cb52-1231" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Z_Stat: </span><span class="sc">{</span>stat<span class="sc">}</span><span class="ss">, P_value: </span><span class="sc">{</span>p_value<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb52-1232"><a href="#cb52-1232" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1233"><a href="#cb52-1233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1234"><a href="#cb52-1234" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 3.3: Chi-square test of independence {#sec-Chapter3.3}</span></span>
<span id="cb52-1235"><a href="#cb52-1235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1236"><a href="#cb52-1236" aria-hidden="true" tabindex="-1"></a>Just as ANOVA extends t-tests to more than two groups, chi-square tests of independence extend proportion tests to more than two groups.</span>
<span id="cb52-1237"><a href="#cb52-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1238"><a href="#cb52-1238" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Revisiting the proportion test {.unnumbered}</span></span>
<span id="cb52-1239"><a href="#cb52-1239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1240"><a href="#cb52-1240" aria-hidden="true" tabindex="-1"></a>Here's the proportions test from the last @sec-Chapter3.2. The test statistic is the z-score of minus four-point-two-two.</span>
<span id="cb52-1241"><a href="#cb52-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1242"><a href="#cb52-1242" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Independence of variables {.unnumbered}</span></span>
<span id="cb52-1243"><a href="#cb52-1243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1244"><a href="#cb52-1244" aria-hidden="true" tabindex="-1"></a>That proportion test had a positive result. The small p-value suggested that there was evidence that the hobbyist and age category variables had an association. If the proportion of hobbyists was the same for each age category, the variables would be considered statistically independent. More formally, two categorical variables are consider statistically independent when the proportion of successes in the response variable is the same across all categories of the explanatory variable.</span>
<span id="cb52-1245"><a href="#cb52-1245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1246"><a href="#cb52-1246" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Test for independence of variables {.unnumbered}</span></span>
<span id="cb52-1247"><a href="#cb52-1247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1248"><a href="#cb52-1248" aria-hidden="true" tabindex="-1"></a>The <span class="in">`pingouin`</span> package has an indirect way of testing the difference in the proportions from the previous @sec-Chapter2.3. To the <span class="in">`chi2_independence`</span> method, we pass <span class="in">`stack_overflow`</span> as data, <span class="in">`hobbyist`</span> as <span class="in">`x`</span>, and <span class="in">`age_cat`</span> as <span class="in">`y`</span>. The correction argument specifies whether or not to apply Yates' continuity correction, which is a fudge factor for when the sample size is very small and the degrees of freedom is one. Since each group has over one hundred observations, we don't need it here. The method returns three different pandas DataFrames: the expected counts, the observed counts, and statistics related to the test. Let's look at stats and focus on the <span class="in">`pearson`</span> test row and the <span class="in">`chi2`</span> and <span class="in">`pval`</span> columns. The p-value is the same as we had with the z-test of around two in one hundred thousand. The <span class="in">`chi2`</span> value is the squared result of our z-score seen in the previous @sec-Chapter3.2.</span>
<span id="cb52-1249"><a href="#cb52-1249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1250"><a href="#cb52-1250" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Job satisfaction and age category {.unnumbered}</span></span>
<span id="cb52-1251"><a href="#cb52-1251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1252"><a href="#cb52-1252" aria-hidden="true" tabindex="-1"></a>Let's try another example. Recall that the Stack Overflow sample has an age category variable with two categories and a job satisfaction variable with five categories.</span>
<span id="cb52-1253"><a href="#cb52-1253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1254"><a href="#cb52-1254" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Declaring the hypotheses {.unnumbered}</span></span>
<span id="cb52-1255"><a href="#cb52-1255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1256"><a href="#cb52-1256" aria-hidden="true" tabindex="-1"></a>We can declare hypotheses to test for independence of these variables. Here, age category is the response variable, and job satisfaction is the explanatory variable. The null hypothesis is that independence occurs. Let's use a <span class="in">`significance level`</span> of <span class="in">`point-one`</span>. The test statistic is denoted chi-square. It quantifies how far away the observed results are from the expected values if independence was true.</span>
<span id="cb52-1257"><a href="#cb52-1257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1258"><a href="#cb52-1258" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Exploratory visualization: proportional stacked bar plot {.unnumbered}</span></span>
<span id="cb52-1259"><a href="#cb52-1259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1260"><a href="#cb52-1260" aria-hidden="true" tabindex="-1"></a>Let's explore the data using a proportional stacked bar plot. We begin by calculating the proportions in each age group. Next, we use the unstack method to convert this table into wide format. Using the plot method and setting kind to bar and stacked to True produces a proportional stacked bar plot.</span>
<span id="cb52-1261"><a href="#cb52-1261" aria-hidden="true" tabindex="-1"></a>If the age category was independent of job satisfaction, the split between the age categories would be at the same height in each of the five bars. There's some variation here, but we'll need a <span class="in">`chi-square independence test`</span> to determine whether it's a significant difference.</span>
<span id="cb52-1262"><a href="#cb52-1262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1263"><a href="#cb52-1263" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Chi-square independence test {.unnumbered}</span></span>
<span id="cb52-1264"><a href="#cb52-1264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1265"><a href="#cb52-1265" aria-hidden="true" tabindex="-1"></a>Let's again use the <span class="in">`chi-square independence test`</span> from <span class="in">`pingouin`</span>. We have <span class="in">`stack_overflow`</span> as the data and <span class="in">`job_sat`</span> and <span class="in">`age_cat`</span> as <span class="in">`x`</span> and <span class="in">`y`</span>. We leave out a correction here since our <span class="in">`degrees of freedom`</span> is <span class="in">`four`</span>, calculated by subtracting one from each of the variable categories and multiplying. The <span class="in">`p-value`</span> is <span class="in">`point-two-three`</span>, which is above the significance level we set, so we conclude that age categories are independent of job satisfaction.</span>
<span id="cb52-1266"><a href="#cb52-1266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1267"><a href="#cb52-1267" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Swapping the variables? {.unnumbered}</span></span>
<span id="cb52-1268"><a href="#cb52-1268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1269"><a href="#cb52-1269" aria-hidden="true" tabindex="-1"></a>Swapping the variables, so age category is the response and job satisfaction is the explanatory variable, we see that the splits for each bar are in similar places.</span>
<span id="cb52-1270"><a href="#cb52-1270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1271"><a href="#cb52-1271" aria-hidden="true" tabindex="-1"></a><span class="fu">#### chi-square both ways {.unnumbered}</span></span>
<span id="cb52-1272"><a href="#cb52-1272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1273"><a href="#cb52-1273" aria-hidden="true" tabindex="-1"></a>If we run the chi-square test with the variables swapped, then the results are identical. Because of this, we phrase our questions as "are variables X and Y independent?", rather than "is variable X independent from variable Y?", since the order doesn't matter.</span>
<span id="cb52-1274"><a href="#cb52-1274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1275"><a href="#cb52-1275" aria-hidden="true" tabindex="-1"></a><span class="fu">#### What about direction and tails? {.unnumbered}</span></span>
<span id="cb52-1276"><a href="#cb52-1276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1277"><a href="#cb52-1277" aria-hidden="true" tabindex="-1"></a>We didn't worry about tails in this test, and in fact, the <span class="in">`chi2_independence`</span> method doesn't have an alternative argument. This is because the chi-square test statistic is based on the square of observed and expected counts, and square numbers are non-negative. That means that chi-square tests tend to be right-tailed tests.</span>
<span id="cb52-1278"><a href="#cb52-1278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1279"><a href="#cb52-1279" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>1 Left-tailed chi-square tests are used in statistical forensics to detect if a fit is suspiciously good because the data was fabricated. Chi-square tests of variance can be two-tailed. These are niche uses, though.</span>
<span id="cb52-1280"><a href="#cb52-1280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1281"><a href="#cb52-1281" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 3.3.3</span></span>
<span id="cb52-1282"><a href="#cb52-1282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1283"><a href="#cb52-1283" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Performing a chi-square test {.unnumbered}</span></span>
<span id="cb52-1284"><a href="#cb52-1284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1285"><a href="#cb52-1285" aria-hidden="true" tabindex="-1"></a>The *chi-square independence test* compares proportions of successes of one categorical variable across the categories of another categorical variable.</span>
<span id="cb52-1286"><a href="#cb52-1286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1287"><a href="#cb52-1287" aria-hidden="true" tabindex="-1"></a>Trade deals often use a form of business shorthand in order to specify the exact details of their contract. These are International Chamber of Commerce (ICC) international commercial terms, or *incoterms* for short.</span>
<span id="cb52-1288"><a href="#cb52-1288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1289"><a href="#cb52-1289" aria-hidden="true" tabindex="-1"></a>The <span class="in">`late_shipments`</span> dataset includes a <span class="in">`vendor_inco_term`</span> that describes the incoterms that applied to a given shipment. The choices are:</span>
<span id="cb52-1290"><a href="#cb52-1290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1291"><a href="#cb52-1291" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`EXW`</span>: "Ex works". The buyer pays for transportation of the goods.</span>
<span id="cb52-1292"><a href="#cb52-1292" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`CIP`</span>: "Carriage and insurance paid to". The seller pays for freight and insurance until the goods board a ship.</span>
<span id="cb52-1293"><a href="#cb52-1293" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`DDP`</span>: "Delivered duty paid". The seller pays for transportation of the goods until they reach a destination port.</span>
<span id="cb52-1294"><a href="#cb52-1294" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`FCA`</span>: "Free carrier". The seller pays for transportation of the goods.</span>
<span id="cb52-1295"><a href="#cb52-1295" aria-hidden="true" tabindex="-1"></a>Perhaps the incoterms affect whether or not the freight costs are expensive. Test these hypotheses with a significance level of <span class="in">`0.01`</span>.</span>
<span id="cb52-1296"><a href="#cb52-1296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1297"><a href="#cb52-1297" aria-hidden="true" tabindex="-1"></a>$H_O$: <span class="in">`vendor_inco_term`</span> and <span class="in">`freight_cost_group`</span> are independent.</span>
<span id="cb52-1298"><a href="#cb52-1298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1299"><a href="#cb52-1299" aria-hidden="true" tabindex="-1"></a>$H_A$: <span class="in">`vendor_inco_term`</span> and <span class="in">`freight_cost_group`</span> are associated.</span>
<span id="cb52-1300"><a href="#cb52-1300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1301"><a href="#cb52-1301" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-1302"><a href="#cb52-1302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1303"><a href="#cb52-1303" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Calculate the proportion of <span class="in">`freight_cost_group`</span> in <span class="in">`late_shipments`</span> grouped by <span class="in">`vendor_inco_term`</span>.</span>
<span id="cb52-1304"><a href="#cb52-1304" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Unstack the <span class="in">`.value_counts()`</span> result to be in wide format instead of long.</span>
<span id="cb52-1305"><a href="#cb52-1305" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Create a proportional stacked bar plot with bars filled based on <span class="in">`freight_cost_group`</span> across the levels of <span class="in">`vendor_inco_term`</span>.</span>
<span id="cb52-1306"><a href="#cb52-1306" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Perform a chi-square test of independence on <span class="in">`freight_cost_group`</span> and <span class="in">`vendor_inco_term`</span> in the <span class="in">`late_shipments`</span> dataset.</span>
<span id="cb52-1307"><a href="#cb52-1307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1310"><a href="#cb52-1310" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-1311"><a href="#cb52-1311" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-1312"><a href="#cb52-1312" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-1313"><a href="#cb52-1313" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-1314"><a href="#cb52-1314" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb52-1315"><a href="#cb52-1315" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb52-1316"><a href="#cb52-1316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1317"><a href="#cb52-1317" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-1318"><a href="#cb52-1318" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-1319"><a href="#cb52-1319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1320"><a href="#cb52-1320" aria-hidden="true" tabindex="-1"></a><span class="co"># Proportion of freight_cost_group grouped by vendor_inco_term</span></span>
<span id="cb52-1321"><a href="#cb52-1321" aria-hidden="true" tabindex="-1"></a>props <span class="op">=</span> late_shipments.groupby(<span class="st">'vendor_inco_term'</span>)[<span class="st">'freight_cost_groups'</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb52-1322"><a href="#cb52-1322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1323"><a href="#cb52-1323" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert props to wide format</span></span>
<span id="cb52-1324"><a href="#cb52-1324" aria-hidden="true" tabindex="-1"></a>wide_props <span class="op">=</span> props.unstack()</span>
<span id="cb52-1325"><a href="#cb52-1325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1326"><a href="#cb52-1326" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop 'DDU' row</span></span>
<span id="cb52-1327"><a href="#cb52-1327" aria-hidden="true" tabindex="-1"></a>wide_props <span class="op">=</span> wide_props.drop(<span class="st">'DDU'</span>, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb52-1328"><a href="#cb52-1328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1329"><a href="#cb52-1329" aria-hidden="true" tabindex="-1"></a><span class="co"># Print wide_props</span></span>
<span id="cb52-1330"><a href="#cb52-1330" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(wide_props)</span>
<span id="cb52-1331"><a href="#cb52-1331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1332"><a href="#cb52-1332" aria-hidden="true" tabindex="-1"></a><span class="co"># Proportional stacked bar plot of freight_cost_group vs. vendor_inco_term</span></span>
<span id="cb52-1333"><a href="#cb52-1333" aria-hidden="true" tabindex="-1"></a>wide_props.plot(kind<span class="op">=</span><span class="st">'bar'</span>, stacked<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb52-1334"><a href="#cb52-1334" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb52-1335"><a href="#cb52-1335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1336"><a href="#cb52-1336" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine if freight_cost_group and vendor_inco_term are independent</span></span>
<span id="cb52-1337"><a href="#cb52-1337" aria-hidden="true" tabindex="-1"></a>expected, observed, stats <span class="op">=</span> pingouin.chi2_independence(data<span class="op">=</span> late_shipments ,x<span class="op">=</span> <span class="st">'freight_cost_groups'</span>, y<span class="op">=</span><span class="st">'vendor_inco_term'</span>)</span>
<span id="cb52-1338"><a href="#cb52-1338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1339"><a href="#cb52-1339" aria-hidden="true" tabindex="-1"></a><span class="co"># Print results</span></span>
<span id="cb52-1340"><a href="#cb52-1340" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stats[stats[<span class="st">'test'</span>] <span class="op">==</span> <span class="st">'pearson'</span>]) </span>
<span id="cb52-1341"><a href="#cb52-1341" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1342"><a href="#cb52-1342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1343"><a href="#cb52-1343" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>What should you conclude from the hypothesis test? </span>
<span id="cb52-1344"><a href="#cb52-1344" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Answer**: Reject the null hypothesis and conclude that <span class="in">`vendor_inco_term`</span> and <span class="in">`freight_cost_group`</span> are associated.</span>
<span id="cb52-1345"><a href="#cb52-1345" aria-hidden="true" tabindex="-1"></a><span class="ss">-  </span>*The test to compare proportions of successes in a categorical variable across groups of another categorical variable is called a chi-square test of independence*.</span>
<span id="cb52-1346"><a href="#cb52-1346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1347"><a href="#cb52-1347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1348"><a href="#cb52-1348" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 3.4: Chi-square goodness of fit tests {#sec-Chapter3.4}</span></span>
<span id="cb52-1349"><a href="#cb52-1349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1350"><a href="#cb52-1350" aria-hidden="true" tabindex="-1"></a>Last time, we used a chi-square test to compare proportions in two categorical variables. This time, we'll use another variant of the chi-square test to compare a single categorical variable to a hypothesized distribution.</span>
<span id="cb52-1351"><a href="#cb52-1351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1352"><a href="#cb52-1352" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Purple links {.unnumbered}</span></span>
<span id="cb52-1353"><a href="#cb52-1353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1354"><a href="#cb52-1354" aria-hidden="true" tabindex="-1"></a>The Stack Overflow survey contains a fun question about how users feel when they discover that they already visited the top resource, also called a purple link, when trying to solve a coding problem. We can use the <span class="in">`.value-counts`</span> method to get the counts of each group in the <span class="in">`purple_link`</span> column. We also do a little bit of manipulation here to get a nicely structured DataFrame that we can work with later. First, we rename the leftmost column to be <span class="in">`purple_link`</span>, assign the counts to <span class="in">`n`</span>, and finally sort by <span class="in">`purple_link`</span>, so the responses are in alphabetical order. There are four possible answers stored in the <span class="in">`purple_link`</span> column.</span>
<span id="cb52-1355"><a href="#cb52-1355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1356"><a href="#cb52-1356" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Declaring the hypotheses {.unnumbered}</span></span>
<span id="cb52-1357"><a href="#cb52-1357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1358"><a href="#cb52-1358" aria-hidden="true" tabindex="-1"></a>Let's hypothesize that half of the users in the population would respond "Hello, old friend", and the other three responses would get one sixth each. We can create a DataFrame for these hypothesized results from a dictionary of key-value pairs for each response. We specify the hypotheses as whether or not the sample matches this hypothesized distribution. The test statistic, chi-squared, measures how far the observed sample distribution of proportions is from the hypothesized distribution. Let's set the significance level of point-zero-one.</span>
<span id="cb52-1359"><a href="#cb52-1359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1360"><a href="#cb52-1360" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Hypothesized counts by category {.unnumbered}</span></span>
<span id="cb52-1361"><a href="#cb52-1361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1362"><a href="#cb52-1362" aria-hidden="true" tabindex="-1"></a>To visualize the <span class="in">`purple_link`</span> distribution, it will help to have the hypothesized counts for each answer, which are calculated by multiplying the hypothesized proportions by the total number of observations in the sample.</span>
<span id="cb52-1363"><a href="#cb52-1363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1364"><a href="#cb52-1364" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Visualizing counts {.unnumbered}</span></span>
<span id="cb52-1365"><a href="#cb52-1365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1366"><a href="#cb52-1366" aria-hidden="true" tabindex="-1"></a>Let's create a visualization to see how well the hypothesized counts appear to model the observed counts. The natural way to visualize the counts of a categorical variable is with a bar plot. First, we use <span class="in">`plt.bar`</span> to plot the observed <span class="in">`purple_link`</span> counts, setting the horizontal axis to <span class="in">`purple_link`</span> and the vertical axis to <span class="in">`n`</span>. We set the color of the bars and add a label for a legend. We do the same again for the hypothesized counts, but also add transparency with the alpha argument.</span>
<span id="cb52-1367"><a href="#cb52-1367" aria-hidden="true" tabindex="-1"></a>We can see that two of the responses are reasonably well-modeled by the hypothesized distribution and another two appear quite different, but we'll need to run a hypothesis test to see if the difference is statistically significant.</span>
<span id="cb52-1368"><a href="#cb52-1368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1369"><a href="#cb52-1369" aria-hidden="true" tabindex="-1"></a><span class="fu">#### chi-square goodness of fit test {.unnumbered}</span></span>
<span id="cb52-1370"><a href="#cb52-1370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1371"><a href="#cb52-1371" aria-hidden="true" tabindex="-1"></a>The one-sample chi-square test is called a goodness of fit test, as we're testing how well our hypothesized data fits the observed data. To run the test, we use the <span class="in">`chisquare`</span> method from <span class="in">`scipy.stats`</span>. There are two required arguments to chisquare: an array-like object for the observed counts, <span class="in">`f_obs`</span>, and one for the expected counts, <span class="in">`f_exp`</span>. The p-value returned by the function is very small, much lower than the significance level of point-zero-one, so we conclude that the sample distribution of proportions is different from the hypothesized distribution.</span>
<span id="cb52-1372"><a href="#cb52-1372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1373"><a href="#cb52-1373" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 3.4.1</span></span>
<span id="cb52-1374"><a href="#cb52-1374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1375"><a href="#cb52-1375" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Visualizing goodness of fit {.unnumbered}</span></span>
<span id="cb52-1376"><a href="#cb52-1376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1377"><a href="#cb52-1377" aria-hidden="true" tabindex="-1"></a>The chi-square goodness of fit test compares proportions of each level of a categorical variable to hypothesized values. Before running such a test, it can be helpful to visually compare the distribution in the sample to the hypothesized distribution.</span>
<span id="cb52-1378"><a href="#cb52-1378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1379"><a href="#cb52-1379" aria-hidden="true" tabindex="-1"></a>Recall the vendor incoterms in the <span class="in">`late_shipments`</span> dataset. You hypothesize that the four values occur with these frequencies in the population of shipments.</span>
<span id="cb52-1380"><a href="#cb52-1380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1381"><a href="#cb52-1381" aria-hidden="true" tabindex="-1"></a><span class="in">`CIP`</span>: 0.05</span>
<span id="cb52-1382"><a href="#cb52-1382" aria-hidden="true" tabindex="-1"></a><span class="in">`DDP`</span>: 0.1</span>
<span id="cb52-1383"><a href="#cb52-1383" aria-hidden="true" tabindex="-1"></a><span class="in">`EXW`</span>: 0.75</span>
<span id="cb52-1384"><a href="#cb52-1384" aria-hidden="true" tabindex="-1"></a><span class="in">`FCA`</span>: 0.1</span>
<span id="cb52-1385"><a href="#cb52-1385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1386"><a href="#cb52-1386" aria-hidden="true" tabindex="-1"></a>These frequencies are stored in the <span class="in">`hypothesized`</span> DataFrame.</span>
<span id="cb52-1387"><a href="#cb52-1387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1388"><a href="#cb52-1388" aria-hidden="true" tabindex="-1"></a>The <span class="in">`incoterm_counts`</span> DataFrame stores the <span class="in">`.value_counts()`</span> of the <span class="in">`vendor_inco_term`</span> column.</span>
<span id="cb52-1389"><a href="#cb52-1389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1390"><a href="#cb52-1390" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-1391"><a href="#cb52-1391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1392"><a href="#cb52-1392" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Find the total number of rows in <span class="in">`late_shipments`</span>.</span>
<span id="cb52-1393"><a href="#cb52-1393" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Add a column named <span class="in">`n`</span> to the <span class="in">`hypothesized`</span> DataFrame that is the <span class="in">`hypothesized`</span> <span class="in">`prop`</span> column times <span class="in">`n_total`</span>.</span>
<span id="cb52-1394"><a href="#cb52-1394" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Create a bar graph of <span class="in">`'n'`</span> versus <span class="in">`'vendor_inco_term'`</span> for the <span class="in">`incoterm_counts`</span> data, specifying a red color.</span>
<span id="cb52-1395"><a href="#cb52-1395" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Add blue bars to the plot showing the same results from the <span class="in">`hypothesized`</span> DataFrame, specifying an <span class="in">`alpha`</span> of <span class="in">`0.5`</span>.</span>
<span id="cb52-1396"><a href="#cb52-1396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1399"><a href="#cb52-1399" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-1400"><a href="#cb52-1400" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-1401"><a href="#cb52-1401" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-1402"><a href="#cb52-1402" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-1403"><a href="#cb52-1403" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb52-1404"><a href="#cb52-1404" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb52-1405"><a href="#cb52-1405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1406"><a href="#cb52-1406" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-1407"><a href="#cb52-1407" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-1408"><a href="#cb52-1408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1409"><a href="#cb52-1409" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the number of rows in late_shipments</span></span>
<span id="cb52-1410"><a href="#cb52-1410" aria-hidden="true" tabindex="-1"></a>n_total <span class="op">=</span> <span class="bu">len</span>(late_shipments)</span>
<span id="cb52-1411"><a href="#cb52-1411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1412"><a href="#cb52-1412" aria-hidden="true" tabindex="-1"></a><span class="co"># Print n_total</span></span>
<span id="cb52-1413"><a href="#cb52-1413" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(n_total)</span>
<span id="cb52-1414"><a href="#cb52-1414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1415"><a href="#cb52-1415" aria-hidden="true" tabindex="-1"></a>hypothesized <span class="op">=</span> pd.DataFrame({</span>
<span id="cb52-1416"><a href="#cb52-1416" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vendor_inco_term'</span>: [<span class="st">'CIP'</span>, <span class="st">'DDP'</span>, <span class="st">'EXW'</span>, <span class="st">'FCA'</span>],</span>
<span id="cb52-1417"><a href="#cb52-1417" aria-hidden="true" tabindex="-1"></a>    <span class="st">'prop'</span>: [<span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.75</span>, <span class="fl">0.1</span>]</span>
<span id="cb52-1418"><a href="#cb52-1418" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb52-1419"><a href="#cb52-1419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1420"><a href="#cb52-1420" aria-hidden="true" tabindex="-1"></a><span class="co"># Create value counts for vendor_inco_term column</span></span>
<span id="cb52-1421"><a href="#cb52-1421" aria-hidden="true" tabindex="-1"></a>incoterm_counts <span class="op">=</span> late_shipments[<span class="st">'vendor_inco_term'</span>].value_counts()<span class="op">\</span></span>
<span id="cb52-1422"><a href="#cb52-1422" aria-hidden="true" tabindex="-1"></a>.rename_axis(<span class="st">'vendor_inco_term'</span>)<span class="op">\</span></span>
<span id="cb52-1423"><a href="#cb52-1423" aria-hidden="true" tabindex="-1"></a>.reset_index(name <span class="op">=</span> <span class="st">'n'</span>)<span class="op">\</span></span>
<span id="cb52-1424"><a href="#cb52-1424" aria-hidden="true" tabindex="-1"></a>.sort_values(<span class="st">'vendor_inco_term'</span>)</span>
<span id="cb52-1425"><a href="#cb52-1425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1426"><a href="#cb52-1426" aria-hidden="true" tabindex="-1"></a><span class="co"># Create n column that is prop column * n_total</span></span>
<span id="cb52-1427"><a href="#cb52-1427" aria-hidden="true" tabindex="-1"></a>hypothesized[<span class="st">'n'</span>] <span class="op">=</span> hypothesized[<span class="st">'prop'</span>] <span class="op">*</span> n_total</span>
<span id="cb52-1428"><a href="#cb52-1428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1429"><a href="#cb52-1429" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the modified hypothesized DataFrame</span></span>
<span id="cb52-1430"><a href="#cb52-1430" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(hypothesized)</span>
<span id="cb52-1431"><a href="#cb52-1431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1432"><a href="#cb52-1432" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot a red bar graph of n vs. vendor_inco_term for incoterm_counts</span></span>
<span id="cb52-1433"><a href="#cb52-1433" aria-hidden="true" tabindex="-1"></a>plt.bar(incoterm_counts[<span class="st">'vendor_inco_term'</span>],incoterm_counts[<span class="st">'n'</span>], color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">"Observed"</span>)</span>
<span id="cb52-1434"><a href="#cb52-1434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1435"><a href="#cb52-1435" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a blue bar plot for the hypothesized counts</span></span>
<span id="cb52-1436"><a href="#cb52-1436" aria-hidden="true" tabindex="-1"></a>plt.bar(hypothesized[<span class="st">'vendor_inco_term'</span>], hypothesized[<span class="st">'n'</span>], color <span class="op">=</span> <span class="st">'blue'</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>,label<span class="op">=</span><span class="st">"Hypothesized"</span>)</span>
<span id="cb52-1437"><a href="#cb52-1437" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb52-1438"><a href="#cb52-1438" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb52-1439"><a href="#cb52-1439" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1440"><a href="#cb52-1440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1441"><a href="#cb52-1441" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 3.4.2</span></span>
<span id="cb52-1442"><a href="#cb52-1442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1443"><a href="#cb52-1443" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Performing a goodness of fit test {.unnumbered}</span></span>
<span id="cb52-1444"><a href="#cb52-1444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1445"><a href="#cb52-1445" aria-hidden="true" tabindex="-1"></a>The bar plot of <span class="in">`vendor_inco_term`</span> suggests that the distribution across the four categories was quite close to the hypothesized distribution. You'll need to perform a *chi-square goodness of fit test* to see whether the differences are statistically significant.</span>
<span id="cb52-1446"><a href="#cb52-1446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1447"><a href="#cb52-1447" aria-hidden="true" tabindex="-1"></a>Recall the hypotheses for this type of test:</span>
<span id="cb52-1448"><a href="#cb52-1448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1449"><a href="#cb52-1449" aria-hidden="true" tabindex="-1"></a>$H_O$: The sample matches with the hypothesized distribution.</span>
<span id="cb52-1450"><a href="#cb52-1450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1451"><a href="#cb52-1451" aria-hidden="true" tabindex="-1"></a>$H_A$: The sample does not match with the hypothesized distribution.</span>
<span id="cb52-1452"><a href="#cb52-1452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1453"><a href="#cb52-1453" aria-hidden="true" tabindex="-1"></a>To decide which hypothesis to choose, we'll set a significance level of <span class="in">`0.1`</span>.</span>
<span id="cb52-1454"><a href="#cb52-1454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1455"><a href="#cb52-1455" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-1456"><a href="#cb52-1456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1457"><a href="#cb52-1457" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Using the <span class="in">`incoterm_counts`</span> and <span class="in">`hypothesized`</span> datasets, perform a chi-square goodness of fit test on the incoterm counts, <span class="in">`n`</span>.</span>
<span id="cb52-1458"><a href="#cb52-1458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1461"><a href="#cb52-1461" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-1462"><a href="#cb52-1462" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-1463"><a href="#cb52-1463" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-1464"><a href="#cb52-1464" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-1465"><a href="#cb52-1465" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> chisquare</span>
<span id="cb52-1466"><a href="#cb52-1466" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb52-1467"><a href="#cb52-1467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1468"><a href="#cb52-1468" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-1469"><a href="#cb52-1469" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-1470"><a href="#cb52-1470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1471"><a href="#cb52-1471" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the number of rows in late_shipments</span></span>
<span id="cb52-1472"><a href="#cb52-1472" aria-hidden="true" tabindex="-1"></a>n_total <span class="op">=</span> <span class="bu">len</span>(late_shipments)</span>
<span id="cb52-1473"><a href="#cb52-1473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1474"><a href="#cb52-1474" aria-hidden="true" tabindex="-1"></a><span class="co"># Hypothesized dataset</span></span>
<span id="cb52-1475"><a href="#cb52-1475" aria-hidden="true" tabindex="-1"></a>hypothesized <span class="op">=</span> pd.DataFrame({</span>
<span id="cb52-1476"><a href="#cb52-1476" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vendor_inco_term'</span>: [<span class="st">'CIP'</span>, <span class="st">'DDP'</span>, <span class="st">'EXW'</span>, <span class="st">'FCA'</span>],</span>
<span id="cb52-1477"><a href="#cb52-1477" aria-hidden="true" tabindex="-1"></a>    <span class="st">'prop'</span>: [<span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.75</span>, <span class="fl">0.1</span>]</span>
<span id="cb52-1478"><a href="#cb52-1478" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb52-1479"><a href="#cb52-1479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1480"><a href="#cb52-1480" aria-hidden="true" tabindex="-1"></a><span class="co"># Create value counts for vendor_inco_term column</span></span>
<span id="cb52-1481"><a href="#cb52-1481" aria-hidden="true" tabindex="-1"></a>incoterm_counts <span class="op">=</span> late_shipments[<span class="st">'vendor_inco_term'</span>].value_counts()<span class="op">\</span></span>
<span id="cb52-1482"><a href="#cb52-1482" aria-hidden="true" tabindex="-1"></a>.rename_axis(<span class="st">'vendor_inco_term'</span>)<span class="op">\</span></span>
<span id="cb52-1483"><a href="#cb52-1483" aria-hidden="true" tabindex="-1"></a>.reset_index(name <span class="op">=</span> <span class="st">'n'</span>)<span class="op">\</span></span>
<span id="cb52-1484"><a href="#cb52-1484" aria-hidden="true" tabindex="-1"></a>.sort_values(<span class="st">'vendor_inco_term'</span>)</span>
<span id="cb52-1485"><a href="#cb52-1485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1486"><a href="#cb52-1486" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter out 'DDU'</span></span>
<span id="cb52-1487"><a href="#cb52-1487" aria-hidden="true" tabindex="-1"></a>incoterm_counts <span class="op">=</span> incoterm_counts[incoterm_counts[<span class="st">'vendor_inco_term'</span>] <span class="op">!=</span> <span class="st">'DDU'</span>]</span>
<span id="cb52-1488"><a href="#cb52-1488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1489"><a href="#cb52-1489" aria-hidden="true" tabindex="-1"></a><span class="co"># Create n column that is prop column * n_total</span></span>
<span id="cb52-1490"><a href="#cb52-1490" aria-hidden="true" tabindex="-1"></a>hypothesized[<span class="st">'n'</span>] <span class="op">=</span> hypothesized[<span class="st">'prop'</span>] <span class="op">*</span> n_total</span>
<span id="cb52-1491"><a href="#cb52-1491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1492"><a href="#cb52-1492" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure the sums of observed and expected frequencies match</span></span>
<span id="cb52-1493"><a href="#cb52-1493" aria-hidden="true" tabindex="-1"></a>observed_sum <span class="op">=</span> incoterm_counts[<span class="st">'n'</span>].<span class="bu">sum</span>()</span>
<span id="cb52-1494"><a href="#cb52-1494" aria-hidden="true" tabindex="-1"></a>expected_sum <span class="op">=</span> hypothesized[<span class="st">'n'</span>].<span class="bu">sum</span>()</span>
<span id="cb52-1495"><a href="#cb52-1495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1496"><a href="#cb52-1496" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust the expected frequencies to match the observed sum</span></span>
<span id="cb52-1497"><a href="#cb52-1497" aria-hidden="true" tabindex="-1"></a>hypothesized[<span class="st">'n'</span>] <span class="op">=</span> hypothesized[<span class="st">'n'</span>] <span class="op">*</span> (observed_sum <span class="op">/</span> expected_sum)</span>
<span id="cb52-1498"><a href="#cb52-1498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1499"><a href="#cb52-1499" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform a goodness of fit test on the incoterm counts n</span></span>
<span id="cb52-1500"><a href="#cb52-1500" aria-hidden="true" tabindex="-1"></a>gof_test <span class="op">=</span> chisquare(f_obs<span class="op">=</span> incoterm_counts[<span class="st">'n'</span>], f_exp <span class="op">=</span> hypothesized[<span class="st">'n'</span>])</span>
<span id="cb52-1501"><a href="#cb52-1501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1502"><a href="#cb52-1502" aria-hidden="true" tabindex="-1"></a><span class="co"># Print gof_test results</span></span>
<span id="cb52-1503"><a href="#cb52-1503" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Chi-Square goodness of fit test: </span><span class="sc">{</span>gof_test<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb52-1504"><a href="#cb52-1504" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1505"><a href="#cb52-1505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1506"><a href="#cb52-1506" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Question**</span>
<span id="cb52-1507"><a href="#cb52-1507" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>What should you conclude from the hypothesis test? *Fail to reject the null hypothesis and conclude that n follows the distribution specified by hypothesized. The test to compare the proportions of a categorical variable to a hypothesized distribution is called a chi-square goodness of fit test.*</span>
<span id="cb52-1508"><a href="#cb52-1508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1509"><a href="#cb52-1509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1510"><a href="#cb52-1510" aria-hidden="true" tabindex="-1"></a><span class="fu">## CHAPTER 4: Non-Parametric Tests {#sec-Chapter4}</span></span>
<span id="cb52-1511"><a href="#cb52-1511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1512"><a href="#cb52-1512" aria-hidden="true" tabindex="-1"></a>Finally, it’s time to learn about the assumptions made by parametric hypothesis tests, and see how non-parametric tests can be used when those assumptions aren't met.</span>
<span id="cb52-1513"><a href="#cb52-1513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1514"><a href="#cb52-1514" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 4.1: Assumptions in hypothesis testing {#sec-Chapter4.1}</span></span>
<span id="cb52-1515"><a href="#cb52-1515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1516"><a href="#cb52-1516" aria-hidden="true" tabindex="-1"></a>Each hypothesis test we've seen so far makes assumptions about the data. It's only when these assumptions are met that it is appropriate to use that hypothesis test.</span>
<span id="cb52-1517"><a href="#cb52-1517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1518"><a href="#cb52-1518" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Randomness {.unnumbered}</span></span>
<span id="cb52-1519"><a href="#cb52-1519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1520"><a href="#cb52-1520" aria-hidden="true" tabindex="-1"></a>Whether it uses one or multiple samples, every hypothesis test assumes that each sample is randomly sourced from its population. If we don't have a random sample, then it won't be representative of the population. To check this assumption, we need to know where our data came from. There are no statistical or coding tests we can perform to check this. If in doubt, ask the people involved in data collection, or a domain expert that understands the population being sampled.</span>
<span id="cb52-1521"><a href="#cb52-1521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1522"><a href="#cb52-1522" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>1 <span class="co">[</span><span class="ot">Sampling techniques are discussed in "Sampling in Python"</span><span class="co">](https://lawaloa.github.io/Sampling/)</span>.</span>
<span id="cb52-1523"><a href="#cb52-1523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1524"><a href="#cb52-1524" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Independence of observations {.unnumbered}</span></span>
<span id="cb52-1525"><a href="#cb52-1525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1526"><a href="#cb52-1526" aria-hidden="true" tabindex="-1"></a>Tests also assume that each observation is independent. There are some special cases like paired t-tests where dependencies between two samples are allowed, but these change the calculations, so we need to understand where such dependencies occur. As we saw with the paired t-test, not accounting for dependencies results in an increased chance of false negative and false positive errors. Not accounting for dependencies is a difficult problem to diagnose during analysis. Ideally, it needs to be discussed before data collection.</span>
<span id="cb52-1527"><a href="#cb52-1527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1528"><a href="#cb52-1528" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Large sample size {.unnumbered}</span></span>
<span id="cb52-1529"><a href="#cb52-1529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1530"><a href="#cb52-1530" aria-hidden="true" tabindex="-1"></a>Hypothesis tests also assume that our sample is large enough that the Central Limit Theorem applies, and the sample distribution can be assumed to be normally distributed. Smaller samples incur greater uncertainty, which may mean that the Central Limit Theorem does not apply and the sampling distribution might not be normally distributed. The increased uncertainty of a small sample means we get wider confidence intervals on the parameter we are trying to estimate. If the Central Limit Theorem does not apply, the calculations on the sample, and any conclusions drawn from them, could be nonsense, which increases the chance of false negative and false positive errors. How big our sample needs to be to be "big enough" depends on the test.</span>
<span id="cb52-1531"><a href="#cb52-1531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1532"><a href="#cb52-1532" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Large sample size: t-test {.unnumbered}</span></span>
<span id="cb52-1533"><a href="#cb52-1533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1534"><a href="#cb52-1534" aria-hidden="true" tabindex="-1"></a>For one sample t-tests, a popular heuristic is that we need at least thirty observations in our sample. For the two sample case or ANOVA, we need thirty observations from each group. That means we can't compensate for one minority group sample by making the majority group bigger. In the paired case, we need thirty pairs of observations. Sometimes we can get away with less than 30 in each of these tests; the important thing is that the null distribution appears normal. This is often the case at around 30 and that's the reason for this somewhat arbitrary threshold.</span>
<span id="cb52-1535"><a href="#cb52-1535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1536"><a href="#cb52-1536" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Large sample size: proportion tests {.unnumbered}</span></span>
<span id="cb52-1537"><a href="#cb52-1537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1538"><a href="#cb52-1538" aria-hidden="true" tabindex="-1"></a>For one sample proportion tests, the sample is considered big enough if it contains at least ten successes and ten failures. Notice that if the probability of success is close to zero or close to one, then we need a bigger sample. In the two sample case, we require ten successes and ten failures from each sample.</span>
<span id="cb52-1539"><a href="#cb52-1539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1540"><a href="#cb52-1540" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Large sample size: chi-square tests {.unnumbered}</span></span>
<span id="cb52-1541"><a href="#cb52-1541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1542"><a href="#cb52-1542" aria-hidden="true" tabindex="-1"></a>The chi-square test is slightly more forgiving and only requires five successes and five failures in each group, rather than ten.</span>
<span id="cb52-1543"><a href="#cb52-1543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1544"><a href="#cb52-1544" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Sanity check {.unnumbered}</span></span>
<span id="cb52-1545"><a href="#cb52-1545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1546"><a href="#cb52-1546" aria-hidden="true" tabindex="-1"></a>One more check we can perform is to calculate a bootstrap distribution and visualize it with a histogram. If we don't see a bell-shaped normal curve, then one of the assumptions hasn't been met. In that case, we should revisit the data collection process, and see if any of the three assumptions of randomness, independence, and sample size do not hold.</span>
<span id="cb52-1547"><a href="#cb52-1547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1548"><a href="#cb52-1548" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 4.1.1</span></span>
<span id="cb52-1549"><a href="#cb52-1549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1550"><a href="#cb52-1550" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Testing sample size {.unnumbered}</span></span>
<span id="cb52-1551"><a href="#cb52-1551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1552"><a href="#cb52-1552" aria-hidden="true" tabindex="-1"></a>In order to conduct a hypothesis test and be sure that the result is fair, a sample must meet three requirements: it is a random sample of the population, the observations are independent, and there are enough observations. Of these, only the last condition is easily testable with code.</span>
<span id="cb52-1553"><a href="#cb52-1553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1554"><a href="#cb52-1554" aria-hidden="true" tabindex="-1"></a>The minimum sample size depends on the type of hypothesis tests you want to perform. You'll now test some scenarios on the <span class="in">`late_shipments`</span> dataset.</span>
<span id="cb52-1555"><a href="#cb52-1555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1556"><a href="#cb52-1556" aria-hidden="true" tabindex="-1"></a>Note that the <span class="in">`.all()`</span> method from pandas can be used to check if all elements are true. For example, given a DataFrame df with numeric entries, you check to see if all its elements are less than 5, using <span class="in">`(df &lt; 5).all()`</span>.</span>
<span id="cb52-1557"><a href="#cb52-1557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1558"><a href="#cb52-1558" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-1559"><a href="#cb52-1559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1560"><a href="#cb52-1560" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Get the count of each value in the freight_cost_group column of late_shipments.</span>
<span id="cb52-1561"><a href="#cb52-1561" aria-hidden="true" tabindex="-1"></a>Insert a suitable number to inspect whether the counts are "big enough" for a two sample t-test.</span>
<span id="cb52-1562"><a href="#cb52-1562" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Get the count of each value in the late column of late_shipments.</span>
<span id="cb52-1563"><a href="#cb52-1563" aria-hidden="true" tabindex="-1"></a>Insert a suitable number to inspect whether the counts are "big enough" for a one sample proportion test.</span>
<span id="cb52-1564"><a href="#cb52-1564" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Get the count of each value in the <span class="in">`freight_cost_group`</span> column of <span class="in">`late_shipments`</span> grouped by <span class="in">`vendor_inco_term`</span>.</span>
<span id="cb52-1565"><a href="#cb52-1565" aria-hidden="true" tabindex="-1"></a>Insert a suitable number to inspect whether the counts are <span class="in">`"big enough"`</span> for a chi-square independence test.</span>
<span id="cb52-1566"><a href="#cb52-1566" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Get the count of each value in the <span class="in">`shipment_mode`</span> column of <span class="in">`late_shipments`</span>.</span>
<span id="cb52-1567"><a href="#cb52-1567" aria-hidden="true" tabindex="-1"></a>Insert a suitable number to inspect whether the counts are "big enough" for an ANOVA test.</span>
<span id="cb52-1568"><a href="#cb52-1568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1571"><a href="#cb52-1571" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-1572"><a href="#cb52-1572" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-1573"><a href="#cb52-1573" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-1574"><a href="#cb52-1574" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-1575"><a href="#cb52-1575" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> chisquare</span>
<span id="cb52-1576"><a href="#cb52-1576" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb52-1577"><a href="#cb52-1577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1578"><a href="#cb52-1578" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-1579"><a href="#cb52-1579" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-1580"><a href="#cb52-1580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1581"><a href="#cb52-1581" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the freight_cost_group values</span></span>
<span id="cb52-1582"><a href="#cb52-1582" aria-hidden="true" tabindex="-1"></a>counts_1 <span class="op">=</span> late_shipments[<span class="st">'freight_cost_groups'</span>].value_counts()</span>
<span id="cb52-1583"><a href="#cb52-1583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1584"><a href="#cb52-1584" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb52-1585"><a href="#cb52-1585" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(counts_1)</span>
<span id="cb52-1586"><a href="#cb52-1586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1587"><a href="#cb52-1587" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect whether the counts are big enough</span></span>
<span id="cb52-1588"><a href="#cb52-1588" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>((counts_1 <span class="op">&gt;=</span> <span class="dv">30</span>).<span class="bu">all</span>())</span>
<span id="cb52-1589"><a href="#cb52-1589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1590"><a href="#cb52-1590" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the late values</span></span>
<span id="cb52-1591"><a href="#cb52-1591" aria-hidden="true" tabindex="-1"></a>counts_2 <span class="op">=</span> late_shipments[<span class="st">'late'</span>].value_counts()</span>
<span id="cb52-1592"><a href="#cb52-1592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1593"><a href="#cb52-1593" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb52-1594"><a href="#cb52-1594" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(counts_2)</span>
<span id="cb52-1595"><a href="#cb52-1595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1596"><a href="#cb52-1596" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect whether the counts are big enough</span></span>
<span id="cb52-1597"><a href="#cb52-1597" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>((counts_2 <span class="op">&gt;=</span> <span class="dv">10</span>).<span class="bu">all</span>())</span>
<span id="cb52-1598"><a href="#cb52-1598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1599"><a href="#cb52-1599" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the values of freight_cost_group grouped by vendor_inco_term</span></span>
<span id="cb52-1600"><a href="#cb52-1600" aria-hidden="true" tabindex="-1"></a>counts_3 <span class="op">=</span> late_shipments.groupby(<span class="st">'vendor_inco_term'</span>)[<span class="st">'freight_cost_groups'</span>].value_counts()<span class="op">\</span></span>
<span id="cb52-1601"><a href="#cb52-1601" aria-hidden="true" tabindex="-1"></a>.drop(<span class="st">'DDU'</span>)</span>
<span id="cb52-1602"><a href="#cb52-1602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1603"><a href="#cb52-1603" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb52-1604"><a href="#cb52-1604" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(counts_3)</span>
<span id="cb52-1605"><a href="#cb52-1605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1606"><a href="#cb52-1606" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect whether the counts are big enough</span></span>
<span id="cb52-1607"><a href="#cb52-1607" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>((counts_3 <span class="op">&gt;=</span> <span class="dv">5</span>).<span class="bu">all</span>())</span>
<span id="cb52-1608"><a href="#cb52-1608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1609"><a href="#cb52-1609" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the shipment_mode values</span></span>
<span id="cb52-1610"><a href="#cb52-1610" aria-hidden="true" tabindex="-1"></a>counts_4 <span class="op">=</span> late_shipments[<span class="st">'shipment_mode'</span>].value_counts()</span>
<span id="cb52-1611"><a href="#cb52-1611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1612"><a href="#cb52-1612" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb52-1613"><a href="#cb52-1613" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Count_4:"</span>, counts_4)</span>
<span id="cb52-1614"><a href="#cb52-1614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1615"><a href="#cb52-1615" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect whether the counts are big enough</span></span>
<span id="cb52-1616"><a href="#cb52-1616" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>((counts_4 <span class="op">&gt;=</span> <span class="dv">30</span>).<span class="bu">all</span>())</span>
<span id="cb52-1617"><a href="#cb52-1617" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1618"><a href="#cb52-1618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1619"><a href="#cb52-1619" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 4.2: Non-parametric tests {#sec-Chapter4.2}</span></span>
<span id="cb52-1620"><a href="#cb52-1620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1621"><a href="#cb52-1621" aria-hidden="true" tabindex="-1"></a>So what do we do if the assumptions for the hypothesis tests we've seen so far aren't met?</span>
<span id="cb52-1622"><a href="#cb52-1622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1623"><a href="#cb52-1623" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Parametric tests {.unnumbered}</span></span>
<span id="cb52-1624"><a href="#cb52-1624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1625"><a href="#cb52-1625" aria-hidden="true" tabindex="-1"></a>The tests that we've seen so far are known as parametric tests. Tests like the z-test, t-test, and ANOVA are all based on the assumption that the population is normally distributed. Parametric tests also require sample sizes that are "big enough" that the Central Limit Theorem applies.</span>
<span id="cb52-1626"><a href="#cb52-1626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1627"><a href="#cb52-1627" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Smaller Republican votes data {.unnumbered}</span></span>
<span id="cb52-1628"><a href="#cb52-1628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1629"><a href="#cb52-1629" aria-hidden="true" tabindex="-1"></a>Let's study a case where the sample size requirement isn't met with a subset of the US Presidential voting results for Republican candidates that we examined in a previous chapter. Here, <span class="in">`repub_votes_small`</span> contains only five counties randomly sampled from the larger dataset of 2008 and 2012 county-level returns.</span>
<span id="cb52-1630"><a href="#cb52-1630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1631"><a href="#cb52-1631" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Results with `pingouin.ttest()` {.unnumbered}</span></span>
<span id="cb52-1632"><a href="#cb52-1632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1633"><a href="#cb52-1633" aria-hidden="true" tabindex="-1"></a>Let's try performing a paired t-test on this small sample. Recall that we require 30 pairs to feel confident in using a t-test, and this sample only contains five. We set a significance level of one percent and use the <span class="in">`ttest`</span> method from <span class="in">`pingouin`</span> to perform the left-tailed paired t-test. The small p-value indicates we should reject the null hypothesis, leading us to suspect that the 2008 election had a smaller percentage of Republican votes than the 2012 election.</span>
<span id="cb52-1634"><a href="#cb52-1634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1635"><a href="#cb52-1635" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Non-parametric tests {.unnumbered}</span></span>
<span id="cb52-1636"><a href="#cb52-1636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1637"><a href="#cb52-1637" aria-hidden="true" tabindex="-1"></a>In situations where we aren't sure about these assumptions, or we are certain that the assumptions aren't met, we can use non-parametric tests. They do not make the normal distribution assumptions or the sample size conditions that we saw in the previous video. There are many different ways to perform tests without these parametric assumptions. In this chapter, we'll focus on those relating to ranks. Consider the list, x. The first value of x, one, is the smallest value and the second value, fifteen, is the fifth smallest. These orderings from smallest to largest are known as the ranks of the elements of x. We can access them with the <span class="in">`rankdata`</span> method from <span class="in">`scipy.stats`</span>.</span>
<span id="cb52-1638"><a href="#cb52-1638" aria-hidden="true" tabindex="-1"></a>Let's now use a non-parametric test to see what kind of results it gives. Remember that non-parametric tests work better than the parametric alternative in situations where the sample size is small or the data cannot be assumed to be normally distributed.</span>
<span id="cb52-1639"><a href="#cb52-1639" aria-hidden="true" tabindex="-1"></a>We will use the Wilcoxon-signed rank test, which was developed by Frank Wilcoxon in 1945 and was one of the first non-parametric procedures developed. We'll go over the inner workings of the test before implementing it using another <span class="in">`pingouin`</span> method.</span>
<span id="cb52-1640"><a href="#cb52-1640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1641"><a href="#cb52-1641" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Wilcoxon-signed rank test (Step 1) {.unnumbered}</span></span>
<span id="cb52-1642"><a href="#cb52-1642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1643"><a href="#cb52-1643" aria-hidden="true" tabindex="-1"></a>The Wilcoxon-signed rank test requires us to calculate the absolute differences in the pairs of data and then rank them. First, we take the differences in the paired values.</span>
<span id="cb52-1644"><a href="#cb52-1644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1645"><a href="#cb52-1645" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Wilcoxon-signed rank test (Step 2) {.unnumbered}</span></span>
<span id="cb52-1646"><a href="#cb52-1646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1647"><a href="#cb52-1647" aria-hidden="true" tabindex="-1"></a>Next, we take the absolute value of the differences, using the <span class="in">`.abs`</span> method, and place them in the <span class="in">`abs_diff`</span> column.</span>
<span id="cb52-1648"><a href="#cb52-1648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1649"><a href="#cb52-1649" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Wilcoxon-signed rank test (Step 3) {.unnumbered}</span></span>
<span id="cb52-1650"><a href="#cb52-1650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1651"><a href="#cb52-1651" aria-hidden="true" tabindex="-1"></a>Then, we rank these absolute differences using the <span class="in">`rankdata`</span> method from <span class="in">`scipy.stats`</span>.</span>
<span id="cb52-1652"><a href="#cb52-1652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1653"><a href="#cb52-1653" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Wilcoxon-signed rank test (Step 4) {.unnumbered}</span></span>
<span id="cb52-1654"><a href="#cb52-1654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1655"><a href="#cb52-1655" aria-hidden="true" tabindex="-1"></a>The last part of our calculation involves calculating a test statistic called W. W uses the signs of the diff column to split the ranks into two groups: one for rows with negative differences and one for positive differences. T-minus is defined as the sum of the ranks with negative differences, and T-plus is the sum of the ranks with positive differences. For this example, all the differences are negative, so the T-minus value is the sum of the five ranks, and T-plus is zero. The test statistic W is the smaller of T-minus and T-plus, which in this case, is zero. We can calculate W, and its corresponding p-value, using a <span class="in">`pingouin`</span> method instead of manual calculation.</span>
<span id="cb52-1656"><a href="#cb52-1656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1657"><a href="#cb52-1657" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Implementation with `pingouin.wilcoxon()` {.unnumbered}</span></span>
<span id="cb52-1658"><a href="#cb52-1658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1659"><a href="#cb52-1659" aria-hidden="true" tabindex="-1"></a>The <span class="in">`.wilcoxon`</span> method from <span class="in">`pingouin`</span> takes very similar arguments to the <span class="in">`.ttest`</span> method, except it doesn't have a paired argument. The function returns a W value of zero - the same as our manual calculation! This corresponds to a p-value of around three percent, which is over ten times larger than the p-value from the t-test, so we should feel more confident with this result given the small sample size. The Wilcoxon test indicates that we do not have evidence that the 2008 Republican percentages are smaller than the 2012 percentages using this small sample of five rows.</span>
<span id="cb52-1660"><a href="#cb52-1660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1661"><a href="#cb52-1661" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 4.2.1</span></span>
<span id="cb52-1662"><a href="#cb52-1662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1663"><a href="#cb52-1663" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Wilcoxon signed-rank test {.unnumbered}</span></span>
<span id="cb52-1664"><a href="#cb52-1664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1665"><a href="#cb52-1665" aria-hidden="true" tabindex="-1"></a>You'll explore the difference between the proportion of county-level votes for the Democratic candidate in 2012 and 2016 to identify if the difference is significant.</span>
<span id="cb52-1666"><a href="#cb52-1666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1667"><a href="#cb52-1667" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-1668"><a href="#cb52-1668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1669"><a href="#cb52-1669" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Conduct a paired t-test on the percentage columns using an appropriate alternative hypothesis.</span>
<span id="cb52-1670"><a href="#cb52-1670" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Conduct a Wilcoxon-signed rank test on the same columns.</span>
<span id="cb52-1671"><a href="#cb52-1671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1674"><a href="#cb52-1674" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-1675"><a href="#cb52-1675" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-1676"><a href="#cb52-1676" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-1677"><a href="#cb52-1677" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-1678"><a href="#cb52-1678" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb52-1679"><a href="#cb52-1679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1680"><a href="#cb52-1680" aria-hidden="true" tabindex="-1"></a>sample_dem_data <span class="op">=</span> pd.read_feather(<span class="st">'datasets/dem_votes_potus_12_16.feather'</span>)</span>
<span id="cb52-1681"><a href="#cb52-1681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1682"><a href="#cb52-1682" aria-hidden="true" tabindex="-1"></a><span class="co"># Conduct a paired t-test on dem_percent_12 and dem_percent_16</span></span>
<span id="cb52-1683"><a href="#cb52-1683" aria-hidden="true" tabindex="-1"></a>paired_test_results <span class="op">=</span> pingouin.ttest(x<span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_12'</span>],</span>
<span id="cb52-1684"><a href="#cb52-1684" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_16'</span>], paired<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb52-1685"><a href="#cb52-1685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1686"><a href="#cb52-1686" aria-hidden="true" tabindex="-1"></a><span class="co"># Print paired t-test results</span></span>
<span id="cb52-1687"><a href="#cb52-1687" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(paired_test_results)</span>
<span id="cb52-1688"><a href="#cb52-1688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1689"><a href="#cb52-1689" aria-hidden="true" tabindex="-1"></a><span class="co"># Conduct a Wilcoxon test on dem_percent_12 and dem_percent_16</span></span>
<span id="cb52-1690"><a href="#cb52-1690" aria-hidden="true" tabindex="-1"></a>wilcoxon_test_results <span class="op">=</span> pingouin.wilcoxon(x<span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_12'</span>],</span>
<span id="cb52-1691"><a href="#cb52-1691" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> sample_dem_data[<span class="st">'dem_percent_16'</span>])</span>
<span id="cb52-1692"><a href="#cb52-1692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1693"><a href="#cb52-1693" aria-hidden="true" tabindex="-1"></a><span class="co"># Print Wilcoxon test results</span></span>
<span id="cb52-1694"><a href="#cb52-1694" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(wilcoxon_test_results)</span>
<span id="cb52-1695"><a href="#cb52-1695" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1696"><a href="#cb52-1696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1697"><a href="#cb52-1697" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter 4.3: Non-parametric ANOVA and unpaired t-tests</span></span>
<span id="cb52-1698"><a href="#cb52-1698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1699"><a href="#cb52-1699" aria-hidden="true" tabindex="-1"></a>In the previous chapter @sec-Chapter4.2, we explored some non-parametric techniques and how they compare to their parametric counterparts. We'll continue on that theme here focusing on non-parametric alternatives to tests of independent numeric samples.</span>
<span id="cb52-1700"><a href="#cb52-1700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1701"><a href="#cb52-1701" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Wilcoxon-Mann-Whitney test {.unnumbered}</span></span>
<span id="cb52-1702"><a href="#cb52-1702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1703"><a href="#cb52-1703" aria-hidden="true" tabindex="-1"></a>We can avoid assumptions about normally distributed data by performing hypothesis tests on the ranks of a numeric input. The Wilcoxon-Mann-Whitney test is, very roughly speaking, a t-test on ranked data. This test is similar to the Wilcoxon test we saw in the last video, but works on unpaired data instead.</span>
<span id="cb52-1704"><a href="#cb52-1704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1705"><a href="#cb52-1705" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Wilcoxon-Mann-Whitney test setup {.unnumbered}</span></span>
<span id="cb52-1706"><a href="#cb52-1706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1707"><a href="#cb52-1707" aria-hidden="true" tabindex="-1"></a>Let's return to the StackOverflow survey and the relationship between converted compensation and the age respondents began coding. We start by focusing on just those two columns in a new DataFrame called <span class="in">`age_vs_comp`</span>. To conduct a Wilcoxon-Mann-Whitney test with <span class="in">`pingouin`</span>, we first need to convert our data from long to wide format. This is accomplished with the <span class="in">`pivot`</span> method from pandas, which unlike <span class="in">`pivot_table`</span>, does not aggregate; instead, it returns the raw values for each group across the rows. We now have our data in two columns named adult and child with the values corresponding to the <span class="in">`converted_comp`</span> entries for each row. An adult value of NaN corresponds to a child entry and a child value of NaN corresponds to an adult entry.</span>
<span id="cb52-1708"><a href="#cb52-1708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1709"><a href="#cb52-1709" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Wilcoxon-Mann-Whitney test {.unnumbered}</span></span>
<span id="cb52-1710"><a href="#cb52-1710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1711"><a href="#cb52-1711" aria-hidden="true" tabindex="-1"></a>Let's set a significance level of one percent. We can run a Wilcoxon-Mann-Whitney test using <span class="in">`mwu`</span> from <span class="in">`pingouin`</span>. It accepts x and y arguments corresponding to the two columns of numbers we want to compare, in this case, child and adult. alternative sets the type of alternative hypothesis, in this case, that those who code first as children have a higher income than those who code first as adults, which is a right-tailed test. Here, the p-value is shown as around ten to the negative nineteenth power, which is significantly smaller than the significance level.</span>
<span id="cb52-1712"><a href="#cb52-1712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1713"><a href="#cb52-1713" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Kruskal-Wallis test {.unnumbered}</span></span>
<span id="cb52-1714"><a href="#cb52-1714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1715"><a href="#cb52-1715" aria-hidden="true" tabindex="-1"></a>In the same way that ANOVA extends t-tests to more than two groups, the Kruskal-Wallis test extends the Wilcoxon-Mann-Whitney test to more than two groups. That is, the Kruskal-Wallis test is a non-parametric version of ANOVA. We use the <span class="in">`Kruskal`</span> method from <span class="in">`pingouin`</span> to perform a Kruskal-Wallis test to investigate if there is a difference in converted_comp between job satisfaction groups. Unlike the Wilcoxon-Mann-Whitney test, we don't need to pivot our data here since the <span class="in">`Kruskal`</span> method works on long data. We pass in <span class="in">`stack_overflow`</span> as data, the dependent variable, dv, as <span class="in">`converted_comp`</span>, and we are comparing between the groups of <span class="in">`job_sat`</span>. Again, the p-value here is very small and smaller than our significance level. This provides evidence that at least one of the mean compensation totals is different than the others across these five job satisfaction groups.</span>
<span id="cb52-1716"><a href="#cb52-1716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1717"><a href="#cb52-1717" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 4.3.1</span></span>
<span id="cb52-1718"><a href="#cb52-1718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1719"><a href="#cb52-1719" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Wilcoxon-Mann-Whitney {.unnumbered}</span></span>
<span id="cb52-1720"><a href="#cb52-1720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1721"><a href="#cb52-1721" aria-hidden="true" tabindex="-1"></a>Another class of non-parametric hypothesis tests are called *rank sum tests*. Ranks are the positions of numeric values from smallest to largest. Think of them as positions in running events: whoever has the fastest (smallest) time is rank 1, second fastest is rank 2, and so on.</span>
<span id="cb52-1722"><a href="#cb52-1722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1723"><a href="#cb52-1723" aria-hidden="true" tabindex="-1"></a>By calculating on the ranks of data instead of the actual values, you can avoid making assumptions about the distribution of the test statistic. It's more robust in the same way that a median is more robust than a mean.</span>
<span id="cb52-1724"><a href="#cb52-1724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1725"><a href="#cb52-1725" aria-hidden="true" tabindex="-1"></a>One common rank-based test is the Wilcoxon-Mann-Whitney test, which is like a non-parametric t-test.</span>
<span id="cb52-1726"><a href="#cb52-1726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1727"><a href="#cb52-1727" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-1728"><a href="#cb52-1728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1729"><a href="#cb52-1729" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Select <span class="in">`weight_kilograms`</span> and late from <span class="in">`late_shipments`</span>, assigning the name <span class="in">`weight_vs_late`</span>.</span>
<span id="cb52-1730"><a href="#cb52-1730" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Convert <span class="in">`weight_vs_late`</span> from long-to-wide format, setting columns to <span class="in">`'late'`</span>.</span>
<span id="cb52-1731"><a href="#cb52-1731" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Run a Wilcoxon-Mann-Whitney test for a difference in <span class="in">`weight_kilograms`</span> when the shipment was late and on-time.</span>
<span id="cb52-1732"><a href="#cb52-1732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1735"><a href="#cb52-1735" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-1736"><a href="#cb52-1736" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-1737"><a href="#cb52-1737" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-1738"><a href="#cb52-1738" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-1739"><a href="#cb52-1739" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb52-1740"><a href="#cb52-1740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1741"><a href="#cb52-1741" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-1742"><a href="#cb52-1742" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-1743"><a href="#cb52-1743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1744"><a href="#cb52-1744" aria-hidden="true" tabindex="-1"></a><span class="co"># Select the weight_kilograms and late columns</span></span>
<span id="cb52-1745"><a href="#cb52-1745" aria-hidden="true" tabindex="-1"></a>weight_vs_late <span class="op">=</span> late_shipments[[<span class="st">'weight_kilograms'</span>, <span class="st">'late'</span>]]</span>
<span id="cb52-1746"><a href="#cb52-1746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1747"><a href="#cb52-1747" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert weight_vs_late into wide format</span></span>
<span id="cb52-1748"><a href="#cb52-1748" aria-hidden="true" tabindex="-1"></a>weight_vs_late_wide <span class="op">=</span> weight_vs_late.pivot(columns<span class="op">=</span><span class="st">'late'</span>, </span>
<span id="cb52-1749"><a href="#cb52-1749" aria-hidden="true" tabindex="-1"></a>                                           values<span class="op">=</span><span class="st">'weight_kilograms'</span>)</span>
<span id="cb52-1750"><a href="#cb52-1750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1751"><a href="#cb52-1751" aria-hidden="true" tabindex="-1"></a><span class="co"># Run a two-sided Wilcoxon-Mann-Whitney test on weight_kilograms vs. late</span></span>
<span id="cb52-1752"><a href="#cb52-1752" aria-hidden="true" tabindex="-1"></a>wmw_test <span class="op">=</span> pingouin.mwu(x<span class="op">=</span>weight_vs_late_wide[<span class="st">'No'</span>],</span>
<span id="cb52-1753"><a href="#cb52-1753" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span> weight_vs_late_wide[<span class="st">'Yes'</span>])</span>
<span id="cb52-1754"><a href="#cb52-1754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1755"><a href="#cb52-1755" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the test results</span></span>
<span id="cb52-1756"><a href="#cb52-1756" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(wmw_test)</span>
<span id="cb52-1757"><a href="#cb52-1757" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1758"><a href="#cb52-1758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1759"><a href="#cb52-1759" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercise 4.3.2</span></span>
<span id="cb52-1760"><a href="#cb52-1760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1761"><a href="#cb52-1761" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Kruskal-Wallis {.unnumbered}</span></span>
<span id="cb52-1762"><a href="#cb52-1762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1763"><a href="#cb52-1763" aria-hidden="true" tabindex="-1"></a>Recall that the Kruskal-Wallis test is a non-parametric version of an ANOVA test, comparing the means across multiple groups.</span>
<span id="cb52-1764"><a href="#cb52-1764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1765"><a href="#cb52-1765" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Instructions {.unnumbered}</span></span>
<span id="cb52-1766"><a href="#cb52-1766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1767"><a href="#cb52-1767" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Run a Kruskal-Wallis test on <span class="in">`weight_kilograms`</span> between the different shipment modes in <span class="in">`late_shipments`</span>.</span>
<span id="cb52-1768"><a href="#cb52-1768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1771"><a href="#cb52-1771" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb52-1772"><a href="#cb52-1772" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary libraries</span></span>
<span id="cb52-1773"><a href="#cb52-1773" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-1774"><a href="#cb52-1774" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-1775"><a href="#cb52-1775" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pingouin</span>
<span id="cb52-1776"><a href="#cb52-1776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1777"><a href="#cb52-1777" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the course dataset </span></span>
<span id="cb52-1778"><a href="#cb52-1778" aria-hidden="true" tabindex="-1"></a>late_shipments <span class="op">=</span> pd.read_feather(<span class="st">'datasets/late_shipments.feather'</span>)</span>
<span id="cb52-1779"><a href="#cb52-1779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1780"><a href="#cb52-1780" aria-hidden="true" tabindex="-1"></a><span class="co"># Run a Kruskal-Wallis test on weight_kilograms vs. shipment_mode</span></span>
<span id="cb52-1781"><a href="#cb52-1781" aria-hidden="true" tabindex="-1"></a>kw_test <span class="op">=</span> pingouin.kruskal(data<span class="op">=</span>late_shipments, dv<span class="op">=</span><span class="st">'weight_kilograms'</span>,</span>
<span id="cb52-1782"><a href="#cb52-1782" aria-hidden="true" tabindex="-1"></a>between<span class="op">=</span> <span class="st">'shipment_mode'</span>)</span>
<span id="cb52-1783"><a href="#cb52-1783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1784"><a href="#cb52-1784" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb52-1785"><a href="#cb52-1785" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(kw_test)</span>
<span id="cb52-1786"><a href="#cb52-1786" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-1787"><a href="#cb52-1787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1788"><a href="#cb52-1788" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Conclusion {.unnumbered}</span></span>
<span id="cb52-1789"><a href="#cb52-1789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1790"><a href="#cb52-1790" aria-hidden="true" tabindex="-1"></a>*The Kruskal-Wallis test yielded a very small p-value, so there is evidence that at least one of the three groups of shipment mode has a different weight distribution than the others. Th Kruskal-Wallis test is comparable to an ANOVA, which tests for a difference in means across multiple groups.*</span>
<span id="cb52-1791"><a href="#cb52-1791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1792"><a href="#cb52-1792" aria-hidden="true" tabindex="-1"></a><span class="fu">## Reference</span></span>
<span id="cb52-1793"><a href="#cb52-1793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-1794"><a href="#cb52-1794" aria-hidden="true" tabindex="-1"></a>Hypothesis Testing in Python Course for Associate Data Scientist in Python Carrer Track in DataCamp Inc by James Chapman.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>